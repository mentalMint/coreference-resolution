{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mentalMint/coreference-resolution/blob/main/RuCoCo_baseline_joker_iis_nsk_su.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyGg3amMeXJ6"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU8dffeJa0fm",
        "outputId": "c39ca853-9824-4e22-d0de-df376be68f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (23.3.1)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (68.2.2)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: wheel in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (0.41.2)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
            "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.41.2\n",
            "    Uninstalling wheel-0.41.2:\n",
            "      Successfully uninstalled wheel-0.41.2\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 68.2.2\n",
            "    Uninstalling setuptools-68.2.2:\n",
            "      Successfully uninstalled setuptools-68.2.2\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.3.1\n",
            "    Uninstalling pip-23.3.1:\n",
            "      Successfully uninstalled pip-23.3.1\n",
            "Successfully installed pip-24.0 setuptools-69.2.0 wheel-0.43.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wPDm1JnYhav",
        "outputId": "f65323c8-c1cd-4f2c-a79d-e0cdbc753687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 24.0 from /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/pip (python 3.9)\n",
            "Collecting transformers==4.15.0\n",
            "  Obtaining dependency information for transformers==4.15.0 from https://files.pythonhosted.org/packages/4a/7f/f1c28621af0d74794b18cbe5534ec7565ee782ba48257d08ec264bc4aacb/transformers-4.15.0-py3-none-any.whl.metadata\n",
            "  Using cached transformers-4.15.0-py3-none-any.whl.metadata (59 kB)\n",
            "Requirement already satisfied: filelock in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (0.21.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (0.1.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.15.0)\n",
            "  Obtaining dependency information for tokenizers<0.11,>=0.10.1 from https://files.pythonhosted.org/packages/a8/4f/ca8bc50358c3aaf50f298860a5ce1822e0c0ff97543e32265d1353760555/tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
            "  Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from transformers==4.15.0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->transformers==4.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->transformers==4.15.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->transformers==4.15.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->transformers==4.15.0) (2024.2.2)\n",
            "Requirement already satisfied: click in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from sacremoses->transformers==4.15.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from sacremoses->transformers==4.15.0) (1.3.2)\n",
            "Using cached transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "Using cached tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Removing file or directory /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/tokenizers-0.13.3.dist-info/\n",
            "      Removing file or directory /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/tokenizers.libs/\n",
            "      Removing file or directory /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/tokenizers/\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.31.0\n",
            "    Uninstalling transformers-4.31.0:\n",
            "      Removing file or directory /home/shuvalov/.conda/envs/env/bin/transformers-cli\n",
            "      Removing file or directory /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/transformers-4.31.0.dist-info/\n",
            "      Removing file or directory /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/transformers/\n",
            "      Successfully uninstalled transformers-4.31.0\n",
            "  changing mode of /home/shuvalov/.conda/envs/env/bin/transformers-cli to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "trl 0.4.7 requires transformers>=4.18.0, but you have transformers 4.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --verbose transformers==4.15.0\n",
        "# !python -m pip install --verbose transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeeFoXyWPtFb",
        "outputId": "88e0fcf6-f259-4d58-f125-c0edf5bf86fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.13.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch==1.13.1) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (69.2.0)\n",
            "Requirement already satisfied: wheel in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.43.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch==1.13.1 --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QVn-kbca18V",
        "outputId": "7e67f60d-0512-477c-edb7-68663dc2f80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy==3.2.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (3.2.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (69.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy==3.2.1) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy==3.2.1) (6.4.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy==3.2.1) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy==3.2.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.1) (2024.2.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.1) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from jinja2->spacy==3.2.1) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy==3.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqD5DYHulqyX",
        "outputId": "f1cb006b-8fc3-4855-b1e6-823f80da1034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning==1.9.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (6.0.1)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2024.2.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pytorch-lightning==1.9.0) (0.10.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from lightning-utilities>=0.4.2->pytorch-lightning==1.9.0) (69.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.7.99)\n",
            "Requirement already satisfied: wheel in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->pytorch-lightning==1.9.0) (0.43.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.6)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install pytorch-lightning==1.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59aclzcbhWDR",
        "outputId": "a17d402b-4782-4be2-81d8-e0370112ecc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.2.0/ru_core_news_md-3.2.0-py3-none-any.whl#egg=ru_core_news_md==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\r\n",
            "\u001b[0mCollecting ru-core-news-md==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.2.0/ru_core_news_md-3.2.0-py3-none-any.whl (43.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 MB\u001b[0m \u001b[31m351.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from ru-core-news-md==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: pymorphy2>=0.9 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from ru-core-news-md==3.2.0) (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pymorphy2>=0.9->ru-core-news-md==3.2.0) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pymorphy2>=0.9->ru-core-news-md==3.2.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pymorphy2>=0.9->ru-core-news-md==3.2.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (69.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (6.4.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2024.2.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->ru-core-news-md==3.2.0) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_md')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download ru_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Q6p3nKTC7C",
        "outputId": "86489b47-4008-491a-cf43-e5103740b7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (0.21.4)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.22.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (2024.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->huggingface_hub) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Downloading huggingface_hub-0.22.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.5/388.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.21.4\n",
            "    Uninstalling huggingface-hub-0.21.4:\n",
            "      Successfully uninstalled huggingface-hub-0.21.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "trl 0.4.7 requires transformers>=4.18.0, but you have transformers 4.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaHyjSwe1HfY",
        "outputId": "fb633d19-6a95-4e06-c5ee-5315720cf63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_xla in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (2.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch_xla) (2.1.0)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch_xla) (0.10)\n",
            "Requirement already satisfied: pyyaml in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from torch_xla) (6.0.1)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from cloud-tpu-client>=0.10.0->torch_xla) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from cloud-tpu-client>=0.10.0->torch_xla) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.28.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (0.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch_xla) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (5.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U 'torch_xla'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dmqf7Z3fuAR",
        "outputId": "111c2c82-01f6-4832-8625-a073b3df50d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp39-cp39-linux_x86_64.whl size=124786 sha256=5a1ad39c6520552bfca06d7246d136fad8b5a982375791beba703de3b2960921\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2tqffs24/wheels/f2/7a/49/9bef8878949914ecb90c08fc5bf30a05e17f475fe7e08b63a8\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ],
      "source": [
        "!pip install --no-cache-dir pickle5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install typing-inspect==0.8.0 typing_extensions==4.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtgDbBEolJma",
        "outputId": "608690fb-a89d-4ecf-ff86-74672ed28c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-inspect==0.8.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (0.8.0)\r\n",
            "Requirement already satisfied: typing_extensions==4.5.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (4.5.0)\r\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (from typing-inspect==0.8.0) (1.0.0)\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81sQ9r2Jy7ML"
      },
      "source": [
        "# Used classes and methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gzw8OonziQT"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from typing import Dict, Iterator, List, Optional, Tuple, List, NamedTuple\n",
        "import transformers\n",
        "import spacy\n",
        "from tokenizers import pre_tokenizers\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from transformers import AutoModel\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# global_encoder_model_name = \"cointegrated/rubert-tiny\"\n",
        "# global_encoder_model_name = \"cointegrated/rubert-tiny2\"\n",
        "# global_encoder_model_name = \"blinoff/roberta-base-russian-v0\"\n",
        "global_encoder_model_name = \"ai-forever/ruRoberta-large\"\n",
        "# global_encoder_model_name = \"kazzand/ru-longformer-tiny-16384\"\n",
        "# global_encoder_model_name = \"kazzand/ru-longformer-large-4096\"\n",
        "\n",
        "\n",
        "max_text_length = 512\n",
        "\n",
        "class SpanExtractor:\n",
        "    skipped_pos = {\"ADP\", \"CCONJ\", \"SCONJ\"}\n",
        "    allowed_punct = {\"\\\"\", \"'\", \"(\", \")\", \".\"}\n",
        "\n",
        "    def __init__(self, model_name: str = \"ru_core_news_md\"):\n",
        "        self.nlp = spacy.load(model_name)\n",
        "\n",
        "    def __call__(self, text: str) -> Iterator[Tuple[int, int]]:\n",
        "        res = self.nlp(text, disable=(\"lemmatizer\", \"ner\"))\n",
        "        for token in res:\n",
        "            if token.pos_ in {\"DET\", \"PRON\"}:             # определитель, местоимение\n",
        "                yield token.idx, token.idx + len(token)\n",
        "            elif token.pos_ in {\"NOUN\", \"PROPN\"}:\n",
        "                start, end = token.idx, token.idx + len(token)\n",
        "                for i in range(token.i - 1, -1, -1):\n",
        "                    if (token.sent != res[i].sent\n",
        "                            or not token.is_ancestor(res[i])):\n",
        "                        break\n",
        "                    if res[i].head == token:\n",
        "                        if self._is_participle_phrase(res[i]):\n",
        "                            break\n",
        "                        if self._is_skipped_pos(res[i]):\n",
        "                            continue\n",
        "                        leftmost = next(node for node in res[i].subtree if not self._is_skipped_pos(node))\n",
        "                        if leftmost.idx < start:\n",
        "                            start = leftmost.idx\n",
        "                for i in range(token.i + 1, len(res)):\n",
        "                    if (token.sent != res[i].sent\n",
        "                            or not token.is_ancestor(res[i])):\n",
        "                        break\n",
        "                    if res[i].head == token:\n",
        "                        if self._is_participle_phrase(res[i]):\n",
        "                            break\n",
        "                        if self._is_skipped_pos(res[i]):\n",
        "                            continue\n",
        "                        rightmost = next(node for node in reversed(list(res[i].subtree))\n",
        "                                         if not self._is_skipped_pos(node))\n",
        "                        if rightmost.idx + len(rightmost) > end:\n",
        "                            end = rightmost.idx + len(rightmost)\n",
        "                yield (start, end)\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_participle_phrase(token: spacy.tokens.token.Token) -> bool:\n",
        "        return token.pos_ == \"VERB\" and any(node != token for node in token.subtree)\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_skipped_pos(token: spacy.tokens.token.Token) -> bool:\n",
        "        return (token.pos_ in SpanExtractor.skipped_pos\n",
        "                or (token.pos_ == \"PUNCT\" and token.text not in SpanExtractor.allowed_punct))\n",
        "\n",
        "class Doc:\n",
        "\n",
        "    span_extractor = SpanExtractor()\n",
        "\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 data: dict,\n",
        "                 semantics: dict = None,\n",
        "                 *,\n",
        "                 tokenizer: transformers.PreTrainedTokenizerBase,\n",
        "                 extract_all_spans: bool = False,\n",
        "                 ):\n",
        "        self.name = name\n",
        "        self.raw_data = data\n",
        "        self.semantics = semantics\n",
        "        self.encoding = tokenizer(data[\"text\"],\n",
        "                                  add_special_tokens=True,\n",
        "                                  padding=True,\n",
        "                                  truncation=True,\n",
        "                                  max_length=max_text_length,\n",
        "                                  return_tensors=\"pt\",\n",
        "                                  return_attention_mask=True,\n",
        "                                  return_overflowing_tokens=True,\n",
        "                                  return_offsets_mapping=True,\n",
        "                                  return_special_tokens_mask=True)\n",
        "        self.flattening_mask = (self.encoding.special_tokens_mask == 0)\n",
        "        self.flat_offset_mapping = self.encoding.offset_mapping[self.flattening_mask].tolist()\n",
        "        self._start_mapping: Dict[int, int] = {}\n",
        "        self._end_mapping: Dict[int, int] = {}\n",
        "        for token_i, (char_start, char_end) in enumerate(self.flat_offset_mapping):\n",
        "            if char_start != char_end:\n",
        "                if char_start in self._start_mapping or char_end in self._end_mapping:\n",
        "                    logging.warning(f\"{self.name}: \"\n",
        "                                    f\"overlapping subtoken {token_i} at {(char_start, char_end)}; \"\n",
        "                                    f\"existing subtokens: {self._start_mapping.get(char_start)}, \"\n",
        "                                    f\"{self._end_mapping.get(char_end)}\")\n",
        "                    continue\n",
        "                self._start_mapping[char_start] = token_i\n",
        "                self._end_mapping[char_end] = token_i\n",
        "\n",
        "        self.entities = self._match_entities_to_tokens()\n",
        "\n",
        "        self._all_spans = None\n",
        "        if extract_all_spans:\n",
        "            self._all_spans = self._extract_all_spans()\n",
        "\n",
        "        self.spans_classes = None\n",
        "        self.sem_classes = None\n",
        "        if self.semantics != None:\n",
        "            self.spans_classes, self.sem_classes = self.match_sem_class_to_span()\n",
        "            logging.warning(\"semantic classes: \" + str(self.sem_classes))\n",
        "            self.sem_classes_sizes = Counter(self.spans_classes.values())\n",
        "\n",
        "    def match_sem_class_to_span(self):\n",
        "        spans_classes = {}\n",
        "        sem_classes = []\n",
        "        for obj in self.semantics:\n",
        "            start = obj[\"location\"][\"start\"]\n",
        "            end = obj[\"location\"][\"end\"]\n",
        "            char_span = (start, end)\n",
        "            token_span = self.char_span_to_tokens((start, end))\n",
        "            if token_span:\n",
        "                sem_class = obj[\"value\"]\n",
        "                spans_classes[token_span] = sem_class\n",
        "                if sem_class not in sem_classes:\n",
        "                    sem_classes.append(sem_class)\n",
        "                if token_span not in self._all_spans:\n",
        "                    self._all_spans.append(token_span)\n",
        "                logging.warning(f\"{self.name}: adding classified entity {char_span}: {data['text'][start:end]}\")\n",
        "            else:\n",
        "                logging.warning(f\"{self.name}: skipping classified entity {char_span}: {data['text'][start:end]}\")\n",
        "        return spans_classes, sem_classes\n",
        "\n",
        "    @property\n",
        "    def all_spans(self) -> Iterator[Tuple[int, int]]:\n",
        "        if self._all_spans is None:\n",
        "            self._all_spans = self._extract_all_spans()\n",
        "        return iter(self._all_spans)\n",
        "\n",
        "    def char_span_to_tokens(self, span: Tuple[int, int]) -> Optional[Tuple[int, int]]:\n",
        "        char_start, char_end = span\n",
        "        token_start = self._start_mapping.get(char_start)\n",
        "        token_end = self._end_mapping.get(char_end)\n",
        "        if token_start is not None and token_end is not None:\n",
        "            return (token_start, token_end + 1)\n",
        "        logging.warning(f\"{self.name}: skipping span {(char_start, char_end)}, \"\n",
        "                        f\"{repr(self.raw_data['text'][char_start: char_end])}\")\n",
        "\n",
        "    def token_span_to_chars(self, span: Tuple[int, int]) -> Tuple[int, int]:\n",
        "        token_start, token_end = span\n",
        "        char_start = self.flat_offset_mapping[token_start][0]\n",
        "        char_end = self.flat_offset_mapping[token_end - 1][1]\n",
        "        return (char_start, char_end)\n",
        "\n",
        "    def _extract_all_spans(self) -> List[Tuple[int, int]]:\n",
        "        out = []\n",
        "        for char_span in self.span_extractor(self.raw_data[\"text\"]):\n",
        "            token_span = self.char_span_to_tokens(char_span)\n",
        "            if token_span:\n",
        "                out.append(token_span)\n",
        "        return out\n",
        "\n",
        "    def _match_entities_to_tokens(self) -> List[List[Tuple[int, int]]]:\n",
        "        char_entities = self.raw_data[\"entities\"]\n",
        "        token_entities = []\n",
        "\n",
        "        for char_entity in char_entities:\n",
        "            token_entity = []\n",
        "            for char_start, char_end in char_entity:\n",
        "                token_span = self.char_span_to_tokens((char_start, char_end))\n",
        "                if token_span:\n",
        "                    token_entity.append(token_span)\n",
        "            if token_entity:\n",
        "                token_entities.append(token_entity)\n",
        "            else:\n",
        "                logging.warning(f\"{self.name}: skipping entity {char_entity}\")\n",
        "\n",
        "        return token_entities\n",
        "\n",
        "\n",
        "ADD_PUNCTUATION_PRE_TOKENIZER = {global_encoder_model_name, }\n",
        "\n",
        "\n",
        "def load_tokenizer(model_name: str) -> transformers.AutoTokenizer:\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    if model_name in ADD_PUNCTUATION_PRE_TOKENIZER:\n",
        "        tokenizer._tokenizer.pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Punctuation(),\n",
        "                                                                      tokenizer._tokenizer.pre_tokenizer])\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "EPS = 1e-8\n",
        "\n",
        "\n",
        "class LEAResult(NamedTuple):\n",
        "    precision: float\n",
        "    precision_weight: float\n",
        "    recall: float\n",
        "    recall_weight: float\n",
        "\n",
        "\n",
        "class CorefModel(pl.LightningModule):\n",
        "    def __init__(self,\n",
        "                 encoder_model_name: str = global_encoder_model_name,\n",
        "                 dropout_rate: float = 0.3,\n",
        "                 k: int = 50,\n",
        "                 max_batches_train: Optional[int] = None,\n",
        "                 **discarded_kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(\"encoder_model_name\", \"dropout_rate\", \"k\", \"max_batches_train\")\n",
        "\n",
        "        self.encoder = AutoModel.from_pretrained(encoder_model_name)\n",
        "\n",
        "        self.token_importance_linear = torch.nn.Linear(self.encoder.config.hidden_size, 1)\n",
        "        self.span_dropout = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.coarse_bilinear = torch.nn.Linear(self.encoder.config.hidden_size, self.encoder.config.hidden_size)\n",
        "        self.coarse_dropout = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.fine_linear = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.encoder.config.hidden_size * 3, self.encoder.config.hidden_size),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            torch.nn.Linear(self.encoder.config.hidden_size, 1)\n",
        "        )\n",
        "\n",
        "        self.k = k\n",
        "        self.max_batches_train = max_batches_train\n",
        "\n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser):\n",
        "        parser = parent_parser.add_argument_group(\"CorefModel\")\n",
        "        parser.add_argument(\"--encoder_model_name\", default=global_encoder_model_name)\n",
        "        parser.add_argument(\"--dropout_rate\", type=float, default=0.3)\n",
        "        parser.add_argument(\"--k\", type=int, default=50)\n",
        "        parser.add_argument(\"--max_batches_train\", type=int)\n",
        "        return parent_parser\n",
        "\n",
        "    def forward(self, doc: Doc) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "        # Encoding spans ################\n",
        "\n",
        "        # The input batches of the document are processed independently by a BERT-like model,\n",
        "        # then the last hidden states of all the batch outputs are taken, exluding special tokens (cls, sep and pad)\n",
        "        # This gives us embs - [n_tokens, emb] matrix with token embeddings\n",
        "        input_ids, attention_mask = doc.encoding.input_ids.to(self.device), doc.encoding.attention_mask.to(self.device)\n",
        "        if not self.training or self.max_batches_train is None or len(input_ids) <= self.max_batches_train:\n",
        "            embs = self.encoder(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        else:\n",
        "            embs = torch.zeros((*input_ids.shape, self.encoder.config.hidden_size), device=self.device)\n",
        "            selected_batches = torch.rand(len(input_ids)).topk(self.max_batches_train).indices\n",
        "            embs[selected_batches] = self.encoder(input_ids=input_ids[selected_batches],\n",
        "                                                  attention_mask=attention_mask[selected_batches]).last_hidden_state\n",
        "        embs = embs[doc.flattening_mask]      # Убираем специальные токены                                              # [n_tokens, emb]\n",
        "\n",
        "        if doc.sem_classes != None and len(doc.sem_classes) > 0:\n",
        "            all_scores = None\n",
        "            all_indices = None\n",
        "            for sem_class in doc.sem_classes:\n",
        "                # We transform a matrix of span starts and ends into an [n_spans, n_tokens] boolean mask,\n",
        "                # which for i-th row will have 1 at positions of tokens that are part of the i-th span\n",
        "                spans = torch.tensor(list(doc.all_spans), dtype=torch.long, device=self.device)     # [n_spans, 2]\n",
        "                indices = torch.arange(0, len(embs), device=self.device).unsqueeze(0).expand(len(spans), len(embs))\n",
        "                span_mask = (indices >= spans[:, 0].unsqueeze(1)) * (indices < spans[:, 1].unsqueeze(1))\n",
        "                span_mask = span_mask.to(torch.float)\n",
        "                span_mask = torch.log(span_mask)\n",
        "                # logging.warning(\"span mask: \" + str(span_mask))\n",
        "\n",
        "                # Each token representation is passed through trainable token importance linear layer\n",
        "                # The obtained scores are then softmaxed for each span\n",
        "                # This way, if a span consists of one token, this token's embeddings will have 1.0 of the weight\n",
        "                # While, for example, for a two-token span with scores of [1.2, 2.6] the weights will be [0.2, 0.8]\n",
        "                token_scores = self.token_importance_linear(embs).squeeze(1)                        # [n_tokens]\n",
        "                token_scores = token_scores.unsqueeze(0).expand(len(spans), len(embs))              # [n_spans, n_tokens]\n",
        "                token_scores = torch.softmax(token_scores + span_mask, dim=1)\n",
        "                for span, span_class in doc.spans_classes.items():\n",
        "                    if (span_class != sem_class):\n",
        "                        span_index = doc._all_spans.index(span)\n",
        "                        token_scores[span_index] *= 0\n",
        "                        # spans = torch.cat((spans[:span_index],spans[span_index+1:]))\n",
        "                logging.warning(\"token scores: \" + str(token_scores))\n",
        "\n",
        "                # Span representations are obtained as weighted sums of the token representations of the span\n",
        "                embs = token_scores.mm(embs)                                                        # [n_spans, emb]\n",
        "                logging.warning(\"span embeddings: \" + str(embs))\n",
        "                embs = self.span_dropout(embs)\n",
        "\n",
        "                # Coarse span pair scoring ######\n",
        "\n",
        "                # We set to -inf the scores of all span pairs (i, j) where i <= j (we only predict right to left links)\n",
        "                pair_mask = torch.arange(0, len(embs), device=self.device)\n",
        "                pair_mask = pair_mask.unsqueeze(1) - pair_mask.unsqueeze(0)\n",
        "                pair_mask = torch.log((pair_mask > 0).to(torch.float))                              # [n_spans, n_spans]\n",
        "\n",
        "                # Coarse coreference scores are obtained as S ⋅ W ⋅ S.T,\n",
        "                #   where S is the matrix of span representations\n",
        "                #   and W is a matrix of trainable weights\n",
        "                # The pair mask is added to the scores to mask the links between undesired positions\n",
        "                coarse_scores = self.coarse_dropout(self.coarse_bilinear(embs)).mm(embs.T)\n",
        "                coarse_scores = pair_mask + coarse_scores                                           # [n_spans, n_spans]\n",
        "\n",
        "                # Top scoring antecedents are taken further for expensive fine span pair scoring\n",
        "                k=min(int(self.k / len(doc.sem_classes)), len(coarse_scores))\n",
        "                top_scores, top_indices = torch.topk(coarse_scores,                                 # [n_spans, n_ants]\n",
        "                                                    # k=min(int(self.k / len(doc.spans_classes) * doc.sem_classes_sizes[sem_class]), len(coarse_scores)),\n",
        "                                                    k,\n",
        "                                                    dim=1, sorted=False)\n",
        "\n",
        "                # print(\"local k = \" + str(self.k))\n",
        "                # print(\"local k = \" + str(k))\n",
        "                # print(\"spans with classes = \" + str(len(doc.spans_classes)))\n",
        "                # print(\"class size = \" + str(doc.sem_classes_sizes[sem_class]))\n",
        "                # print(\"classes count = \" + str(len(doc.sem_classes)))\n",
        "\n",
        "                logging.warning(f\"top scores for {sem_class}: \" + str(top_scores))\n",
        "                logging.warning(f\"top indices for {sem_class}: \" + str(top_indices))\n",
        "\n",
        "                # Fine span pair scoring ########\n",
        "\n",
        "                # Fine scores are obtained by first building the pair matrix: a concatenation of the following:\n",
        "                #   a_spans: embeddings of all spans in the documents\n",
        "                #   b_spans: embeddings of top-k antecedents for each span of the document\n",
        "                #   similarity: element-wise product of a_spans and b_spans\n",
        "                a_spans = embs.unsqueeze(1).expand(embs.shape[0], top_scores.shape[1], embs.shape[1])\n",
        "                b_spans = embs[top_indices]\n",
        "                similarity = a_spans * b_spans\n",
        "                pair_matrix = torch.cat((a_spans, b_spans, similarity), dim=2)                  # [n_spans, n_ants, pair_emb]\n",
        "\n",
        "                # The resulting pair matrix is passed through dense layers\n",
        "                fine_scores = self.fine_linear(pair_matrix).squeeze(2)                          # [n_spans, n_ants]\n",
        "\n",
        "                # Fine scores and coarse scores are added together (important for training)\n",
        "                if all_scores == None:\n",
        "                    all_scores = fine_scores + top_scores\n",
        "                    all_indices = top_indices\n",
        "                else:\n",
        "                    torch.cat((all_scores, fine_scores + top_scores), dim=1)\n",
        "                    torch.cat((all_indices, top_indices), dim=1)\n",
        "\n",
        "            logging.warning(\"all scores: \" + str(all_scores))\n",
        "            logging.warning(\"all indices: \" + str(all_indices))\n",
        "            return all_scores, all_indices\n",
        "        else:\n",
        "            # We transform a matrix of span starts and ends into an [n_spans, n_tokens] boolean mask,\n",
        "            # which for i-th row will have 1 at positions of tokens that are part of the i-th span\n",
        "            spans = torch.tensor(list(doc.all_spans), dtype=torch.long, device=self.device)     # [n_spans, 2]\n",
        "            indices = torch.arange(0, len(embs), device=self.device).unsqueeze(0).expand(len(spans), len(embs))\n",
        "            span_mask = (indices >= spans[:, 0].unsqueeze(1)) * (indices < spans[:, 1].unsqueeze(1))\n",
        "            span_mask = torch.log(span_mask.to(torch.float))\n",
        "            # logging.warning(\"span mask: \" + str(span_mask))\n",
        "\n",
        "            # Each token representation is passed through trainable token importance linear layer\n",
        "            # The obtained scores are then softmaxed for each span\n",
        "            # This way, if a span consists of one token, this token's embeddings will have 1.0 of the weight\n",
        "            # While, for example, for a two-token span with scores of [1.2, 2.6] the weights will be [0.2, 0.8]\n",
        "            token_scores = self.token_importance_linear(embs).squeeze(1)                        # [n_tokens]\n",
        "            token_scores = token_scores.unsqueeze(0).expand(len(spans), len(embs))              # [n_spans, n_tokens]\n",
        "            token_scores = torch.softmax(token_scores + span_mask, dim=1)\n",
        "\n",
        "            # Span representations are obtained as weighted sums of the token representations of the span\n",
        "            embs = token_scores.mm(embs)                                                        # [n_spans, emb]\n",
        "            embs = self.span_dropout(embs)\n",
        "\n",
        "            # Coarse span pair scoring ######\n",
        "\n",
        "            # We set to -inf the scores of all span pairs (i, j) where i <= j (we only predict right to left links)\n",
        "            pair_mask = torch.arange(0, len(embs), device=self.device)\n",
        "            pair_mask = pair_mask.unsqueeze(1) - pair_mask.unsqueeze(0)\n",
        "            pair_mask = torch.log((pair_mask > 0).to(torch.float))                              # [n_spans, n_spans]\n",
        "\n",
        "            # Coarse coreference scores are obtained as S ⋅ W ⋅ S.T,\n",
        "            #   where S is the matrix of span representations\n",
        "            #   and W is a matrix of trainable weights\n",
        "            # The pair mask is added to the scores to mask the links between undesired positions\n",
        "            coarse_scores = self.coarse_dropout(self.coarse_bilinear(embs)).mm(embs.T)\n",
        "            coarse_scores = pair_mask + coarse_scores                                           # [n_spans, n_spans]\n",
        "\n",
        "            # Top scoring antecedents are taken further for expensive fine span pair scoring\n",
        "            top_scores, top_indices = torch.topk(coarse_scores,                                 # [n_spans, n_ants]\n",
        "                                                k=min(self.k, len(coarse_scores)),\n",
        "                                                dim=1, sorted=False)\n",
        "\n",
        "            # Fine span pair scoring ########\n",
        "\n",
        "            # Fine scores are obtained by first building the pair matrix: a concatenation of the following:\n",
        "            #   a_spans: embeddings of all spans in the documents\n",
        "            #   b_spans: embeddings of top-k antecedents for each span of the document\n",
        "            #   similarity: element-wise product of a_spans and b_spans\n",
        "            a_spans = embs.unsqueeze(1).expand(embs.shape[0], top_scores.shape[1], embs.shape[1])\n",
        "            b_spans = embs[top_indices]\n",
        "            similarity = a_spans * b_spans\n",
        "            pair_matrix = torch.cat((a_spans, b_spans, similarity), dim=2)                  # [n_spans, n_ants, pair_emb]\n",
        "\n",
        "            # The resulting pair matrix is passed through dense layers\n",
        "            fine_scores = self.fine_linear(pair_matrix).squeeze(2)                          # [n_spans, n_ants]\n",
        "\n",
        "            # logging.warning(f\"top scores: \" + str(top_scores))\n",
        "            # logging.warning(f\"top indices: \" + str(top_indices))\n",
        "\n",
        "            # Fine scores and coarse scores are added together (important for training)\n",
        "            return fine_scores + top_scores, top_indices\n",
        "\n",
        "    @staticmethod\n",
        "    def lea(a_clusters: List[List[Tuple[int, int]]],\n",
        "            b_clusters: List[List[Tuple[int, int]]]) -> LEAResult:\n",
        "        recall, r_weight = CorefModel._lea(a_clusters, b_clusters)\n",
        "        precision, p_weight = CorefModel._lea(b_clusters, a_clusters)\n",
        "        return LEAResult(precision, p_weight, recall, r_weight)\n",
        "\n",
        "    @staticmethod\n",
        "    def _lea(key: List[List[Tuple[int, int]]],\n",
        "             response: List[List[Tuple[int, int]]]) -> Tuple[float, float]:\n",
        "        \"\"\" See aclweb.org/anthology/P16-1060.pdf. \"\"\"\n",
        "        response_clusters = [set(cluster) for cluster in response]\n",
        "        response_map = {mention: cluster\n",
        "                        for cluster in response_clusters\n",
        "                        for mention in cluster}\n",
        "        importances = []\n",
        "        resolutions = []\n",
        "        for entity in key:\n",
        "            size = len(entity)\n",
        "            if size == 1:  # entities of size 1 are not annotated\n",
        "                continue\n",
        "            importances.append(size)\n",
        "            correct_links = 0\n",
        "            for i in range(size):\n",
        "                for j in range(i + 1, size):\n",
        "                    correct_links += int(entity[i] in response_map.get(entity[j], {}))\n",
        "            resolutions.append(correct_links / (size * (size - 1) / 2))\n",
        "        res = sum(imp * res for imp, res in zip(importances, resolutions))\n",
        "        weight = sum(importances)\n",
        "        return res, weight\n",
        "\n",
        "    def loss(self, doc: Doc, top_scores: torch.Tensor, top_indices: torch.Tensor) -> torch.Tensor:\n",
        "        span2entity = {span: i for i, entity in enumerate(doc.entities, start=1) for span in entity}\n",
        "        entity_ids = torch.tensor([span2entity.get(span, 0) for span in doc.all_spans], device=self.device)\n",
        "\n",
        "        valid_pair_map = (top_scores > float('-inf'))\n",
        "        y = entity_ids[top_indices] * valid_pair_map\n",
        "        y[y == 0] = -1\n",
        "        y = (y == entity_ids.unsqueeze(1))\n",
        "        y = torch.cat((y, torch.full((len(y), 1), False, device=y.device)), dim=1)\n",
        "        y[y.sum(dim=1) == 0, -1] = True\n",
        "        y = y.to(torch.float)  # [n_spans, k + 1]\n",
        "\n",
        "        top_scores = torch.cat((top_scores, torch.zeros((len(top_scores), 1), device=top_scores.device)), dim=1)\n",
        "\n",
        "        gold = torch.logsumexp(top_scores + torch.log(y.to(torch.float)), dim=1)\n",
        "        pred = torch.logsumexp(top_scores, dim=1)\n",
        "        return (pred - gold).mean()\n",
        "\n",
        "    def predict(self, doc: Doc) -> List[List[Tuple[int, int]]]:\n",
        "        top_scores, top_indices = self(doc)\n",
        "        positive_scores = (top_scores > 0).detach().cpu().numpy()\n",
        "        best_ants = top_scores.argmax(dim=1).cpu().numpy()\n",
        "        indices_map = top_indices.cpu().numpy()\n",
        "\n",
        "        spans = list(doc.all_spans)\n",
        "        links = []\n",
        "        for a_idx, b_ant_idx in enumerate(best_ants):\n",
        "            if positive_scores[a_idx, b_ant_idx]:\n",
        "                b_idx = indices_map[a_idx, b_ant_idx]\n",
        "                links.append((spans[a_idx], spans[b_idx]))\n",
        "\n",
        "        span2entity = {}\n",
        "\n",
        "        def get_entity(span: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
        "            if span not in span2entity:\n",
        "                span2entity[span] = [span]\n",
        "            return span2entity[span]\n",
        "\n",
        "        for source, target in links:\n",
        "            source_entity, target_entity = get_entity(source), get_entity(target)\n",
        "            if source_entity is not target_entity:\n",
        "                source_entity.extend(target_entity)\n",
        "                for span in target_entity:\n",
        "                    span2entity[span] = source_entity\n",
        "\n",
        "        ids = set()\n",
        "        entities = []\n",
        "        for entity in span2entity.values():\n",
        "            if id(entity) not in ids:\n",
        "                ids.add(id(entity))\n",
        "                entities.append(entity)\n",
        "\n",
        "        return sorted(sorted(entity) for entity in entities)\n",
        "\n",
        "    def run(self, doc: Doc) -> torch.Tensor:\n",
        "        top_scores, top_indices = self(doc)\n",
        "        return self.loss(doc, top_scores, top_indices)\n",
        "\n",
        "    def training_step(self, batch: List[Doc], batch_idx: int):\n",
        "        if len(batch) > 1:\n",
        "            loss = torch.cat([self.run(doc) for doc in batch]).sum()\n",
        "        else:\n",
        "            loss = self.run(batch[0])\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch: List[Doc], batch_idx: int):\n",
        "        scores = []\n",
        "        for doc in batch:\n",
        "            scores.append(self.lea(self.predict(doc), doc.entities))\n",
        "        return scores\n",
        "\n",
        "    def validation_epoch_end(self, outputs: List[List[LEAResult]]):  # type: ignore[override]\n",
        "        precision = 0.0\n",
        "        precision_weight = 0.0\n",
        "        recall = 0.0\n",
        "        recall_weight = 0.0\n",
        "        for output in outputs:\n",
        "            for result in output:\n",
        "                precision += result.precision\n",
        "                precision_weight += result.precision_weight\n",
        "                recall += result.recall\n",
        "                recall_weight += result.recall_weight\n",
        "\n",
        "        total_precision = precision / (precision_weight + EPS)\n",
        "        total_recall = recall / (recall_weight + EPS)\n",
        "        f1 = (total_precision * total_recall) / (total_precision + total_recall + EPS) * 2\n",
        "        self.log(\"val_lea\", f1)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        coref_parameters = []\n",
        "        for submodule in self.children():\n",
        "            if submodule is not self.encoder:\n",
        "                coref_parameters.extend(submodule.parameters())\n",
        "        return torch.optim.Adam([\n",
        "            {\"params\": self.encoder.parameters(), \"lr\": 1e-5},\n",
        "            {\"params\": coref_parameters, \"lr\": 3e-4}\n",
        "        ])\n",
        "\n",
        "\n",
        "class CorefDocs(torch.utils.data.Dataset):\n",
        "    def __init__(self, path: str, tokenizer: transformers.PreTrainedTokenizerFast):\n",
        "        self.docs = []\n",
        "        for entry in os.scandir(path):\n",
        "            if entry.name.endswith(\".json\"):\n",
        "                with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "                    data = json.load(f, strict=False)\n",
        "                    logging.warning(entry.name)\n",
        "                    # logging.warning(data[\"text\"])\n",
        "                    if len(data[\"text\"]) > 0:\n",
        "                        if data[\"text\"][0] == \" \":\n",
        "                            data[\"text\"] = data[\"text\"].replace(\" \", \"\", 1).replace('\\n', '')\n",
        "                            logging.warning(\"Replace first space\")\n",
        "\n",
        "                    data = json.loads(json.dumps(data).replace('\\\\t', '').replace('\\t', '').replace('\\\\r', '').replace('\\r', '').replace('\\\\0', '').replace('\\0', ''), strict=False)\n",
        "                    # data = json.loads(json.dumps(data), strict=False)\n",
        "\n",
        "                    self.docs.append(Doc(entry.name, data, tokenizer=tokenizer, extract_all_spans=True))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Doc:\n",
        "        return self.docs[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.docs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRxQS9lTzXnl"
      },
      "source": [
        "# Download and split datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuY72HrvPiuR",
        "outputId": "d545addf-5489-4541-8084-0f49c84c04b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170629/4078494547.py:34: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
            "  logging.warn(entry.name)\n",
            "WARNING:root:2017_world_rogozin_008.json\n",
            "WARNING:root:2014_blog_poland.json\n",
            "WARNING:root:2000_russia_minyust.json\n",
            "WARNING:root:2001_world_tonnel_003.json\n",
            "WARNING:root:2003_world_avto_007.json\n",
            "WARNING:root:2007_world_okruashvil_li.json\n",
            "WARNING:root:2002_sport_obman.json\n",
            "WARNING:root:2010_russia_pase.json\n",
            "WARNING:root:2001_world_mig31_usa.json\n",
            "WARNING:root:2018_sport_toxic_003.json\n",
            "WARNING:root:2011_russia_intelsat_001.json\n",
            "WARNING:root:2007_finance_rosfin.json\n",
            "WARNING:root:2016_world_vietnam_004.json\n",
            "WARNING:root:2012_world_beduins_001.json\n",
            "WARNING:root:2020_finance_15_less.json\n",
            "WARNING:root:2003_sport_56473865.json\n",
            "WARNING:root:2014_russia_solovey.json\n",
            "WARNING:root:2000_world_yalta.json\n",
            "WARNING:root:2007_russia_new_004.json\n",
            "WARNING:root:2018_world_saudi_004.json\n",
            "WARNING:root:2009_sport_basket_005.json\n",
            "WARNING:root:2018_world_kremlindossierr.json\n",
            "WARNING:root:2013_realty_sennikov.json\n",
            "WARNING:root:2011_world_gaise.json\n",
            "WARNING:root:2003_sport_65463788654.json\n",
            "WARNING:root:2004_sport_sir_alex.json\n",
            "WARNING:root:2006_world_saparat.json\n",
            "WARNING:root:2019_world_president.json\n",
            "WARNING:root:2018_blog_putin_lenin.json\n",
            "WARNING:root:2017_blog_tgukraine.json\n",
            "WARNING:root:2006_russia_l39.json\n",
            "WARNING:root:2000_sport_asiancup_001.json\n",
            "WARNING:root:2011_sport_semi_001.json\n",
            "WARNING:root:2008_sport_nad_001.json\n",
            "WARNING:root:2017_world_israelsecret.json\n",
            "WARNING:root:2003_world_shuttle_004.json\n",
            "WARNING:root:2015_world_udary_001.json\n",
            "WARNING:root:2010_cinema_goya.json\n",
            "WARNING:root:2014_russia_putinfrance.json\n",
            "WARNING:root:2011_world_japhod.json\n",
            "WARNING:root:2001_russia_primorye.json\n",
            "WARNING:root:2001_russia_6_crash.json\n",
            "WARNING:root:2009_sport_fifa_009.json\n",
            "WARNING:root:2007_world_oprosgeorgia.json\n",
            "WARNING:root:2006_russia_rpzh_001.json\n",
            "WARNING:root:2019_russia_rosgidromet.json\n",
            "WARNING:root:2007_russia_found.json\n",
            "WARNING:root:2012_cinema_semki.json\n",
            "WARNING:root:2014_sport_fedor_002.json\n",
            "WARNING:root:2014_world_free_004.json\n",
            "WARNING:root:2011_auto_Dorogi_duraki.json\n",
            "WARNING:root:2004_world_gripp_021.json\n",
            "WARNING:root:2009_sport_pavlo.json\n",
            "WARNING:root:2016_world_lukoil.json\n",
            "WARNING:root:2003_russia_frankfurt.json\n",
            "WARNING:root:2011_russia_s4astie.json\n",
            "WARNING:root:2016_blog_fsbtrafik.json\n",
            "WARNING:root:2008_cinema_stone_005.json\n",
            "WARNING:root:2012_russia_volkova.json\n",
            "WARNING:root:2003_world_100_bin_laden.json\n",
            "WARNING:root:2008_world_collider_004.json\n",
            "WARNING:root:2010_world_rls.json\n",
            "WARNING:root:2010_sport_dymano.json\n",
            "WARNING:root:2008_realty_lost_interest.json\n",
            "WARNING:root:2018_blog_inoagent.json\n",
            "WARNING:root:2006_russia_grib.json\n",
            "WARNING:root:2002_russia_boi_001.json\n",
            "WARNING:root:2007_world_yazva_002.json\n",
            "WARNING:root:2015_world_ukrmsk.json\n",
            "WARNING:root:2003_russia_troop_train.json\n",
            "WARNING:root:2009_russia_progress_001.json\n",
            "WARNING:root:2002_russia_svyaz.json\n",
            "WARNING:root:2001_finance_gazprom1_001.json\n",
            "WARNING:root:2005_russia_kanidis.json\n",
            "WARNING:root:2019_auto_skodakamiq.json\n",
            "WARNING:root:2013_realty_ebay_ozero.json\n",
            "WARNING:root:2010_realty_mouldy.json\n",
            "WARNING:root:2005_cinema_net_sex.json\n",
            "WARNING:root:2017_russia_doska.json\n",
            "WARNING:root:2016_sport_firestarter_001.json\n",
            "WARNING:root:2001_world_izrael_diplomat.json\n",
            "WARNING:root:2005_world_india_005.json\n",
            "WARNING:root:2011_russia_cards_005.json\n",
            "WARNING:root:2014_world_dnr_list.json\n",
            "WARNING:root:2006_world_geohelp.json\n",
            "WARNING:root:2007_sport_zav.json\n",
            "WARNING:root:2001_russia_ntvzarplata.json\n",
            "WARNING:root:2009_finance_blue_stream_001.json\n",
            "WARNING:root:2003_russia_kolka_002.json\n",
            "WARNING:root:2014_world_gb_cabinet.json\n",
            "WARNING:root:2001_world_palestina2_003.json\n",
            "WARNING:root:2004_sport_5673486432.json\n",
            "WARNING:root:2019_russia_demushkin_001.json\n",
            "WARNING:root:2012_auto_marussia.json\n",
            "WARNING:root:2009_russia_newges.json\n",
            "WARNING:root:2009_world_secretar.json\n",
            "WARNING:root:2009_world_moonturn.json\n",
            "WARNING:root:2008_sport_feder_001.json\n",
            "WARNING:root:2010_russia_elfuture.json\n",
            "WARNING:root:2007_auto_belgium.json\n",
            "WARNING:root:2014_realty_9metres.json\n",
            "WARNING:root:2005_sport_cheater_001.json\n",
            "WARNING:root:2006_russia_georgia.json\n",
            "WARNING:root:2013_hitech_po4ta_002.json\n",
            "WARNING:root:2012_russia_strelba_002.json\n",
            "WARNING:root:2006_russia_end_corruption.json\n",
            "WARNING:root:2005_world_vnuk.json\n",
            "WARNING:root:2014_russia_kadyrov_015.json\n",
            "WARNING:root:2015_auto_corbusier_coup.json\n",
            "WARNING:root:2001_russia_echo_inter.json\n",
            "WARNING:root:2013_hitech_haker_rabota.json\n",
            "WARNING:root:2007_world_vlast_002.json\n",
            "WARNING:root:2010_russia_hodorkovsky_004.json\n",
            "WARNING:root:2006_world_turk_009.json\n",
            "WARNING:root:2002_world_krazha.json\n",
            "WARNING:root:2017_sport_ioc_010.json\n",
            "WARNING:root:2020_russia_vorontzov.json\n",
            "WARNING:root:2018_cinema_stallone_001.json\n",
            "WARNING:root:2001_sport_hardtime.json\n",
            "WARNING:root:2020_russia_still_passport.json\n",
            "WARNING:root:2005_world_quake_007.json\n",
            "WARNING:root:2008_world_dj_002.json\n",
            "WARNING:root:2015_sport_vor.json\n",
            "WARNING:root:2014_realty_greece.json\n",
            "WARNING:root:2009_russia_tvc.json\n",
            "WARNING:root:2010_finance_fiat_001.json\n",
            "WARNING:root:2005_world_hostage_002.json\n",
            "WARNING:root:2019_world_savin_001.json\n",
            "WARNING:root:2004_cinema_alanis.json\n",
            "WARNING:root:2017_world_monk_001.json\n",
            "WARNING:root:2020_russia_dezinf2b.json\n",
            "WARNING:root:2005_cinema_smykov.json\n",
            "WARNING:root:2017_world_lavrov_tillerson_001.json\n",
            "WARNING:root:2016_russia_4urov1.json\n",
            "WARNING:root:2019_russia_egorsmrddin.json\n",
            "WARNING:root:2017_world_venecuelacrida.json\n",
            "WARNING:root:2009_finance_volvo_004.json\n",
            "WARNING:root:2012_world_storshe.json\n",
            "WARNING:root:2002_russia_putin4_001.json\n",
            "WARNING:root:2008_realty_sochi_015.json\n",
            "WARNING:root:2014_auto_cheapest.json\n",
            "WARNING:root:2013_russia_licedei_003.json\n",
            "WARNING:root:2007_russia_moscow_012.json\n",
            "WARNING:root:2010_hitech_ebaycourt.json\n",
            "WARNING:root:2001_russia_fire_011.json\n",
            "WARNING:root:2020_russia_shaved_obysk.json\n",
            "WARNING:root:2011_finance_auto_japan_001.json\n",
            "WARNING:root:2015_sport_bros.json\n",
            "WARNING:root:2016_russia_lesin_002.json\n",
            "WARNING:root:2005_russia_ciklon_001.json\n",
            "WARNING:root:2005_world_trams.json\n",
            "WARNING:root:2015_realty_btb_anel.json\n",
            "WARNING:root:2007_russia_perm_006.json\n",
            "WARNING:root:2011_auto_averbuh.json\n",
            "WARNING:root:2011_realty_auctions.json\n",
            "WARNING:root:2010_finance_banki_009.json\n",
            "WARNING:root:2011_world_istanbul_001.json\n",
            "WARNING:root:2006_russia_plane.json\n",
            "WARNING:root:2003_sport_euroleague.json\n",
            "WARNING:root:2015_finance_trustbank_001.json\n",
            "WARNING:root:2000_world_bahrein_001.json\n",
            "WARNING:root:2005_cinema_efimov.json\n",
            "WARNING:root:2002_russia_africa.json\n",
            "WARNING:root:2001_world_virgo_3.json\n",
            "WARNING:root:2004_russia_trepashkin.json\n",
            "WARNING:root:2010_world_okin.json\n",
            "WARNING:root:2014_cinema_gaft_003.json\n",
            "WARNING:root:2012_russia_panova_001.json\n",
            "WARNING:root:2008_world_peraty.json\n",
            "WARNING:root:2016_auto_don_228.json\n",
            "WARNING:root:2016_sport_friendly_006.json\n",
            "WARNING:root:2014_world_maliki.json\n",
            "WARNING:root:2003_sport_5738675654.json\n",
            "WARNING:root:2015_world_iran_030.json\n",
            "WARNING:root:2003_russia_nepal.json\n",
            "WARNING:root:2009_world_laureat_001.json\n",
            "WARNING:root:2017_auto_tesla_002.json\n",
            "WARNING:root:2001_world_most_019.json\n",
            "WARNING:root:2007_auto_sf_001.json\n",
            "WARNING:root:2013_russia_bulavaminus.json\n",
            "WARNING:root:2010_auto_poshlini_2303.json\n",
            "WARNING:root:2007_russia_elections_001.json\n",
            "WARNING:root:2011_russia_bulava1.json\n",
            "WARNING:root:2014_world_lysenko.json\n",
            "WARNING:root:2015_sport_atl_003.json\n",
            "WARNING:root:2014_russia_chubais_001.json\n",
            "WARNING:root:2004_russia_progny_046.json\n",
            "WARNING:root:2017_realty_kings2017_001.json\n",
            "WARNING:root:2016_sport_torpedo.json\n",
            "WARNING:root:2009_world_medvedvrime.json\n",
            "WARNING:root:2009_russia_dtp5.json\n",
            "WARNING:root:2006_cinema_jacko_016.json\n",
            "WARNING:root:2001_finance_chubaisusa.json\n",
            "WARNING:root:2008_world_pro_024.json\n",
            "WARNING:root:2009_sport_tima_002.json\n",
            "WARNING:root:2013_russia_an.json\n",
            "WARNING:root:2015_finance_auchanwaste.json\n",
            "WARNING:root:2011_finance_china_005.json\n",
            "WARNING:root:2002_world_kuchma2_003.json\n",
            "WARNING:root:2011_world_deboshiry2.json\n",
            "WARNING:root:2002_sport_sokolovaruschamp.json\n",
            "WARNING:root:2008_auto_10-euro.json\n",
            "WARNING:root:2013_russia_kadirov.json\n",
            "WARNING:root:2017_realty_vvod_001.json\n",
            "WARNING:root:2011_realty_bitza_001.json\n",
            "WARNING:root:2010_world_kirgizija_002.json\n",
            "WARNING:root:2009_finance_prom.json\n",
            "WARNING:root:2008_world_uskov_004.json\n",
            "WARNING:root:2006_world_karlos.json\n",
            "WARNING:root:2015_hitech_googlespb.json\n",
            "WARNING:root:2006_finance_wto_003.json\n",
            "WARNING:root:2011_sport_cskaperm.json\n",
            "WARNING:root:2020_world_palermo_001.json\n",
            "WARNING:root:2012_sport_idiot_002.json\n",
            "WARNING:root:2018_sport_juventus.json\n",
            "WARNING:root:2001_sport_diegobokahuniors.json\n",
            "WARNING:root:2005_world_namek.json\n",
            "WARNING:root:2005_russia_soldat_002.json\n",
            "WARNING:root:2002_cinema_britney_003.json\n",
            "WARNING:root:2017_sport_igor_003.json\n",
            "WARNING:root:2013_sport_kozak_001.json\n",
            "WARNING:root:2015_world_poroshenko_006.json\n",
            "WARNING:root:2018_world_trumpfbi.json\n",
            "WARNING:root:2016_russia_mosmetroshot2.json\n",
            "WARNING:root:2013_finance_tungiang.json\n",
            "WARNING:root:2004_russia_progny_025.json\n",
            "WARNING:root:2014_world_secbody.json\n",
            "WARNING:root:2009_russia_bodrunov_001.json\n",
            "WARNING:root:2011_sport_vote_003.json\n",
            "WARNING:root:2011_russia_pod_em.json\n",
            "WARNING:root:2001_world_mitteran.json\n",
            "WARNING:root:2014_cinema_exrector.json\n",
            "WARNING:root:2015_world_islamic_001.json\n",
            "WARNING:root:2002_russia_forigners.json\n",
            "WARNING:root:2003_world_war_004.json\n",
            "WARNING:root:2018_hitech_yarovaya_rspp.json\n",
            "WARNING:root:2011_russia_rusoil.json\n",
            "WARNING:root:2020_auto_tesla_aust.json\n",
            "WARNING:root:2010_world_again.json\n",
            "WARNING:root:2010_russia_spisok_004.json\n",
            "WARNING:root:2011_sport_zayka_004.json\n",
            "WARNING:root:2018_russia_soyuz_003.json\n",
            "WARNING:root:2014_world_suda.json\n",
            "WARNING:root:2016_hitech_flexcamera.json\n",
            "WARNING:root:2012_world_8dollars.json\n",
            "WARNING:root:2020_blog_no_food.json\n",
            "WARNING:root:2004_sport_czar.json\n",
            "WARNING:root:2007_sport_legal_pro.json\n",
            "WARNING:root:2006_russia_ivanov_008.json\n",
            "WARNING:root:2018_russia_guber_004.json\n",
            "WARNING:root:2012_world_afg_002.json\n",
            "WARNING:root:2010_world_otbili.json\n",
            "WARNING:root:2006_russia_sen_002.json\n",
            "WARNING:root:2013_blog_rusofob.json\n",
            "WARNING:root:2007_world_bushcoldwarxxi.json\n",
            "WARNING:root:2002_finance_int.json\n",
            "WARNING:root:2001_russia_ugroza_001.json\n",
            "WARNING:root:2014_finance_rugovcntrldcmpnsspndngs.json\n",
            "WARNING:root:2011_hitech_brinwikimoney.json\n",
            "WARNING:root:2019_russia_cemax_dopros.json\n",
            "WARNING:root:2014_world_dobkin_001.json\n",
            "WARNING:root:2012_world_kodirov.json\n",
            "WARNING:root:2016_russia_tigers.json\n",
            "WARNING:root:2009_hitech_nosocnets.json\n",
            "WARNING:root:2010_world_mars_007.json\n",
            "WARNING:root:2007_world_pro_discussion.json\n",
            "WARNING:root:2010_russia_lager_001.json\n",
            "WARNING:root:2001_finance_opec_cuts_001.json\n",
            "WARNING:root:2017_world_talks_003.json\n",
            "WARNING:root:2017_russia_donbasspeskov.json\n",
            "WARNING:root:2003_russia_lacisa.json\n",
            "WARNING:root:2007_world_ytonyli.json\n",
            "WARNING:root:2017_russia_mamaev_003.json\n",
            "WARNING:root:2011_world_2nlo.json\n",
            "WARNING:root:2008_finance_ukraina_002.json\n",
            "WARNING:root:2013_russia_domodedovo_009.json\n",
            "WARNING:root:2008_finance_udokan.json\n",
            "WARNING:root:2003_finance_shancev2.json\n",
            "WARNING:root:2009_finance_rubl10.json\n",
            "WARNING:root:2007_world_vgaze.json\n",
            "WARNING:root:2008_sport_horse_004.json\n",
            "WARNING:root:2009_sport_swe_001.json\n",
            "WARNING:root:2004_world_crush.json\n",
            "WARNING:root:2020_blog_rus_covid.json\n",
            "WARNING:root:2012_sport_romulo_001.json\n",
            "WARNING:root:2016_russia_foreignaffairs.json\n",
            "WARNING:root:2011_russia_senator.json\n",
            "WARNING:root:2009_world_arson.json\n",
            "WARNING:root:2005_world_abramovich_012.json\n",
            "WARNING:root:2007_russia_bus_002.json\n",
            "WARNING:root:2002_russia_bodrov_005.json\n",
            "WARNING:root:2005_sport_ski_002.json\n",
            "WARNING:root:2017_sport_rubzen.json\n",
            "WARNING:root:2005_russia_sudforbs.json\n",
            "WARNING:root:2013_blog_zabastovka2.json\n",
            "WARNING:root:2015_hitech_mstore.json\n",
            "WARNING:root:2019_sport_amanda_001.json\n",
            "WARNING:root:2010_world_kuvalda_001.json\n",
            "WARNING:root:2007_russia_worry_001.json\n",
            "WARNING:root:2005_finance_yuk_014.json\n",
            "WARNING:root:2004_world_turok.json\n",
            "WARNING:root:2012_cinema_water.json\n",
            "WARNING:root:2017_auto_tesla_1.json\n",
            "WARNING:root:2014_finance_rugrumanachos.json\n",
            "WARNING:root:2008_world_soglasen.json\n",
            "WARNING:root:2016_realty_novaya_ocenka.json\n",
            "WARNING:root:2017_hitech_aquila2.json\n",
            "WARNING:root:2005_finance_india.json\n",
            "WARNING:root:2003_russia_clash.json\n",
            "WARNING:root:2021_world_bidenvstrump.json\n",
            "WARNING:root:2007_russia_emiraty.json\n",
            "WARNING:root:2007_cinema_tv_002.json\n",
            "WARNING:root:2004_world_az_zarkawi.json\n",
            "WARNING:root:2002_sport_ligachampreal.json\n",
            "WARNING:root:2011_russia_mah.json\n",
            "WARNING:root:2003_cinema_shakespeare.json\n",
            "WARNING:root:2017_auto_gospod.json\n",
            "WARNING:root:2003_russia_kjh_002.json\n",
            "WARNING:root:2014_auto_gibddzebra.json\n",
            "WARNING:root:2008_finance_dodna.json\n",
            "WARNING:root:2011_auto_voditeli_001.json\n",
            "WARNING:root:2012_realty_Eurovegas_001.json\n",
            "WARNING:root:2014_world_greek_001.json\n",
            "WARNING:root:2014_world_bangladesh_001.json\n",
            "WARNING:root:2021_russia_ekb5g.json\n",
            "WARNING:root:2015_cinema_kand.json\n",
            "WARNING:root:2017_sport_masha_020.json\n",
            "WARNING:root:2004_sport_65656776756554.json\n",
            "WARNING:root:2004_world_gwinea.json\n",
            "WARNING:root:2007_world_shve.json\n",
            "WARNING:root:2008_realty_investments_004.json\n",
            "WARNING:root:2016_realty_pentagonal_mart.json\n",
            "WARNING:root:2007_cinema_richards_001.json\n",
            "WARNING:root:2018_hitech_dwarfcomp.json\n",
            "WARNING:root:2010_auto_cajun.json\n",
            "WARNING:root:2014_cinema_leviathanmedin.json\n",
            "WARNING:root:2017_russia_navalny_065.json\n",
            "WARNING:root:2009_world_voz_001.json\n",
            "WARNING:root:2012_world_gambia_001.json\n",
            "WARNING:root:2015_world_sbu_005.json\n",
            "WARNING:root:2018_sport_clash.json\n",
            "WARNING:root:2000_russia_japan_005.json\n",
            "WARNING:root:2002_world_boeing_017.json\n",
            "WARNING:root:2009_auto_genesis_002.json\n",
            "WARNING:root:2014_blog_pushkin_001.json\n",
            "WARNING:root:2008_cinema_exhibition_001.json\n",
            "WARNING:root:2003_world_informants.json\n",
            "WARNING:root:2001_finance_sovet_001.json\n",
            "WARNING:root:2018_blog_rkn_navalny.json\n",
            "WARNING:root:2018_world_buchenkov.json\n",
            "WARNING:root:2003_russia_dagestan_003.json\n",
            "WARNING:root:2014_world_kerry1.json\n",
            "WARNING:root:2017_finance_program.json\n",
            "WARNING:root:2017_russia_krasnov.json\n",
            "WARNING:root:2006_finance_naftogazbak.json\n",
            "WARNING:root:2016_hitech_network.json\n",
            "WARNING:root:2010_russia_putin_044.json\n",
            "WARNING:root:2011_sport_prjad.json\n",
            "WARNING:root:2010_cinema_biberama.json\n",
            "WARNING:root:2011_world_bolen.json\n",
            "WARNING:root:2017_auto_platon_straf.json\n",
            "WARNING:root:2006_world_pate.json\n",
            "WARNING:root:2014_sport_bored.json\n",
            "WARNING:root:2002_sport_iskprotivokr.json\n",
            "WARNING:root:2020_realty_mutko_002.json\n",
            "WARNING:root:2011_russia_udal3.json\n",
            "WARNING:root:2016_russia_golodovka_001.json\n",
            "WARNING:root:2007_hitech_rolly.json\n",
            "WARNING:root:2019_world_helicopter.json\n",
            "WARNING:root:2010_hitech_uscourtgps.json\n",
            "WARNING:root:2002_world_stena_003.json\n",
            "WARNING:root:2001_russia_primakov1.json\n",
            "WARNING:root:2005_sport_zidan_001.json\n",
            "WARNING:root:2007_realty_sochi_007.json\n",
            "WARNING:root:2010_russia_pdd_005.json\n",
            "WARNING:root:2016_russia_putinmedia.json\n",
            "WARNING:root:2015_world_heli.json\n",
            "WARNING:root:2013_realty_israel_004.json\n",
            "WARNING:root:2011_finance_vto.json\n",
            "WARNING:root:2014_finance_rugovslr.json\n",
            "WARNING:root:2006_russia_zapov.json\n",
            "WARNING:root:2013_world_polon_005.json\n",
            "WARNING:root:2009_auto_osago.json\n",
            "WARNING:root:2016_world_charliehebdo_002.json\n",
            "WARNING:root:2011_hitech_Chelyaba.json\n",
            "WARNING:root:2016_russia_dod2.json\n",
            "WARNING:root:2014_world_thewall.json\n",
            "WARNING:root:2008_russia_airunion_prok.json\n",
            "WARNING:root:2011_finance_lotto.json\n",
            "WARNING:root:2016_finance_rststats.json\n",
            "WARNING:root:2002_sport_uefaanticonfed.json\n",
            "WARNING:root:2006_finance_otmyv_001.json\n",
            "WARNING:root:2015_world_doumastrike.json\n",
            "WARNING:root:2014_sport_atl.json\n",
            "WARNING:root:2002_world_peregovory_004.json\n",
            "WARNING:root:2002_world_germany_004.json\n",
            "WARNING:root:2013_russia_yars.json\n",
            "WARNING:root:2004_finance_flats_008.json\n",
            "WARNING:root:2005_world_pase_006.json\n",
            "WARNING:root:2013_cinema_gmiinew.json\n",
            "WARNING:root:2013_russia_koma.json\n",
            "WARNING:root:2013_world_india_008.json\n",
            "WARNING:root:2007_world_melnik_003.json\n",
            "WARNING:root:2004_world_pokush_001.json\n",
            "WARNING:root:2004_russia_nevzlin_006.json\n",
            "WARNING:root:2014_world_gepa.json\n",
            "WARNING:root:2011_world_palest_001.json\n",
            "WARNING:root:2001_world_afganistan2_002.json\n",
            "WARNING:root:2018_hitech_atlas.json\n",
            "WARNING:root:2020_hitech_proteus.json\n",
            "WARNING:root:2014_world_poroshen.json\n",
            "WARNING:root:2004_sport_scolrecap.json\n",
            "WARNING:root:2009_finance_goscorg.json\n",
            "WARNING:root:2015_russia_chirikova.json\n",
            "WARNING:root:2004_world_konkurs_002.json\n",
            "WARNING:root:2004_world_iraq_026.json\n",
            "WARNING:root:2017_russia_ostryakov.json\n",
            "WARNING:root:2011_world_belor_002.json\n",
            "WARNING:root:2020_russia_vorontzov_004.json\n",
            "WARNING:root:2002_sport_339874904.json\n",
            "WARNING:root:2002_russia_vkdraka.json\n",
            "WARNING:root:2013_auto_logan_500th.json\n",
            "WARNING:root:2009_russia_pikcet.json\n",
            "WARNING:root:2008_world_huragane.json\n",
            "WARNING:root:2003_sport_russborna.json\n",
            "WARNING:root:2015_world_mortarweddingafg.json\n",
            "WARNING:root:2019_world_keramic.json\n",
            "WARNING:root:2006_world_hostage_001.json\n",
            "WARNING:root:2014_blog_avtomat_002.json\n",
            "WARNING:root:2009_russia_housofluv.json\n",
            "WARNING:root:2006_russia_nazboly.json\n",
            "WARNING:root:2012_world_premiertour.json\n",
            "WARNING:root:2001_finance_taxes.json\n",
            "WARNING:root:2018_russia_metallolom.json\n",
            "WARNING:root:2004_world_retiredtb.json\n",
            "WARNING:root:2002_finance_odds.json\n",
            "WARNING:root:2018_russia_kozak_001.json\n",
            "WARNING:root:2010_russia_tornadoheat.json\n",
            "WARNING:root:2016_cinema_yankovsky.json\n",
            "WARNING:root:2002_world_iraq_dosie.json\n",
            "WARNING:root:2001_world_turovereact.json\n",
            "WARNING:root:2014_finance_rublackseagas.json\n",
            "WARNING:root:2007_world_dinner.json\n",
            "WARNING:root:2007_finance_obrazovanie.json\n",
            "WARNING:root:2011_russia_okr_001.json\n",
            "WARNING:root:2011_sport_tvent.json\n",
            "WARNING:root:2012_cinema_tyler_001.json\n",
            "WARNING:root:2007_russia_dtp44.json\n",
            "WARNING:root:2008_russia_bakhmina.json\n",
            "WARNING:root:2015_russia_samara_002.json\n",
            "WARNING:root:2011_russia_gannushkina.json\n",
            "WARNING:root:2003_russia_am.json\n",
            "WARNING:root:2006_russia_opos.json\n",
            "WARNING:root:2020_russia_restaurants_checkin.json\n",
            "WARNING:root:2006_russia_busher_001.json\n",
            "WARNING:root:2011_russia_podolskfight.json\n",
            "WARNING:root:2017_russia_serb_005.json\n",
            "WARNING:root:2014_cinema_oscarauct.json\n",
            "WARNING:root:2014_cinema_meriditih.json\n",
            "WARNING:root:2005_world_sharon_019.json\n",
            "WARNING:root:2005_world_robot_006.json\n",
            "WARNING:root:2016_russia_conflictboeing.json\n",
            "WARNING:root:2003_finance_dollar_035.json\n",
            "WARNING:root:2005_world_terror_013.json\n",
            "WARNING:root:2008_world_chopper.json\n",
            "WARNING:root:2013_russia_dress.json\n",
            "WARNING:root:2013_russia_lebedev_007.json\n",
            "WARNING:root:2008_russia_kadyrov_006.json\n",
            "WARNING:root:2011_auto_ocean.json\n",
            "WARNING:root:2009_finance_europe_004.json\n",
            "WARNING:root:2017_russia_fondsud.json\n",
            "WARNING:root:2013_blog_astahov_001.json\n",
            "WARNING:root:2001_world_terakt_israel.json\n",
            "WARNING:root:2007_finance_china_013.json\n",
            "WARNING:root:2017_hitech_intball.json\n",
            "WARNING:root:2016_cinema_mattre.json\n",
            "WARNING:root:2020_russia_maslyaeva.json\n",
            "WARNING:root:2011_finance_dollar_up_036.json\n",
            "WARNING:root:2003_sport_574889754.json\n",
            "WARNING:root:2001_sport_mcenroebacker.json\n",
            "WARNING:root:2012_russia_lukyanov.json\n",
            "WARNING:root:2010_world_azerb_001.json\n",
            "WARNING:root:2002_world_gavel.json\n",
            "WARNING:root:2014_world_usa_022.json\n",
            "WARNING:root:2000_world_summingup_001.json\n",
            "WARNING:root:2015_russia_kur.json\n",
            "WARNING:root:2008_russia_lebed.json\n",
            "WARNING:root:2014_world_tsarnaev.json\n",
            "WARNING:root:2014_cinema_kndrkino.json\n",
            "WARNING:root:2010_world_chs.json\n",
            "WARNING:root:2016_world_u2crash.json\n",
            "WARNING:root:2014_sport_miura.json\n",
            "WARNING:root:2007_world_embargo.json\n",
            "WARNING:root:2001_finance_zurab_002.json\n",
            "WARNING:root:2002_cinema_vysotskij.json\n",
            "WARNING:root:2003_russia_viz.json\n",
            "WARNING:root:2013_russia_pussy_futbolky.json\n",
            "WARNING:root:2002_sport_8497349323.json\n",
            "WARNING:root:2020_russia_police_immune.json\n",
            "WARNING:root:2021_finance_goldvisa.json\n",
            "WARNING:root:2008_auto_romeo_005.json\n",
            "WARNING:root:2015_sport_kamaz_011.json\n",
            "WARNING:root:2015_blog_tarif.json\n",
            "WARNING:root:2007_russia_mashuk.json\n",
            "WARNING:root:2002_russia_basaev_003.json\n",
            "WARNING:root:2015_auto_audi_price.json\n",
            "WARNING:root:2007_russia_solg.json\n",
            "WARNING:root:2008_world_brown_007.json\n",
            "WARNING:root:2017_world_sadr.json\n",
            "WARNING:root:2019_sport_nika.json\n",
            "WARNING:root:2011_finance_vzyatky.json\n",
            "WARNING:root:2011_world_dvc.json\n",
            "WARNING:root:2011_auto_aircar.json\n",
            "WARNING:root:2010_russia_noklon.json\n",
            "WARNING:root:2003_sport_russborn_004.json\n",
            "WARNING:root:2004_russia_zapusk.json\n",
            "WARNING:root:2016_realty_saudprince.json\n",
            "WARNING:root:2003_world_shpir.json\n",
            "WARNING:root:2006_finance_baza.json\n",
            "WARNING:root:2002_world_doklad.json\n",
            "WARNING:root:2004_russia_domknigi.json\n",
            "WARNING:root:2004_russia_wanted_001.json\n",
            "WARNING:root:2010_world_gosling.json\n",
            "WARNING:root:2009_auto_videlennaya.json\n",
            "WARNING:root:2006_finance_avia67.json\n",
            "WARNING:root:2006_cinema_island.json\n",
            "WARNING:root:2018_hitech_5gsouthkorea.json\n",
            "WARNING:root:2014_sport_kvart.json\n",
            "WARNING:root:2017_sport_fancity.json\n",
            "WARNING:root:2014_world_slavyanskobzon.json\n",
            "WARNING:root:2009_sport_det_009.json\n",
            "WARNING:root:2008_russia_mkad_005.json\n",
            "WARNING:root:2014_sport_grad_002.json\n",
            "WARNING:root:2002_russia_kraz.json\n",
            "WARNING:root:2010_finance_lebedev_004.json\n",
            "WARNING:root:2003_russia_posl.json\n",
            "WARNING:root:2004_world_keks_003.json\n",
            "WARNING:root:2002_russia_chech_016.json\n",
            "WARNING:root:2010_russia_aslan.json\n",
            "WARNING:root:2013_auto_new_ds9.json\n",
            "WARNING:root:2017_world_ams.json\n",
            "WARNING:root:2014_hitech_ya_blogs.json\n",
            "WARNING:root:2010_cinema_downfilm.json\n",
            "WARNING:root:2013_sport_lebedev_028.json\n",
            "WARNING:root:2011_russia_kam4atka.json\n",
            "WARNING:root:2020_russia_belo_unite.json\n",
            "WARNING:root:2017_world_kennedy4.json\n",
            "WARNING:root:2011_world_parents_001.json\n",
            "WARNING:root:2010_world_usamks.json\n",
            "WARNING:root:2008_world_uzhin.json\n",
            "WARNING:root:2014_world_canada_008.json\n",
            "WARNING:root:2016_world_kanlizacia.json\n",
            "WARNING:root:2016_sport_roma_007.json\n",
            "WARNING:root:2002_cinema_rerikh.json\n",
            "WARNING:root:2004_russia_monino.json\n",
            "WARNING:root:2007_sport_esebio.json\n",
            "WARNING:root:2016_cinema_atamb_001.json\n",
            "WARNING:root:2012_auto_mustang.json\n",
            "WARNING:root:2002_world_total_eclipse.json\n",
            "WARNING:root:2019_sport_euro_001.json\n",
            "WARNING:root:2018_finance_vtbmagnit.json\n",
            "WARNING:root:2017_blog_churkin3.json\n",
            "WARNING:root:2008_world_faceoff.json\n",
            "WARNING:root:2006_world_ukraina.json\n",
            "WARNING:root:2003_world_trainiraq.json\n",
            "WARNING:root:2010_world_obams.json\n",
            "WARNING:root:2007_russia_lis.json\n",
            "WARNING:root:2013_russia_chirkin_1.json\n",
            "WARNING:root:2008_cinema_terner.json\n",
            "WARNING:root:2011_world_temporarily.json\n",
            "WARNING:root:2014_blog_reforma_002.json\n",
            "WARNING:root:2015_world_bergdahl.json\n",
            "WARNING:root:2013_auto_007_submarine.json\n",
            "WARNING:root:2003_finance_mongol.json\n",
            "WARNING:root:2015_finance_rulaparexlawsuit.json\n",
            "WARNING:root:2011_russia_chuvashov.json\n",
            "WARNING:root:2011_world_aliev_004.json\n",
            "WARNING:root:2021_hitech_amazon_icon.json\n",
            "WARNING:root:2019_hitech_twitter_001.json\n",
            "WARNING:root:2005_world_su_010.json\n",
            "WARNING:root:2000_world_terrorism_006.json\n",
            "WARNING:root:2017_auto_st_bagazhnik.json\n",
            "WARNING:root:2007_russia_vinoven.json\n",
            "WARNING:root:2012_auto_auditts.json\n",
            "WARNING:root:2020_world_biden_wins.json\n",
            "WARNING:root:2013_realty_hong_kong.json\n",
            "WARNING:root:2011_russia_parnas_meeting.json\n",
            "WARNING:root:2003_world_talks_003.json\n",
            "WARNING:root:2004_sport_portlead.json\n",
            "WARNING:root:2001_russia_korz_otv.json\n",
            "WARNING:root:2015_sport_ship_005.json\n",
            "WARNING:root:2017_sport_bottas.json\n",
            "WARNING:root:2007_world_azerjour.json\n",
            "WARNING:root:2015_world_rulist.json\n",
            "WARNING:root:2009_russia_court_011.json\n",
            "WARNING:root:2006_world_abramoff_001.json\n",
            "WARNING:root:2010_world_hamburg_002.json\n",
            "WARNING:root:2002_finance_esr.json\n",
            "WARNING:root:2012_blog_social.json\n",
            "WARNING:root:2016_world_warning_001.json\n",
            "WARNING:root:2002_world_pankisskoe_001.json\n",
            "WARNING:root:2012_russia_bike.json\n",
            "WARNING:root:2012_world_plagiat_002.json\n",
            "WARNING:root:2009_russia_zhirarrest.json\n",
            "WARNING:root:2005_russia_army_006.json\n",
            "WARNING:root:2008_russia_mitvol_005.json\n",
            "WARNING:root:2014_world_ugor.json\n",
            "WARNING:root:2001_world_us_freehtestimony.json\n",
            "WARNING:root:2015_finance_russiangas.json\n",
            "WARNING:root:2009_world_nigeria_006.json\n",
            "WARNING:root:2019_russia_candy.json\n",
            "WARNING:root:2010_world_sad_004.json\n",
            "WARNING:root:2006_russia_vypusk.json\n",
            "WARNING:root:2012_finance_world_oil.json\n",
            "WARNING:root:2007_russia_korrupt_002.json\n",
            "WARNING:root:2014_russia_ufa_005.json\n",
            "WARNING:root:2010_auto_bmw-1.json\n",
            "WARNING:root:2017_world_tu95jp.json\n",
            "WARNING:root:2004_sport_673489787674.json\n",
            "WARNING:root:2014_russia_most_008.json\n",
            "WARNING:root:2013_cinema_chitayut.json\n",
            "WARNING:root:2007_russia_kidnap.json\n",
            "WARNING:root:2017_russia_cheb.json\n",
            "WARNING:root:2010_russia_umarov_002.json\n",
            "WARNING:root:2017_world_imagesat.json\n",
            "WARNING:root:2007_sport_chep_001.json\n",
            "WARNING:root:2021_russia_golubkin.json\n",
            "WARNING:root:2003_world_6killed.json\n",
            "WARNING:root:2015_russia_lavrkunders.json\n",
            "WARNING:root:2013_world_birdflu_002.json\n",
            "WARNING:root:2014_blog_vrachi_003.json\n",
            "WARNING:root:2003_finance_oil_030.json\n",
            "WARNING:root:2006_world_iran_054.json\n",
            "WARNING:root:2006_world_mason.json\n",
            "WARNING:root:2010_russia_detdom_003.json\n",
            "WARNING:root:2009_sport_zicsem.json\n",
            "WARNING:root:2018_sport_masha_009.json\n",
            "WARNING:root:2009_realty_frogs_001.json\n",
            "WARNING:root:2007_world_kirg_005.json\n",
            "WARNING:root:2021_russia_budget_pobeda.json\n",
            "WARNING:root:2002_world_skand.json\n",
            "WARNING:root:2011_russia_kprf_meeting.json\n",
            "WARNING:root:2000_russia_landing.json\n",
            "WARNING:root:2010_finance_sng_001.json\n",
            "WARNING:root:2015_world_merkel_023.json\n",
            "WARNING:root:2020_hitech_udalenka_002.json\n",
            "WARNING:root:2009_russia_avto_011.json\n",
            "WARNING:root:2001_world_ntv_germanyreax.json\n",
            "WARNING:root:2012_russia_duhi.json\n",
            "WARNING:root:2017_world_mh17_003.json\n",
            "WARNING:root:2009_sport_cska_018.json\n",
            "WARNING:root:2014_finance_agroprogrm.json\n",
            "WARNING:root:2017_russia_yakutsk.json\n",
            "WARNING:root:2015_finance_rosneft_001.json\n",
            "WARNING:root:2004_finance_usaf_003.json\n",
            "WARNING:root:2017_world_gallup.json\n",
            "WARNING:root:2003_world_auto_035.json\n",
            "WARNING:root:2011_sport_felix_001.json\n",
            "WARNING:root:2007_russia_less.json\n",
            "WARNING:root:2004_world_vert_017.json\n",
            "WARNING:root:2010_cinema_gaga_002.json\n",
            "WARNING:root:2009_hitech_railetickets2.json\n",
            "WARNING:root:2004_world_ten.json\n",
            "WARNING:root:2003_russia_granata_005.json\n",
            "WARNING:root:2009_russia_suic.json\n",
            "WARNING:root:2001_world_klonirovanie_001.json\n",
            "WARNING:root:2016_finance_nomoreextras.json\n",
            "WARNING:root:2008_russia_nurgal.json\n",
            "WARNING:root:2008_world_ind_flood.json\n",
            "WARNING:root:2014_hitech_library.json\n",
            "WARNING:root:2009_world_ira_003.json\n",
            "WARNING:root:2007_world_elections_016.json\n",
            "WARNING:root:2006_cinema_gora_005.json\n",
            "WARNING:root:2012_cinema_michelj.json\n",
            "WARNING:root:2021_sport_spadin.json\n",
            "WARNING:root:2017_finance_rudeposit.json\n",
            "WARNING:root:2011_world_ipad_002.json\n",
            "WARNING:root:2009_sport_dima.json\n",
            "WARNING:root:2017_realty_passport_ussr.json\n",
            "WARNING:root:2005_russia_vybor_001.json\n",
            "WARNING:root:2020_blog_mishustin_002.json\n",
            "WARNING:root:2002_world_sher_009.json\n",
            "WARNING:root:2004_russia_dvoe.json\n",
            "WARNING:root:2011_russia_ege_005.json\n",
            "WARNING:root:2018_sport_usik_001.json\n",
            "WARNING:root:2005_sport_travel.json\n",
            "WARNING:root:2000_sport_maskaev.json\n",
            "WARNING:root:2002_world_ira_001.json\n",
            "WARNING:root:2008_cinema_beyonce_001.json\n",
            "WARNING:root:2004_world_newdata2.json\n",
            "WARNING:root:2007_world_pari_001.json\n",
            "WARNING:root:2019_blog_maskarad.json\n",
            "WARNING:root:2013_sport_kozel_001.json\n",
            "WARNING:root:2006_sport_drw.json\n",
            "WARNING:root:2000_sport_fiuty.json\n",
            "WARNING:root:2014_russia_putinukr_001.json\n",
            "WARNING:root:2010_cinema_karpov.json\n",
            "WARNING:root:2008_auto_dr.json\n",
            "WARNING:root:2006_russia_pseudo.json\n",
            "WARNING:root:2014_world_zeman_003.json\n",
            "WARNING:root:2012_russia_pozner_007.json\n",
            "WARNING:root:2012_russia_kavkazinet.json\n",
            "WARNING:root:2017_russia_subbotnik_001.json\n",
            "WARNING:root:2007_russia_yakunin_001.json\n",
            "WARNING:root:2013_russia_kuznetsov_003.json\n",
            "WARNING:root:2020_sport_cool.json\n",
            "WARNING:root:2011_russia_surkov_010.json\n",
            "WARNING:root:2011_world_justfishmen.json\n",
            "WARNING:root:2009_world_crocodiles.json\n",
            "WARNING:root:2002_finance_hp_003.json\n",
            "WARNING:root:2010_world_newplanets.json\n",
            "WARNING:root:2003_russia_tourists.json\n",
            "WARNING:root:2003_world_pyatno_001.json\n",
            "WARNING:root:2007_russia_snr.json\n",
            "WARNING:root:2017_auto_toomuchmoney.json\n",
            "WARNING:root:2002_world_fire_074.json\n",
            "WARNING:root:2012_finance_dollar_down_049.json\n",
            "WARNING:root:2001_russia_chech_009.json\n",
            "WARNING:root:2014_russia_vnukovo_004.json\n",
            "WARNING:root:2012_world_eurohostages.json\n",
            "WARNING:root:2008_sport_tre_001.json\n",
            "WARNING:root:2008_world_samolet_012.json\n",
            "WARNING:root:2008_world_22z.json\n",
            "WARNING:root:2012_finance_nyazova.json\n",
            "WARNING:root:2003_russia_kidnap.json\n",
            "WARNING:root:2007_sport_kuzz_003.json\n",
            "WARNING:root:2011_world_robot_001.json\n",
            "WARNING:root:2008_russia_chechenblast_001.json\n",
            "WARNING:root:2011_cinema_cheetah.json\n",
            "WARNING:root:2015_auto_macamdiesel.json\n",
            "WARNING:root:2004_world_marlo.json\n",
            "WARNING:root:2010_hitech_atschoolsgnu.json\n",
            "WARNING:root:2016_russia_veshnyaki.json\n",
            "WARNING:root:2018_blog_povar.json\n",
            "WARNING:root:2006_world_storm_008.json\n",
            "WARNING:root:2002_finance_zhkh_008.json\n",
            "WARNING:root:2006_russia_vesna_001.json\n",
            "WARNING:root:2005_russia_duma27.json\n",
            "WARNING:root:2014_blog_document.json\n",
            "WARNING:root:2007_world_korzai.json\n",
            "WARNING:root:2020_russia_mosmetro.json\n",
            "WARNING:root:2012_cinema_depp.json\n",
            "WARNING:root:2003_russia_tuzlkas.json\n",
            "WARNING:root:2014_russia_putin_sevastopol.json\n",
            "WARNING:root:2010_russia_df_003.json\n",
            "WARNING:root:2004_world_grossmeister.json\n",
            "WARNING:root:2012_world_mars_003.json\n",
            "WARNING:root:2003_sport_bundessecond.json\n",
            "WARNING:root:2004_world_debati.json\n",
            "WARNING:root:2015_world_burundi_005.json\n",
            "WARNING:root:2005_world_sik_001.json\n",
            "WARNING:root:2008_russia_press_protest.json\n",
            "WARNING:root:2015_world_germantank.json\n",
            "WARNING:root:2010_russia_euroset_001.json\n",
            "WARNING:root:2016_russia_bushernew.json\n",
            "WARNING:root:2019_russia_izbili_shies.json\n",
            "WARNING:root:2013_russia_mahachkala_vzryv.json\n",
            "WARNING:root:2004_world_hero_003.json\n",
            "WARNING:root:2013_sport_mike_004.json\n",
            "WARNING:root:2015_finance_mosoblbank_001.json\n",
            "WARNING:root:2012_sport_kaka_002.json\n",
            "WARNING:root:2003_world_monster_001.json\n",
            "WARNING:root:2008_sport_novak_002.json\n",
            "WARNING:root:2009_world_tof_007.json\n",
            "WARNING:root:2002_cinema_nelson_001.json\n",
            "WARNING:root:2007_russia_mitrohin.json\n",
            "WARNING:root:2013_world_trans_002.json\n",
            "WARNING:root:2003_cinema_lora.json\n",
            "WARNING:root:2013_world_baransonredday.json\n",
            "WARNING:root:2017_russia_dtp_002.json\n",
            "WARNING:root:2003_russia_podpiska.json\n",
            "WARNING:root:2002_cinema_blackmore.json\n",
            "WARNING:root:2019_blog_rus_china.json\n",
            "WARNING:root:2005_russia_japan_001.json\n",
            "WARNING:root:2011_sport_banan_002.json\n",
            "WARNING:root:2010_world_hgfd.json\n",
            "WARNING:root:2017_russia_phonetalk.json\n",
            "WARNING:root:2018_world_sanctions_025.json\n",
            "WARNING:root:2019_world_greenlandbonus.json\n",
            "WARNING:root:2009_world_dialog_003.json\n",
            "WARNING:root:2006_world_troe_001.json\n",
            "WARNING:root:2015_hitech_blindspot.json\n",
            "WARNING:root:2013_sport_medal_002.json\n",
            "WARNING:root:2018_finance_vitrenko.json\n",
            "WARNING:root:2013_blog_stalingrad.json\n",
            "WARNING:root:2011_realty_inteco_004.json\n",
            "WARNING:root:2008_russia_orel_003.json\n",
            "WARNING:root:2007_sport_dota_001.json\n",
            "WARNING:root:2018_sport_negative.json\n",
            "WARNING:root:2008_russia_kaspar2.json\n",
            "WARNING:root:2006_world_irah.json\n",
            "WARNING:root:2002_russia_2_chechnua.json\n",
            "WARNING:root:2007_world_oneyaltaenough.json\n",
            "WARNING:root:2004_cinema_arnie.json\n",
            "WARNING:root:2011_russia_kuban_004.json\n",
            "WARNING:root:2009_auto_garagi.json\n",
            "WARNING:root:2011_auto_saud_001.json\n",
            "WARNING:root:2008_sport_kovi_004.json\n",
            "WARNING:root:2005_world_adamkus_003.json\n",
            "WARNING:root:2005_russia_germany.json\n",
            "WARNING:root:2015_auto_kamaz_june.json\n",
            "WARNING:root:2005_finance_vaz_001.json\n",
            "WARNING:root:2003_sport_656467754.json\n",
            "WARNING:root:2003_world_heart_003.json\n",
            "WARNING:root:2006_sport_kar_004.json\n",
            "WARNING:root:2011_finance_eu_nokl.json\n",
            "WARNING:root:2008_world_bezrossiyan.json\n",
            "WARNING:root:2004_russia_plastit_mvd.json\n",
            "WARNING:root:2000_sport_tennis_023.json\n",
            "WARNING:root:2015_russia_krasnoyarskstalin.json\n",
            "WARNING:root:2003_russia_lebedev_003.json\n",
            "WARNING:root:2020_hitech_iran_fake.json\n",
            "WARNING:root:2002_russia_psihologi2.json\n",
            "WARNING:root:2013_russia_nekto.json\n",
            "WARNING:root:2008_cinema_pablo_001.json\n",
            "WARNING:root:2016_auto_granta_germany.json\n",
            "WARNING:root:2010_russia_kotl.json\n",
            "WARNING:root:2017_world_tillsays_005.json\n",
            "WARNING:root:2018_russia_expeskova.json\n",
            "WARNING:root:2017_world_gaylithuania.json\n",
            "WARNING:root:2008_sport_rosso.json\n",
            "WARNING:root:2012_hitech_lkruddos.json\n",
            "WARNING:root:2008_world_garry_004.json\n",
            "WARNING:root:2006_realty_obshe.json\n",
            "WARNING:root:2013_russia_fakel_003.json\n",
            "WARNING:root:2003_sport_detcolrecap.json\n",
            "WARNING:root:2015_world_brit_012.json\n",
            "WARNING:root:2009_sport_rubin_007.json\n",
            "WARNING:root:2014_cinema_vakarchuk.json\n",
            "WARNING:root:2014_sport_kralok.json\n",
            "WARNING:root:2016_russia_dadinfight_001.json\n",
            "WARNING:root:2008_realty_croatia.json\n",
            "WARNING:root:2005_world_galugklek.json\n",
            "WARNING:root:2005_world_larkin.json\n",
            "WARNING:root:2012_russia_guber_004.json\n",
            "WARNING:root:2014_world_nato_025.json\n",
            "WARNING:root:2016_hitech_iPhone2G.json\n",
            "WARNING:root:2014_russia_lavrov_002.json\n",
            "WARNING:root:2012_russia_krasnoyarsk_005.json\n",
            "WARNING:root:2001_russia_zakluchennie.json\n",
            "WARNING:root:2003_russia_deza.json\n",
            "WARNING:root:2018_sport_leo_001.json\n",
            "WARNING:root:2011_russia_visob.json\n",
            "WARNING:root:2003_world_bagdad10.json\n",
            "WARNING:root:2002_world_shihmuradov.json\n",
            "WARNING:root:2016_world_deterra_001.json\n",
            "WARNING:root:2014_russia_vnukovo_005.json\n",
            "WARNING:root:2002_world_gk_001.json\n",
            "WARNING:root:2014_russia_ege_007.json\n",
            "WARNING:root:2019_russia_stepanov_10.json\n",
            "WARNING:root:2010_russia_perepis_003.json\n",
            "WARNING:root:2008_finance_2plus.json\n",
            "WARNING:root:2010_finance_rusal_009.json\n",
            "WARNING:root:2004_russia_nord_018.json\n",
            "WARNING:root:2019_world_deripaska_unsecret.json\n",
            "WARNING:root:2006_russia_zapad_002.json\n",
            "WARNING:root:2021_hitech_starlink_26.json\n",
            "WARNING:root:2017_sport_tosno.json\n",
            "WARNING:root:2016_hitech_baidu.json\n",
            "WARNING:root:2010_world_comment_001.json\n",
            "WARNING:root:2015_russia_churov_005.json\n",
            "WARNING:root:2004_sport_675886289674.json\n",
            "WARNING:root:2017_world_comey_senate.json\n",
            "WARNING:root:2005_sport_habi_001.json\n",
            "WARNING:root:2016_russia_rec.json\n",
            "WARNING:root:2015_realty_kaliningrad_001.json\n",
            "WARNING:root:2014_russia_edinros.json\n",
            "WARNING:root:2005_world_italians.json\n",
            "WARNING:root:2001_russia_korrida2001.json\n",
            "WARNING:root:2011_world_bahrein_002.json\n",
            "WARNING:root:2018_russia_probki.json\n",
            "WARNING:root:2014_finance_krimpublicsector.json\n",
            "WARNING:root:2001_russia_time_003.json\n",
            "WARNING:root:2006_russia_times_002.json\n",
            "WARNING:root:2015_russia_bashneft_002.json\n",
            "WARNING:root:2001_russia_raduev_smi.json\n",
            "WARNING:root:2003_russia_oren.json\n",
            "WARNING:root:2014_russia_intersui.json\n",
            "WARNING:root:2013_sport_vital.json\n",
            "WARNING:root:2018_realty_rat.json\n",
            "WARNING:root:2015_sport_russwe_002.json\n",
            "WARNING:root:2012_blog_police_003.json\n",
            "WARNING:root:2013_blog_medcare.json\n",
            "WARNING:root:2020_sport_basket_027.json\n",
            "WARNING:root:2012_world_ostrova_001.json\n",
            "WARNING:root:2004_sport_7754637756434.json\n",
            "WARNING:root:2004_world_plane_026.json\n",
            "WARNING:root:2014_world_pricefall_001.json\n",
            "WARNING:root:2001_cinema_mikhalkov.json\n",
            "WARNING:root:2003_world_kaida_.json\n",
            "WARNING:root:2005_finance_rosneftegaz.json\n",
            "WARNING:root:2012_russia_mmm_005.json\n",
            "WARNING:root:2011_world_marinau.json\n",
            "WARNING:root:2011_sport_vellit_001.json\n",
            "WARNING:root:2013_russia_savva.json\n",
            "WARNING:root:2005_sport_king_001.json\n",
            "WARNING:root:2006_world_ita_015.json\n",
            "WARNING:root:2005_world_poh_003.json\n",
            "WARNING:root:2015_russia_dolphin.json\n",
            "WARNING:root:2003_russia_lsk.json\n",
            "WARNING:root:2020_russia_udodov_001.json\n",
            "WARNING:root:2000_sport_filip.json\n",
            "WARNING:root:2010_sport_sweet_home.json\n",
            "WARNING:root:2008_world_euro_023.json\n",
            "WARNING:root:2002_russia_alekssevskaya.json\n",
            "WARNING:root:2008_cinema_guggen_001.json\n",
            "WARNING:root:2012_hitech_euhuawei.json\n",
            "WARNING:root:2020_sport_foma_001.json\n",
            "WARNING:root:2019_russia_teacherdress.json\n",
            "WARNING:root:2015_russia_kamchatka_009.json\n",
            "WARNING:root:2018_russia_ne_vyselim.json\n",
            "WARNING:root:2000_sport_bure.json\n",
            "WARNING:root:2012_sport_taekwondo2day.json\n",
            "WARNING:root:2015_russia_soyuz_001.json\n",
            "WARNING:root:2001_world_praga_005.json\n",
            "WARNING:root:2018_russia_poltavchenko_001.json\n",
            "WARNING:root:2016_hitech_newvk.json\n",
            "WARNING:root:2015_auto_ren_14years.json\n",
            "WARNING:root:2010_russia_mobil_001.json\n",
            "WARNING:root:2003_world_miloshevich_001.json\n",
            "WARNING:root:2012_sport_heart_attack.json\n",
            "WARNING:root:2013_world_evac.json\n",
            "WARNING:root:2010_finance_china_013.json\n",
            "WARNING:root:2009_world_gabon.json\n",
            "WARNING:root:2012_world_9yers.json\n",
            "WARNING:root:2007_world_age_001.json\n",
            "WARNING:root:2001_russia_bitirka2.json\n",
            "WARNING:root:2003_sport_figkat.json\n",
            "WARNING:root:2000_russia_pomilovanie_001.json\n",
            "WARNING:root:2011_finance_goszakaz.json\n",
            "WARNING:root:2017_blog_vvp.json\n",
            "WARNING:root:2009_world_antigua_001.json\n",
            "WARNING:root:2016_cinema_hals.json\n",
            "WARNING:root:2014_finance_zakachka.json\n",
            "WARNING:root:2019_russia_besoname.json\n",
            "WARNING:root:2017_world_nestykovki.json\n",
            "WARNING:root:2008_world_koala_001.json\n",
            "WARNING:root:2015_finance_visamc_001.json\n",
            "WARNING:root:2010_world_ryba.json\n",
            "WARNING:root:2014_auto_cadillac_gm.json\n",
            "WARNING:root:2016_sport_mini_003.json\n",
            "WARNING:root:2008_russia_2014sochi.json\n",
            "WARNING:root:2002_world_shah_001.json\n",
            "WARNING:root:2010_russia_storchak_004.json\n",
            "WARNING:root:2007_auto_kuc.json\n",
            "WARNING:root:2011_russia_midgruz.json\n",
            "WARNING:root:2017_hitech_nasa_001.json\n",
            "WARNING:root:2017_finance_alfavscbr.json\n",
            "WARNING:root:2013_finance_cyprusbankdpstct.json\n",
            "WARNING:root:2012_russia_krymsk_014.json\n",
            "WARNING:root:2016_russia_navalny_015.json\n",
            "WARNING:root:2016_russia_bridge_006.json\n",
            "WARNING:root:2008_realty_business.json\n",
            "WARNING:root:2012_world_patriot_005.json\n",
            "WARNING:root:2012_auto_hummondsbest.json\n",
            "WARNING:root:2012_finance_microsber.json\n",
            "WARNING:root:2001_russia_bomgi.json\n",
            "WARNING:root:2004_cinema_niro.json\n",
            "WARNING:root:2002_world_opp.json\n",
            "WARNING:root:2001_russia_mskr.json\n",
            "WARNING:root:2016_hitech_oldibmcool.json\n",
            "WARNING:root:2010_sport_12.json\n",
            "WARNING:root:2004_russia_desert.json\n",
            "WARNING:root:2003_sport_pornyrecap.json\n",
            "WARNING:root:2013_russia_chita.json\n",
            "WARNING:root:2005_cinema_prior.json\n",
            "WARNING:root:2011_world_keit.json\n",
            "WARNING:root:2009_russia_midrf_001.json\n",
            "WARNING:root:2013_sport_basket_027.json\n",
            "WARNING:root:2015_russia_laura.json\n",
            "WARNING:root:2013_russia_problems_001.json\n",
            "WARNING:root:2017_russia_putinhansg20.json\n",
            "WARNING:root:2002_world_sharon_025.json\n",
            "WARNING:root:2006_world_hizblabla.json\n",
            "WARNING:root:2018_world_catfeed.json\n",
            "WARNING:root:2004_russia_cirroz.json\n",
            "WARNING:root:2009_world_kol.json\n",
            "WARNING:root:2008_russia_kaznacheev.json\n",
            "WARNING:root:2012_cinema_rollingsfilm.json\n",
            "WARNING:root:2001_russia_sklyarov_001.json\n",
            "WARNING:root:2017_sport_seb.json\n",
            "WARNING:root:2012_world_mali_008.json\n",
            "WARNING:root:2005_russia_zz_001.json\n",
            "WARNING:root:2005_russia_draule.json\n",
            "WARNING:root:2013_sport_waris.json\n",
            "WARNING:root:2013_russia_medvedevuz.json\n",
            "WARNING:root:2021_russia_distant_end.json\n",
            "WARNING:root:2007_russia_moratorii.json\n",
            "WARNING:root:2004_cinema_ajt.json\n",
            "WARNING:root:2001_sport_33336554.json\n",
            "WARNING:root:2001_russia_surki.json\n",
            "WARNING:root:2020_hitech_fake_vote.json\n",
            "WARNING:root:2015_russia_dadaev_001.json\n",
            "WARNING:root:2010_russia_ugh.json\n",
            "WARNING:root:2019_russia_rulots.json\n",
            "WARNING:root:2007_world_imedi_004.json\n",
            "WARNING:root:2006_world_iran_089.json\n",
            "WARNING:root:2011_finance_avtodor.json\n",
            "WARNING:root:2003_russia_hlor.json\n",
            "WARNING:root:2014_russia_vladim3.json\n",
            "WARNING:root:2021_world_complaint_bbc.json\n",
            "WARNING:root:2002_cinema_seagal.json\n",
            "WARNING:root:2019_world_chirac_mort.json\n",
            "WARNING:root:2012_blog_minus_001.json\n",
            "WARNING:root:2002_russia_starovotova.json\n",
            "WARNING:root:2007_world_atl_002.json\n",
            "WARNING:root:2020_russia_furgal_obyski.json\n",
            "WARNING:root:2001_russia_abuumar.json\n",
            "WARNING:root:2007_russia_bbc_002.json\n",
            "WARNING:root:2003_world_gripp_020.json\n",
            "WARNING:root:2012_auto_limo.json\n",
            "WARNING:root:2007_sport_volley_005.json\n",
            "WARNING:root:2009_finance_oil_020.json\n",
            "WARNING:root:2016_world_zika2.json\n",
            "WARNING:root:2008_world_powercentre.json\n",
            "WARNING:root:2003_russia_iv_003.json\n",
            "WARNING:root:2008_world_duwanskii.json\n",
            "WARNING:root:2018_russia_dogs_002.json\n",
            "WARNING:root:2003_world_lier.json\n",
            "WARNING:root:2018_blog_games_001.json\n",
            "WARNING:root:2013_russia_lublino.json\n",
            "WARNING:root:2017_cinema_oscar_002.json\n",
            "WARNING:root:2011_cinema_tarantino.json\n",
            "WARNING:root:2001_russia_baltika2001.json\n",
            "WARNING:root:2018_cinema_mmkf.json\n",
            "WARNING:root:2010_cinema_ruspris.json\n",
            "WARNING:root:2020_sport_ufc_002.json\n",
            "WARNING:root:2021_russia_policevsdrunkppl.json\n",
            "WARNING:root:2012_finance_putin_bud.json\n",
            "WARNING:root:2003_cinema_bratushki.json\n",
            "WARNING:root:2016_russia_volodin_008.json\n",
            "WARNING:root:2009_finance_rezrvus.json\n",
            "WARNING:root:2010_hitech_cybercrime.json\n",
            "WARNING:root:2014_auto_Patriot.json\n",
            "WARNING:root:2018_world_two_spies.json\n",
            "WARNING:root:2006_cinema_cheb.json\n",
            "WARNING:root:2013_russia_polstrany.json\n",
            "WARNING:root:2015_finance_migrants.json\n",
            "WARNING:root:2009_russia_sys.json\n",
            "WARNING:root:2008_auto_siber_002.json\n",
            "WARNING:root:2013_russia_bast.json\n",
            "WARNING:root:2017_russia_sevastidi_004.json\n",
            "WARNING:root:2006_world_penis.json\n",
            "WARNING:root:2012_world_france_023.json\n",
            "WARNING:root:2005_world_turtle.json\n",
            "WARNING:root:2002_russia_child_away.json\n",
            "WARNING:root:2017_auto_benzin_004.json\n",
            "WARNING:root:2013_realty_domodedovo_001.json\n",
            "WARNING:root:2005_world_lz_001.json\n",
            "WARNING:root:2002_sport_5758753.json\n",
            "WARNING:root:2012_blog_novodvorskaya_001.json\n",
            "WARNING:root:2016_russia_crimea_020.json\n",
            "WARNING:root:2009_auto_domogarov-san.json\n",
            "WARNING:root:2013_sport_swe_001.json\n",
            "WARNING:root:2016_world_finnish_001.json\n",
            "WARNING:root:2017_realty_zenit_002.json\n",
            "WARNING:root:2012_realty_reka_parking.json\n",
            "WARNING:root:2018_sport_box.json\n",
            "WARNING:root:2001_sport_767688575645.json\n",
            "WARNING:root:2011_russia_greben.json\n",
            "WARNING:root:2010_russia_medvedever.json\n",
            "WARNING:root:2000_sport_lewis_001.json\n",
            "WARNING:root:2012_blog_dixi.json\n",
            "WARNING:root:2019_russia_roskosmos_002.json\n",
            "WARNING:root:2009_cinema_simpsons_002.json\n",
            "WARNING:root:2001_world_endeavour_camehome.json\n",
            "WARNING:root:2010_auto_migalki_002.json\n",
            "WARNING:root:2001_russia_prisoners.json\n",
            "WARNING:root:2018_russia_fondagent.json\n",
            "WARNING:root:2021_sport_dinamo.json\n",
            "WARNING:root:2007_sport_davis_013.json\n",
            "WARNING:root:2013_blog_six.json\n",
            "WARNING:root:2013_cinema_krok2013.json\n",
            "WARNING:root:2014_auto_konst_001.json\n",
            "WARNING:root:2008_world_golos_006.json\n",
            "WARNING:root:2008_world_natozhe.json\n",
            "WARNING:root:2003_world_pranks.json\n",
            "WARNING:root:2019_russia_rocket_accid.json\n",
            "WARNING:root:2013_realty_evolution_002.json\n",
            "WARNING:root:2009_sport_team_001.json\n",
            "WARNING:root:2015_blog_opros_001.json\n",
            "WARNING:root:2017_russia_yakut_001.json\n",
            "WARNING:root:2017_russia_sf_gd.json\n",
            "WARNING:root:2008_finance_sarkozy.json\n",
            "WARNING:root:2014_finance_ruoilfld.json\n",
            "WARNING:root:2007_world_sinsity.json\n",
            "WARNING:root:2005_world_karusel.json\n",
            "WARNING:root:2005_russia_kali.json\n",
            "WARNING:root:2010_world_timoshenko_008.json\n",
            "WARNING:root:2005_russia_country.json\n",
            "WARNING:root:2001_world_clintonill.json\n",
            "WARNING:root:2002_russia_bezenzy.json\n",
            "WARNING:root:2011_russia_rotation.json\n",
            "WARNING:root:2002_sport_5674783974.json\n",
            "WARNING:root:2014_sport_sum.json\n",
            "WARNING:root:2003_world_hamas_014.json\n",
            "WARNING:root:2002_world_sputnik_003.json\n",
            "WARNING:root:2015_world_norwayflight.json\n",
            "WARNING:root:2013_auto_drifting.json\n",
            "WARNING:root:2007_sport_boots.json\n",
            "WARNING:root:2013_sport_navas.json\n",
            "WARNING:root:2018_sport_best_005.json\n",
            "WARNING:root:2019_sport_refree_002.json\n",
            "WARNING:root:2013_cinema_hijuelos.json\n",
            "WARNING:root:2016_russia_explosion_001.json\n",
            "WARNING:root:2006_world_jhgd_001.json\n",
            "WARNING:root:2003_russia_vberi.json\n",
            "WARNING:root:2009_hitech_sephonegold.json\n",
            "WARNING:root:2006_sport_lok_010.json\n",
            "WARNING:root:2009_sport_fight_004.json\n",
            "WARNING:root:2002_world_jazeera_004.json\n",
            "WARNING:root:2013_finance_rost3.json\n",
            "WARNING:root:2013_finance_amnesty_008.json\n",
            "WARNING:root:2001_russia_tihonov_013.json\n",
            "WARNING:root:2013_russia_bus3_001.json\n",
            "WARNING:root:2002_sport_4636737864.json\n",
            "WARNING:root:2008_sport_golden_001.json\n",
            "WARNING:root:2011_russia_rev.json\n",
            "WARNING:root:2002_world_uyt_001.json\n",
            "WARNING:root:2009_russia_ozersk.json\n",
            "WARNING:root:2014_finance_chinahelp.json\n",
            "WARNING:root:2008_world_4charge.json\n",
            "WARNING:root:2009_hitech_googlesvghost.json\n",
            "WARNING:root:2007_world_proslushka_002.json\n",
            "WARNING:root:2013_russia_saratovvert.json\n",
            "WARNING:root:2007_russia_su_34.json\n",
            "WARNING:root:2006_world_rate_005.json\n",
            "WARNING:root:2003_russia_inquirer.json\n",
            "WARNING:root:2008_hitech_comtv.json\n",
            "WARNING:root:2009_finance_arm_nabucco.json\n",
            "WARNING:root:2006_finance_yuk_018.json\n",
            "WARNING:root:2010_realty_kazan_001.json\n",
            "WARNING:root:2009_world_corrupt_007.json\n",
            "WARNING:root:2003_world_quake1.json\n",
            "WARNING:root:2014_sport_ars.json\n",
            "WARNING:root:2009_world_gorod.json\n",
            "WARNING:root:2013_russia_kamazy.json\n",
            "WARNING:root:2011_russia_livej.json\n",
            "WARNING:root:2007_sport_stadium_001.json\n",
            "WARNING:root:2002_finance_opek2.json\n",
            "WARNING:root:2016_world_chelic_001.json\n",
            "WARNING:root:2004_world_women3.json\n",
            "WARNING:root:2013_auto_bolsh_park.json\n",
            "WARNING:root:2018_cinema_walking_dead.json\n",
            "WARNING:root:2014_blog_duhovnost.json\n",
            "WARNING:root:2012_cinema_munkrik.json\n",
            "WARNING:root:2010_finance_privatization_003.json\n",
            "WARNING:root:2005_world_chirac_001.json\n",
            "WARNING:root:2002_sport_spainchamp.json\n",
            "WARNING:root:2018_auto_newcharger.json\n",
            "WARNING:root:2004_russia_bell_001.json\n",
            "WARNING:root:2006_sport_paok.json\n",
            "WARNING:root:2010_finance_greece_007.json\n",
            "WARNING:root:2003_world_snn.json\n",
            "WARNING:root:2013_hitech_gals3hole.json\n",
            "WARNING:root:2007_world_eurostat_age.json\n",
            "WARNING:root:2013_world_list.json\n",
            "WARNING:root:2012_russia_weddinshoot.json\n",
            "WARNING:root:2008_sport_tim_001.json\n",
            "WARNING:root:2013_russia_milonov_007.json\n",
            "WARNING:root:2008_finance_correction.json\n",
            "WARNING:root:2012_world_president_001.json\n",
            "WARNING:root:2012_russia_lebedev_020.json\n",
            "WARNING:root:2019_sport_buffon_001.json\n",
            "WARNING:root:2001_finance_minim.json\n",
            "WARNING:root:2017_russia_rockets99ready.json\n",
            "WARNING:root:2005_world_belor_001.json\n",
            "WARNING:root:2015_blog_galimova.json\n",
            "WARNING:root:2014_russia_med_003.json\n",
            "WARNING:root:2016_realty_foros_001.json\n",
            "WARNING:root:2002_world_kohl.json\n",
            "WARNING:root:2007_cinema_metallica_001.json\n",
            "WARNING:root:2011_world_moubarak.json\n",
            "WARNING:root:2021_russia_litvinovich_003.json\n",
            "WARNING:root:2007_russia_nds_001.json\n",
            "WARNING:root:2013_finance_cbrf_002.json\n",
            "WARNING:root:2012_russia_podrostok.json\n",
            "WARNING:root:2013_auto_gibddmos.json\n",
            "WARNING:root:2013_russia_putin_020.json\n",
            "WARNING:root:2006_russia_banki_008.json\n",
            "WARNING:root:2000_russia_lesin_most.json\n",
            "WARNING:root:2008_russia_karymsky.json\n",
            "WARNING:root:2010_russia_putin_multfilm.json\n",
            "WARNING:root:2013_auto_mark_rise.json\n",
            "WARNING:root:2003_russia_pens_014.json\n",
            "WARNING:root:2004_finance_sud_ispolnit.json\n",
            "WARNING:root:2017_cinema_hardy.json\n",
            "WARNING:root:2004_sport_87584873433.json\n",
            "WARNING:root:2018_russia_alehina_001.json\n",
            "WARNING:root:2019_world_burkov.json\n",
            "WARNING:root:2017_world_abe_004.json\n",
            "WARNING:root:2018_russia_onlinekursy.json\n",
            "WARNING:root:2014_world_tripoli_006.json\n",
            "WARNING:root:2001_russia_aznar.json\n",
            "WARNING:root:2019_finance_trillion.json\n",
            "WARNING:root:2008_world_ucha.json\n",
            "WARNING:root:2006_world_alt_001.json\n",
            "WARNING:root:2017_sport_luzhniki_004.json\n",
            "WARNING:root:2006_world_viktor_002.json\n",
            "WARNING:root:2010_sport_menshov.json\n",
            "WARNING:root:2007_sport_beks_009.json\n",
            "WARNING:root:2016_world_manning.json\n",
            "WARNING:root:2010_world_againstpaul.json\n",
            "WARNING:root:2002_sport_5643729874.json\n",
            "WARNING:root:2004_sport_8854637653.json\n",
            "WARNING:root:2008_realty_yashin.json\n",
            "WARNING:root:2012_sport_usada_002.json\n",
            "WARNING:root:2001_sport_steffi.json\n",
            "WARNING:root:2016_hitech_spaces.json\n",
            "WARNING:root:2019_blog_nasledie.json\n",
            "WARNING:root:2013_russia_pussy_kot.json\n",
            "WARNING:root:2003_world_peace_makers_002.json\n",
            "WARNING:root:2012_blog_svershilos.json\n",
            "WARNING:root:2014_world_hamsters.json\n",
            "WARNING:root:2013_finance_siluanov_003.json\n",
            "WARNING:root:2010_russia_limonov_004.json\n",
            "WARNING:root:2019_hitech_ozon_proc.json\n",
            "WARNING:root:2001_russia_primeris4.json\n",
            "WARNING:root:2000_finance_prima.json\n",
            "WARNING:root:2007_auto_israel_002.json\n",
            "WARNING:root:2003_world_zayava_004.json\n",
            "WARNING:root:2007_world_miting_kiev.json\n",
            "WARNING:root:2009_russia_tomskneft.json\n",
            "WARNING:root:2012_auto_svetofor.json\n",
            "WARNING:root:2005_world_chinese.json\n",
            "WARNING:root:2005_finance_houston_003.json\n",
            "WARNING:root:2007_finance_nornick_001.json\n",
            "WARNING:root:2014_russia_guber_001.json\n",
            "WARNING:root:2003_russia_may_001.json\n",
            "WARNING:root:2014_finance_mechelconsort.json\n",
            "WARNING:root:2008_cinema_prokat_024.json\n",
            "WARNING:root:2006_world_abbas_018.json\n",
            "WARNING:root:2003_cinema_urmala.json\n",
            "WARNING:root:2019_russia_sangaji.json\n",
            "WARNING:root:2018_russia_shahov_001.json\n",
            "WARNING:root:2009_cinema_puga4evaisland.json\n",
            "WARNING:root:2002_russia_video_002.json\n",
            "WARNING:root:2007_world_gerontokratia.json\n",
            "WARNING:root:2012_cinema_riseguard.json\n",
            "WARNING:root:2015_sport_quarter_001.json\n",
            "WARNING:root:2012_realty_new_gk.json\n",
            "WARNING:root:2013_sport_kir_001.json\n",
            "WARNING:root:2011_world_vnukim.json\n",
            "WARNING:root:2009_finance_izhavto_default_001.json\n",
            "WARNING:root:2011_cinema_modil.json\n",
            "WARNING:root:2005_cinema_paulo.json\n",
            "WARNING:root:2003_world_dead_014.json\n",
            "WARNING:root:2015_world_syriairanrussia.json\n",
            "WARNING:root:2005_world_terra_024.json\n",
            "WARNING:root:2008_world_karabax_001.json\n",
            "WARNING:root:2012_world_ku4ma.json\n",
            "WARNING:root:2003_russia_sps.json\n",
            "WARNING:root:2013_hitech_iphn6insummer.json\n",
            "WARNING:root:2015_world_avakovfire.json\n",
            "WARNING:root:2007_russia_politkovskay.json\n",
            "WARNING:root:2013_russia_panin2_002.json\n",
            "WARNING:root:2013_world_putinplagiat.json\n",
            "WARNING:root:2015_world_dragon.json\n",
            "WARNING:root:2006_world_sharon_012.json\n",
            "WARNING:root:2013_russia_torch_001.json\n",
            "WARNING:root:2020_russia_sergysmonastery.json\n",
            "WARNING:root:2014_hitech_youtube10.json\n",
            "WARNING:root:2005_russia_yakut.json\n",
            "WARNING:root:2015_russia_romanoff_003.json\n",
            "WARNING:root:2010_hitech_airregkiosk.json\n",
            "WARNING:root:2004_world_obstrel2.json\n",
            "WARNING:root:2009_finance_medevedevspeach.json\n",
            "WARNING:root:2013_world_meladze_001.json\n",
            "WARNING:root:2017_russia_olen.json\n",
            "WARNING:root:2007_world_port_008.json\n",
            "WARNING:root:2011_hitech_cnneteprsn.json\n",
            "WARNING:root:2017_finance_coldweather.json\n",
            "WARNING:root:2009_cinema_coelho_001.json\n",
            "WARNING:root:2004_russia_stepan.json\n",
            "WARNING:root:2010_sport_allstar.json\n",
            "WARNING:root:2009_russia_eston.json\n",
            "WARNING:root:2005_world_the_sun.json\n",
            "WARNING:root:2010_russia_edropravoslav.json\n",
            "WARNING:root:2013_auto_parking.json\n",
            "WARNING:root:2007_sport_scar.json\n",
            "WARNING:root:2014_russia_minust_002.json\n",
            "WARNING:root:2008_world_estony.json\n",
            "WARNING:root:2016_russia_migulya.json\n",
            "WARNING:root:2001_cinema_bardin_001.json\n",
            "WARNING:root:2001_russia_spy5.json\n",
            "WARNING:root:2012_russia_goldputin.json\n",
            "WARNING:root:2002_russia_sapunova_001.json\n",
            "WARNING:root:2007_finance_br_006.json\n",
            "WARNING:root:2012_russia_peskovbrief.json\n",
            "WARNING:root:2011_realty_federation_001.json\n",
            "WARNING:root:2009_russia_noneed.json\n",
            "WARNING:root:2016_world_savchenkolist_001.json\n",
            "WARNING:root:2016_sport_sim.json\n",
            "WARNING:root:2006_cinema_alsu.json\n",
            "WARNING:root:2011_russia_lapshina_001.json\n",
            "WARNING:root:2014_finance_kudrinonfuture.json\n",
            "WARNING:root:2019_sport_seb.json\n",
            "WARNING:root:2003_world_potolok.json\n",
            "WARNING:root:2014_hitech_iwatch_china.json\n",
            "WARNING:root:2012_world_fraptor.json\n",
            "WARNING:root:2014_russia_dagg_003.json\n",
            "WARNING:root:2008_realty_statefunds.json\n",
            "WARNING:root:2017_world_shkreli_001.json\n",
            "WARNING:root:2012_sport_henry.json\n",
            "WARNING:root:2017_russia_feruz_003.json\n",
            "WARNING:root:2012_russia_inet.json\n",
            "WARNING:root:2012_world_dia.json\n",
            "WARNING:root:2020_sport_out.json\n",
            "WARNING:root:2002_sport_38959744.json\n",
            "WARNING:root:2011_sport_ita_003.json\n",
            "WARNING:root:2002_russia_population.json\n",
            "WARNING:root:2011_russia_cater.json\n",
            "WARNING:root:2004_world_djs.json\n",
            "WARNING:root:2015_russia_uglegorsk_001.json\n",
            "WARNING:root:2002_russia_chechnya_034.json\n",
            "WARNING:root:2008_sport_che_005.json\n",
            "WARNING:root:2001_russia_grozn_oper.json\n",
            "WARNING:root:2010_russia_adolescent.json\n",
            "WARNING:root:2012_russia_kovtun.json\n",
            "WARNING:root:2001_sport_sar_001.json\n",
            "WARNING:root:2012_russia_navprogramma.json\n",
            "WARNING:root:2008_world_kleopatra.json\n",
            "WARNING:root:2001_russia_image2.json\n",
            "WARNING:root:2016_russia_yaroslavmudriy.json\n",
            "WARNING:root:2009_world_euongas.json\n",
            "WARNING:root:2016_russia_prim_019.json\n",
            "WARNING:root:2002_russia_kukury.json\n",
            "WARNING:root:2008_cinema_booker_002.json\n",
            "WARNING:root:2001_finance_avtovaz_equador.json\n",
            "WARNING:root:2005_world_itlaphgn.json\n",
            "WARNING:root:2010_russia_perepis_001.json\n",
            "WARNING:root:2009_russia_skp_007.json\n",
            "WARNING:root:2011_russia_esayan3mln.json\n",
            "WARNING:root:2006_russia_buscrash.json\n",
            "WARNING:root:2006_world_hamass_001.json\n",
            "WARNING:root:2018_russia_mahachkala.json\n",
            "WARNING:root:2013_auto_vz_hld.json\n",
            "WARNING:root:2003_sport_milannotwelcome.json\n",
            "WARNING:root:2013_sport_pol_003.json\n",
            "WARNING:root:2014_world_egypt_mursi.json\n",
            "WARNING:root:2007_sport_sheva_018.json\n",
            "WARNING:root:2008_russia_golodlobva.json\n",
            "WARNING:root:2014_hitech_vkontakte_004.json\n",
            "WARNING:root:2015_russia_dtp8.json\n",
            "WARNING:root:2017_sport_spartak_022.json\n",
            "WARNING:root:2005_russia_teplo_008.json\n",
            "WARNING:root:2018_russia_chechnya_006.json\n",
            "WARNING:root:2006_finance_gas_009.json\n",
            "WARNING:root:2016_world_bulgaria_006.json\n",
            "WARNING:root:2009_cinema_princess.json\n",
            "WARNING:root:2006_finance_gazprom_005.json\n",
            "WARNING:root:2005_russia_luzh_tuk.json\n",
            "WARNING:root:2021_sport_salo.json\n",
            "WARNING:root:2010_russia_tu154_003.json\n",
            "WARNING:root:2015_finance_ubscities.json\n",
            "WARNING:root:2009_sport_ole_001.json\n",
            "WARNING:root:2000_finance_mos.json\n",
            "WARNING:root:2019_russia_sobol.json\n",
            "WARNING:root:2004_sport_borrecap_001.json\n",
            "WARNING:root:2018_blog_stariki_stalin.json\n",
            "WARNING:root:2014_world_posoltefft.json\n",
            "WARNING:root:2012_cinema_babalova_002.json\n",
            "WARNING:root:2004_russia_sahalin3.json\n",
            "WARNING:root:2015_russia_goldenbridge.json\n",
            "WARNING:root:2006_cinema_angeliko.json\n",
            "WARNING:root:2010_world_koreakim.json\n",
            "WARNING:root:2005_world_abbas_022.json\n",
            "WARNING:root:2011_hitech_creeper.json\n",
            "WARNING:root:2016_russia_poslanie_001.json\n",
            "WARNING:root:2009_russia_inc_.json\n",
            "WARNING:root:2016_realty_spain_students.json\n",
            "WARNING:root:2020_realty_mosobl_spros.json\n",
            "WARNING:root:2009_russia_mosgor.json\n",
            "WARNING:root:2020_world_corbin.json\n",
            "WARNING:root:2014_realty_krasnaya_polyan.json\n",
            "WARNING:root:2004_world_piraan.json\n",
            "WARNING:root:2004_finance_accuratno.json\n",
            "WARNING:root:2012_sport_ukr_003.json\n",
            "WARNING:root:2010_sport_klich_004.json\n",
            "WARNING:root:2005_world_kitai_002.json\n",
            "WARNING:root:2010_russia_rtut.json\n",
            "WARNING:root:2003_russia_blow_001.json\n",
            "WARNING:root:2006_world_man_woman.json\n",
            "WARNING:root:2013_world_mig29_001.json\n",
            "WARNING:root:2006_sport_pov_002.json\n",
            "WARNING:root:2001_world_bush_022.json\n",
            "WARNING:root:2013_world_santa.json\n",
            "WARNING:root:2012_russia_mammontov.json\n",
            "WARNING:root:2018_sport_ekaterina.json\n",
            "WARNING:root:2006_world_letters_002.json\n",
            "WARNING:root:2003_world_lincoln.json\n",
            "WARNING:root:2000_world_cyclon.json\n",
            "WARNING:root:2008_russia_vainshtok.json\n",
            "WARNING:root:2020_russia_stat_16may.json\n",
            "WARNING:root:2020_world_turkruskarabah.json\n",
            "WARNING:root:2008_russia_putin_014.json\n",
            "WARNING:root:2004_world_minister.json\n",
            "WARNING:root:2008_sport_holly_005.json\n",
            "WARNING:root:2000_finance_bujet_004.json\n",
            "WARNING:root:2014_world_moderators.json\n",
            "WARNING:root:2011_world_go.json\n",
            "WARNING:root:2020_sport_barca_002.json\n",
            "WARNING:root:2011_world_oonbunty.json\n",
            "WARNING:root:2013_realty_spain_004.json\n",
            "WARNING:root:2008_auto_gps.json\n",
            "WARNING:root:2020_world_diseasepeak.json\n",
            "WARNING:root:2007_sport_lokreal.json\n",
            "WARNING:root:2012_world_magnitsk_005.json\n",
            "WARNING:root:2009_world_liege.json\n",
            "WARNING:root:2006_finance_rts_002.json\n",
            "WARNING:root:2004_russia_nevzladvok.json\n",
            "WARNING:root:2017_realty_crcc_metro.json\n",
            "WARNING:root:2012_auto_deps.json\n",
            "WARNING:root:2016_sport_cska_001.json\n",
            "WARNING:root:2011_russia_suic.json\n",
            "WARNING:root:2017_world_japanarmy.json\n",
            "WARNING:root:2011_auto_smart.json\n",
            "WARNING:root:2001_russia_kolmogorov_back.json\n",
            "WARNING:root:2004_russia_5_chechentsev.json\n",
            "WARNING:root:2006_world_iraq_025.json\n",
            "WARNING:root:2015_russia_rakety.json\n",
            "WARNING:root:2017_russia_veteran.json\n",
            "WARNING:root:2010_realty_astoria.json\n",
            "WARNING:root:2003_russia_gololed_005.json\n",
            "WARNING:root:2018_world_brauderbank.json\n",
            "WARNING:root:2017_sport_dynamo_004.json\n",
            "WARNING:root:2014_cinema_cannes_body.json\n",
            "WARNING:root:2004_russia_photo_001.json\n",
            "WARNING:root:2005_russia_most.json\n",
            "WARNING:root:2005_russia_alice.json\n",
            "WARNING:root:2007_russia_utrata.json\n",
            "WARNING:root:2016_sport_tarasenko_002.json\n",
            "WARNING:root:2009_finance_kurs_013.json\n",
            "WARNING:root:2003_russia_frz.json\n",
            "WARNING:root:2006_cinema_madonna_031.json\n",
            "WARNING:root:2001_russia_chechnya2_004.json\n",
            "WARNING:root:2010_russia_dym_004.json\n",
            "WARNING:root:2004_sport_655657764534.json\n",
            "WARNING:root:2004_russia_gripp2.json\n",
            "WARNING:root:2016_cinema_banksy_003.json\n",
            "WARNING:root:2008_russia_med_flot.json\n",
            "WARNING:root:2009_world_sme_001.json\n",
            "WARNING:root:2015_russia_milonovgay.json\n",
            "WARNING:root:2010_russia_mer_003.json\n",
            "WARNING:root:2019_sport_rusfut_004.json\n",
            "WARNING:root:2003_world_escalibur.json\n",
            "WARNING:root:2007_sport_advokaat_001.json\n",
            "WARNING:root:2019_russia_kolobok.json\n",
            "WARNING:root:2010_world_ter_004.json\n",
            "WARNING:root:2012_russia_dokupalis.json\n",
            "WARNING:root:2012_world_damask_004.json\n",
            "WARNING:root:2015_world_oprospew.json\n",
            "WARNING:root:2017_auto_kalanick_001.json\n",
            "WARNING:root:2014_world_gumukrsays.json\n",
            "WARNING:root:2016_world_reznik2.json\n",
            "WARNING:root:2017_russia_crimea_020.json\n",
            "WARNING:root:2009_finance_neft_001.json\n",
            "WARNING:root:2004_world_georg_parl.json\n",
            "WARNING:root:2011_finance_nelegal.json\n",
            "WARNING:root:2000_russia_kirienko.json\n",
            "WARNING:root:2007_russia_gerakl_001.json\n",
            "WARNING:root:2002_world_sex_snaks.json\n",
            "WARNING:root:2004_world_condemned.json\n",
            "WARNING:root:2007_auto_toyota_gm.json\n",
            "WARNING:root:2006_russia_derspig.json\n",
            "WARNING:root:2014_finance_nevaout.json\n",
            "WARNING:root:2004_finance_tax_001.json\n",
            "WARNING:root:2005_russia_pogoda_122.json\n",
            "WARNING:root:2006_russia_new_dopros.json\n",
            "WARNING:root:2008_cinema_hirst_007.json\n",
            "WARNING:root:2017_russia_fontan.json\n",
            "WARNING:root:2005_russia_obstrel_007.json\n",
            "WARNING:root:2002_world_lider3.json\n",
            "WARNING:root:2012_cinema_grapofilm.json\n",
            "WARNING:root:2010_finance_gazprombank.json\n",
            "WARNING:root:2009_russia_sev_os.json\n",
            "WARNING:root:2012_russia_naezd_001.json\n",
            "WARNING:root:2010_auto_latviya.json\n",
            "WARNING:root:2017_russia_smolensk_002.json\n",
            "WARNING:root:2002_russia_jara2.json\n",
            "WARNING:root:2010_russia_boot.json\n",
            "WARNING:root:2003_world_smi_003.json\n",
            "WARNING:root:2005_world_tl.json\n",
            "WARNING:root:2011_world_alive_002.json\n",
            "WARNING:root:2001_russia_gantamirov_newposition.json\n",
            "WARNING:root:2009_world_tay.json\n",
            "WARNING:root:2015_world_cheheninisis_001.json\n",
            "WARNING:root:2013_world_tokyogirl.json\n",
            "WARNING:root:2001_russia_zoo_moscow.json\n",
            "WARNING:root:2010_russia_dymlast.json\n",
            "WARNING:root:2008_world_memorandum_001.json\n",
            "WARNING:root:2010_russia_lavrov_es.json\n",
            "WARNING:root:2015_finance_rucreditspbck.json\n",
            "WARNING:root:2005_world_annan_003.json\n",
            "WARNING:root:2011_world_matosim.json\n",
            "WARNING:root:2007_finance_beloneft.json\n",
            "WARNING:root:2015_cinema_arni.json\n",
            "WARNING:root:2017_world_kndr_021.json\n",
            "WARNING:root:2009_world_opooz.json\n",
            "WARNING:root:2008_world_impostor.json\n",
            "WARNING:root:2018_hitech_dorsey.json\n",
            "WARNING:root:2014_russia_nofsb.json\n",
            "WARNING:root:2013_hitech_Google_003.json\n",
            "WARNING:root:2012_finance_dobrota.json\n",
            "WARNING:root:2012_auto_niss_stpeter.json\n",
            "WARNING:root:2013_hitech_yutbdial.json\n",
            "WARNING:root:2005_world_menshealth.json\n",
            "WARNING:root:2009_finance_times.json\n",
            "WARNING:root:2013_world_blast_007.json\n",
            "WARNING:root:2012_russia_migrants_004.json\n",
            "WARNING:root:2019_realty_tesha.json\n",
            "WARNING:root:2019_sport_medvedev_017.json\n",
            "WARNING:root:2012_auto_Samara_001.json\n",
            "WARNING:root:2012_russia_toporova.json\n",
            "WARNING:root:2010_world_mn_003.json\n",
            "WARNING:root:2004_world_mosulhour.json\n",
            "WARNING:root:2003_world_203ter.json\n",
            "WARNING:root:2016_russia_kadyringush.json\n",
            "WARNING:root:2014_world_premia_001.json\n",
            "WARNING:root:2018_sport_ice.json\n",
            "WARNING:root:2005_russia_xodor.json\n",
            "WARNING:root:2011_realty_yanukovich_001.json\n",
            "WARNING:root:2010_world_but_2.json\n",
            "WARNING:root:2016_sport_contributio.json\n",
            "WARNING:root:2003_world_despite.json\n",
            "WARNING:root:2014_blog_hodorkovskaya.json\n",
            "WARNING:root:2010_world_ellie.json\n",
            "WARNING:root:2004_cinema_faberge_001.json\n",
            "WARNING:root:2012_blog_spi.json\n",
            "WARNING:root:2009_finance_kudrin_013.json\n",
            "WARNING:root:2007_world_massmedia_002.json\n",
            "WARNING:root:2000_russia_communist.json\n",
            "WARNING:root:2019_hitech_spectrr.json\n",
            "WARNING:root:2014_russia_putin_024.json\n",
            "WARNING:root:2017_sport_draw_014.json\n",
            "WARNING:root:2018_world_all_saudi.json\n",
            "WARNING:root:2007_world_brazilia_002.json\n",
            "WARNING:root:2011_sport_gym_002.json\n",
            "WARNING:root:2002_world_gradishte.json\n",
            "WARNING:root:2002_russia_srok.json\n",
            "WARNING:root:2016_auto_statgai.json\n",
            "WARNING:root:2011_sport_chelsea_001.json\n",
            "WARNING:root:2001_russia_kuzbassugol.json\n",
            "WARNING:root:2013_cinema_polunin_002.json\n",
            "WARNING:root:2011_realty_rzhd_003.json\n",
            "WARNING:root:2018_world_trump_kimsanctions.json\n",
            "WARNING:root:2011_finance_lagard_001.json\n",
            "WARNING:root:2018_russia_teplohod.json\n",
            "WARNING:root:2013_russia_greenpeace_008.json\n",
            "WARNING:root:2016_russia_korotkov.json\n",
            "WARNING:root:2002_russia_russia_001.json\n",
            "WARNING:root:2007_world_ovcharki.json\n",
            "WARNING:root:2009_finance_netraboty.json\n",
            "WARNING:root:2014_world_eusanc_002.json\n",
            "WARNING:root:2010_sport_zanata.json\n",
            "WARNING:root:2010_finance_lte_001.json\n",
            "WARNING:root:2004_sport_titrecap_002.json\n",
            "WARNING:root:2011_sport_wta_005.json\n",
            "WARNING:root:2008_world_obana.json\n",
            "WARNING:root:2007_russia_neschitayutevropeytsami.json\n",
            "WARNING:root:2013_cinema_spivakov.json\n",
            "WARNING:root:2015_sport_rusgum.json\n",
            "WARNING:root:2016_world_onechina.json\n",
            "WARNING:root:2012_russia_dagg_002.json\n",
            "WARNING:root:2015_hitech_Seabin.json\n",
            "WARNING:root:2009_finance_naftogazy.json\n",
            "WARNING:root:2017_sport_sambo.json\n",
            "WARNING:root:2001_russia_sud_perenos.json\n",
            "WARNING:root:2002_world_usa_clocl.json\n",
            "WARNING:root:2003_sport_rusgoirl.json\n",
            "WARNING:root:2016_russia_astakhov.json\n",
            "WARNING:root:2009_finance_usa_ukr.json\n",
            "WARNING:root:2012_blog_zuckerberg.json\n",
            "WARNING:root:2018_sport_bobrovsky.json\n",
            "WARNING:root:2010_finance_currencywar.json\n",
            "WARNING:root:2001_sport_kremlincuppress.json\n",
            "WARNING:root:2002_finance_busha_015.json\n",
            "WARNING:root:2000_world_israel1.json\n",
            "WARNING:root:2009_cinema_cenewar.json\n",
            "WARNING:root:2013_hitech_robozhuk.json\n",
            "WARNING:root:2009_hitech_ramvicrype.json\n",
            "WARNING:root:2016_sport_dron_002.json\n",
            "WARNING:root:2003_world_10tys.json\n",
            "WARNING:root:2011_world_mobile_001.json\n",
            "WARNING:root:2011_world_admin_003.json\n",
            "WARNING:root:2003_world_rezolucia.json\n",
            "WARNING:root:2003_russia_kad_003.json\n",
            "WARNING:root:2002_world_ipl.json\n",
            "WARNING:root:2012_russia_medved_009.json\n",
            "WARNING:root:2007_cinema_gastroli.json\n",
            "WARNING:root:2012_russia_kostomarov.json\n",
            "WARNING:root:2002_world_figaro.json\n",
            "WARNING:root:2001_russia_gamtamirov_echo.json\n",
            "WARNING:root:2003_cinema_rakh.json\n",
            "WARNING:root:2016_russia_dagestan_010.json\n",
            "WARNING:root:2007_world_gosdep_002.json\n",
            "WARNING:root:2007_sport_plus.json\n",
            "WARNING:root:2005_russia_kasj_001.json\n",
            "WARNING:root:2016_world_syria_029.json\n",
            "WARNING:root:2008_hitech_news.json\n",
            "WARNING:root:2006_russia_snar.json\n",
            "WARNING:root:2006_russia_rutzcoi.json\n",
            "WARNING:root:2016_sport_txe.json\n",
            "WARNING:root:2014_russia_sobyaninmigrants.json\n",
            "WARNING:root:2016_cinema_adele_005.json\n",
            "WARNING:root:2014_russia_milo.json\n",
            "WARNING:root:2006_russia_roman_001.json\n",
            "WARNING:root:2005_sport_gazza.json\n",
            "WARNING:root:2010_world_psel.json\n",
            "WARNING:root:2018_russia_rkngoogle_001.json\n",
            "WARNING:root:2011_sport_balls.json\n",
            "WARNING:root:2017_russia_tatartraur.json\n",
            "WARNING:root:2012_world_nakb.json\n",
            "WARNING:root:2013_finance_rokirovka.json\n",
            "WARNING:root:2019_hitech_mrg_beeline2.json\n",
            "WARNING:root:2012_russia_mcfaul_004.json\n",
            "WARNING:root:2003_finance_min_003.json\n",
            "WARNING:root:2007_russia_zyazikov.json\n",
            "WARNING:root:2001_world_crime_009.json\n",
            "WARNING:root:2005_world_manes.json\n",
            "WARNING:root:2001_sport_usselrasistquit.json\n",
            "WARNING:root:2009_hitech_eutelecommlaws.json\n",
            "WARNING:root:2011_world_yellowdiam.json\n",
            "WARNING:root:2016_world_losses.json\n",
            "WARNING:root:2003_russia_melnikov.json\n",
            "WARNING:root:2014_cinema_geteborgfilm.json\n",
            "WARNING:root:2004_world_confirm_004.json\n",
            "WARNING:root:2004_cinema_babaskov_005.json\n",
            "WARNING:root:2017_world_finland_004.json\n",
            "WARNING:root:2013_sport_dogovor_004.json\n",
            "WARNING:root:2015_world_hnr.json\n",
            "WARNING:root:2013_auto_kndr_bicycl.json\n",
            "WARNING:root:2004_russia_depp_001.json\n",
            "WARNING:root:2006_world_opolz_003.json\n",
            "WARNING:root:2006_world_sweden_003.json\n",
            "WARNING:root:2003_world_30sars.json\n",
            "WARNING:root:2000_finance_londonclub.json\n",
            "WARNING:root:2002_world_india_020.json\n",
            "WARNING:root:2002_russia_hozeev_003.json\n",
            "WARNING:root:2002_world_vizit_009.json\n",
            "WARNING:root:2006_finance_gzprm.json\n",
            "WARNING:root:2013_world_taxletters.json\n",
            "WARNING:root:2017_world_macron_005.json\n",
            "WARNING:root:2012_russia_doctors.json\n",
            "WARNING:root:2013_sport_cska_008.json\n",
            "WARNING:root:2010_cinema_bynes.json\n",
            "WARNING:root:2021_world_iskanders.json\n",
            "WARNING:root:2014_cinema_prohazkova.json\n",
            "WARNING:root:2001_world_extrad.json\n",
            "WARNING:root:2003_sport_engtrecap.json\n",
            "WARNING:root:2001_world_spy_004.json\n",
            "WARNING:root:2010_world_kim_005.json\n",
            "WARNING:root:2017_realty_stalagmit2018.json\n",
            "WARNING:root:2010_world_newglava.json\n",
            "WARNING:root:2011_world_kenignoteurope.json\n",
            "WARNING:root:2011_cinema_wildtomb.json\n",
            "WARNING:root:2007_sport_plu_009.json\n",
            "WARNING:root:2009_cinema_torino.json\n",
            "WARNING:root:2020_world_full_drugs.json\n",
            "WARNING:root:2017_russia_weapon_004.json\n",
            "WARNING:root:2005_world_puka4.json\n",
            "WARNING:root:2010_russia_boot_001.json\n",
            "WARNING:root:2010_sport_favor.json\n",
            "WARNING:root:2016_world_karpov_003.json\n",
            "WARNING:root:2016_hitech_nivea.json\n",
            "WARNING:root:2012_world_assange_002.json\n",
            "WARNING:root:2001_russia_shparo_finish.json\n",
            "WARNING:root:2020_russia_trialpostpnd.json\n",
            "WARNING:root:2005_world_baski_001.json\n",
            "WARNING:root:2014_auto_duma_drunk.json\n",
            "WARNING:root:2016_russia_krasnodardush.json\n",
            "WARNING:root:2015_world_khamenei.json\n",
            "WARNING:root:2019_russia_ekbislam.json\n",
            "WARNING:root:2008_cinema_police_002.json\n",
            "WARNING:root:2009_sport_hiddink_005.json\n",
            "WARNING:root:2009_world_pripasy.json\n",
            "WARNING:root:2014_russia_solyanka.json\n",
            "WARNING:root:2005_russia_komi.json\n",
            "WARNING:root:2003_russia_miting_002.json\n",
            "WARNING:root:2009_sport_mor_001.json\n",
            "WARNING:root:2004_cinema_kinotavr.json\n",
            "WARNING:root:2016_world_usa_043.json\n",
            "WARNING:root:2015_russia_muhudinov_001.json\n",
            "WARNING:root:2005_world_menshalf.json\n",
            "WARNING:root:2010_world_dorogo.json\n",
            "WARNING:root:2008_world_un_kiev.json\n",
            "WARNING:root:2007_world_kroleg.json\n",
            "WARNING:root:2011_cinema_gaga_004.json\n",
            "WARNING:root:2006_sport_hat.json\n",
            "WARNING:root:2007_world_brit_012.json\n",
            "WARNING:root:2001_world_trdcysd.json\n",
            "WARNING:root:2011_russia_rezo.json\n",
            "WARNING:root:2004_finance_uhciterusskiy.json\n",
            "WARNING:root:2013_sport_pavel_005.json\n",
            "WARNING:root:2005_finance_cbrhg.json\n",
            "WARNING:root:2020_russia_hiv_dud_test.json\n",
            "WARNING:root:2013_blog_spy.json\n",
            "WARNING:root:2001_russia_moscowsnow_roofcrack2.json\n",
            "WARNING:root:2012_russia_danilov.json\n",
            "WARNING:root:2012_blog_denkosmo.json\n",
            "WARNING:root:2016_world_vengriavon.json\n",
            "WARNING:root:2002_finance_soros.json\n",
            "WARNING:root:2001_sport_minikalgary.json\n",
            "WARNING:root:2009_russia_blog_medved.json\n",
            "WARNING:root:2014_russia_dmitriev_001.json\n",
            "WARNING:root:2006_world_plut.json\n",
            "WARNING:root:2009_hitech_flypaper.json\n",
            "WARNING:root:2014_russia_lopata.json\n",
            "WARNING:root:2007_cinema_masks.json\n",
            "WARNING:root:2012_blog_visrorii.json\n",
            "WARNING:root:2001_world_mercury_leak.json\n",
            "WARNING:root:2001_world_ruba.json\n",
            "WARNING:root:2020_hitech_dit_viber.json\n",
            "WARNING:root:2009_finance_oilcredit.json\n",
            "WARNING:root:2002_sport_demlonlyrus.json\n",
            "WARNING:root:2015_hitech_chromebit.json\n",
            "WARNING:root:2020_russia_oil_credit.json\n",
            "WARNING:root:2017_russia_omskrap.json\n",
            "WARNING:root:2012_russia_puting_003.json\n",
            "WARNING:root:2001_russia_axenen_gzt.json\n",
            "WARNING:root:2011_world_ozon.json\n",
            "WARNING:root:2001_russia_tuleev_vub.json\n",
            "WARNING:root:2007_world_village.json\n",
            "WARNING:root:2011_sport_masha_001.json\n",
            "WARNING:root:2004_russia_spoon.json\n",
            "WARNING:root:2006_russia_donor.json\n",
            "WARNING:root:2009_sport_bal_001.json\n",
            "WARNING:root:2004_sport_petrrecap.json\n",
            "WARNING:root:2019_sport_rg.json\n",
            "WARNING:root:2018_russia_er_putin.json\n",
            "WARNING:root:2001_russia_general_vlasov.json\n",
            "WARNING:root:2019_russia_swimout.json\n",
            "WARNING:root:2013_russia_roshalgolikova.json\n",
            "WARNING:root:2017_russia_doma_002.json\n",
            "WARNING:root:2010_world_maoist.json\n",
            "WARNING:root:2012_realty_ozero.json\n",
            "WARNING:root:2011_finance_indi.json\n",
            "WARNING:root:2010_world_siloperation.json\n",
            "WARNING:root:2010_russia_minobor_002.json\n",
            "WARNING:root:2015_world_kndr_017.json\n",
            "WARNING:root:2012_russia_mwdoperation.json\n",
            "WARNING:root:2002_world_afrosnow.json\n",
            "WARNING:root:2012_finance_zanachka.json\n",
            "WARNING:root:2015_hitech_applewatch_001.json\n",
            "WARNING:root:2008_world_rr_002.json\n",
            "WARNING:root:2010_realty_royalheating.json\n",
            "WARNING:root:2016_finance_cnvisa.json\n",
            "WARNING:root:2001_finance_sonicduo_002.json\n",
            "WARNING:root:2005_sport_fedor_off.json\n",
            "WARNING:root:2004_world_tornado.json\n",
            "WARNING:root:2015_world_georgia_ua.json\n",
            "WARNING:root:2009_world_kadyr_002.json\n",
            "WARNING:root:2016_russia_krasnov_sk.json\n",
            "WARNING:root:2008_world_magate_002.json\n",
            "WARNING:root:2012_auto_nikas.json\n",
            "WARNING:root:2012_russia_pussy_002.json\n",
            "WARNING:root:2004_world_izmena_001.json\n",
            "WARNING:root:2015_hitech_win_001.json\n",
            "WARNING:root:2018_world_returntosender.json\n",
            "WARNING:root:2002_russia_president_006.json\n",
            "WARNING:root:2016_russia_waytocommunism.json\n",
            "WARNING:root:2008_cinema_mulligan.json\n",
            "WARNING:root:2008_russia_site_006.json\n",
            "WARNING:root:2016_blog_sheremetkill.json\n",
            "WARNING:root:2017_russia_salt.json\n",
            "WARNING:root:2016_world_mosul_attack.json\n",
            "WARNING:root:2009_finance_soros_010.json\n",
            "WARNING:root:2007_cinema_bigtheatre_002.json\n",
            "WARNING:root:2009_finance_sukhoi_001.json\n",
            "WARNING:root:2017_world_macallister.json\n",
            "WARNING:root:2008_russia_media_003.json\n",
            "WARNING:root:2004_sport_kovalchuk.json\n",
            "WARNING:root:2018_world_ilbezekcase.json\n",
            "WARNING:root:2016_finance_razdel.json\n",
            "WARNING:root:2001_sport_8566574.json\n",
            "WARNING:root:2009_auto_chybais-2.json\n",
            "WARNING:root:2018_cinema_art_001.json\n",
            "WARNING:root:2003_world_hamas_024.json\n",
            "WARNING:root:2009_world_223.json\n",
            "WARNING:root:2002_finance_city_001.json\n",
            "WARNING:root:2008_world_sud_019.json\n",
            "WARNING:root:2000_world_armenia_003.json\n",
            "WARNING:root:2020_russia_fake_sud.json\n",
            "WARNING:root:2014_finance_deripaska_001.json\n",
            "WARNING:root:2016_russia_khorosh.json\n",
            "WARNING:root:2014_auto_model_x.json\n",
            "WARNING:root:2019_world_raketa.json\n",
            "WARNING:root:2015_russia_colon.json\n",
            "WARNING:root:2012_finance_kioski.json\n",
            "WARNING:root:2006_sport_uefa_015.json\n",
            "WARNING:root:2014_world_vasilki.json\n",
            "WARNING:root:2004_world_visit_004.json\n",
            "WARNING:root:2018_blog_aleksanyan.json\n",
            "WARNING:root:2005_cinema_schnur_001.json\n",
            "WARNING:root:2015_sport_ski_003.json\n",
            "WARNING:root:2012_finance_rosneftegaz_003.json\n",
            "WARNING:root:2001_russia_gudermes.json\n",
            "WARNING:root:2008_realty_queen_005.json\n",
            "WARNING:root:2001_world_hanssen_003.json\n",
            "WARNING:root:2002_russia_tv_002.json\n",
            "WARNING:root:2004_russia_tiran.json\n",
            "WARNING:root:2005_russia_sam_007.json\n",
            "WARNING:root:2001_russia_moscow_012.json\n",
            "WARNING:root:2007_world_europa_003.json\n",
            "WARNING:root:2012_world_lazukiny_001.json\n",
            "WARNING:root:2020_russia_urupinsk.json\n",
            "WARNING:root:2017_world_idlib_003.json\n",
            "WARNING:root:2013_russia_kolpino.json\n",
            "WARNING:root:2005_russia_shmidt_002.json\n",
            "WARNING:root:2003_world_checehn.json\n",
            "WARNING:root:2003_world_europe_heat.json\n",
            "WARNING:root:2002_russia_kosmos_001.json\n",
            "WARNING:root:2018_russia_tuva_004.json\n",
            "WARNING:root:2021_world_uscyberresponce.json\n",
            "WARNING:root:2008_realty_nalog_004.json\n",
            "WARNING:root:2008_world_bank_china.json\n",
            "WARNING:root:2011_russia_naryshkin.json\n",
            "WARNING:root:2017_world_trollingnato.json\n",
            "WARNING:root:2012_world_attashe.json\n",
            "WARNING:root:2009_world_ready_002.json\n",
            "WARNING:root:2014_finance_penpf.json\n",
            "WARNING:root:2010_world_sundo.json\n",
            "WARNING:root:2016_blog_vvp.json\n",
            "WARNING:root:2009_russia_rizh.json\n",
            "WARNING:root:2007_sport_safin_001.json\n",
            "WARNING:root:2000_world_sryu.json\n",
            "WARNING:root:2015_world_nutella_001.json\n",
            "WARNING:root:2020_russia_not_agit.json\n",
            "WARNING:root:2016_russia_boeing_009.json\n",
            "WARNING:root:2005_russia_mig_001.json\n",
            "WARNING:root:2011_russia_nbw.json\n",
            "WARNING:root:2007_auto_bluetooth.json\n",
            "WARNING:root:2021_sport_rus.json\n",
            "WARNING:root:2017_russia_roknaren.json\n",
            "WARNING:root:2015_world_lepen_001.json\n",
            "WARNING:root:2003_cinema_baldin_001.json\n",
            "WARNING:root:2015_auto_honda_recall_002.json\n",
            "WARNING:root:2000_sport_chernyshov.json\n",
            "WARNING:root:2007_sport_arb.json\n",
            "WARNING:root:2004_world_dom_013.json\n",
            "WARNING:root:2018_blog_dima.json\n",
            "WARNING:root:2017_russia_navalnback.json\n",
            "WARNING:root:2005_cinema_bond_006.json\n",
            "WARNING:root:2008_russia_nota.json\n",
            "WARNING:root:2016_russia_ekaterinburg_001.json\n",
            "WARNING:root:2020_russia_pushkina.json\n",
            "WARNING:root:2016_realty_evolution.json\n",
            "WARNING:root:2017_world_holland_002.json\n",
            "WARNING:root:2018_world_pomeha.json\n",
            "WARNING:root:2002_world_izr_ter.json\n",
            "WARNING:root:2006_finance_wtoukr.json\n",
            "WARNING:root:2003_russia_nazn.json\n",
            "WARNING:root:2017_russia_hamidullin.json\n",
            "WARNING:root:2005_russia_ivlev_001.json\n",
            "WARNING:root:2012_world_1_april_sobak.json\n",
            "WARNING:root:2012_world_reiting_002.json\n",
            "WARNING:root:2010_finance_hlop.json\n",
            "WARNING:root:2011_world_pro_usa.json\n",
            "WARNING:root:2013_russia_vesilieva_read.json\n",
            "WARNING:root:2006_world_man_004.json\n",
            "WARNING:root:2002_russia_nassli.json\n",
            "WARNING:root:2019_realty_chaika.json\n",
            "WARNING:root:2014_finance_detkinken.json\n",
            "WARNING:root:2020_world_uscncommunism.json\n",
            "WARNING:root:2020_russia_ruschools.json\n",
            "WARNING:root:2003_sport_563777864.json\n",
            "WARNING:root:2014_russia_unavailable.json\n",
            "WARNING:root:2004_russia_izmena.json\n",
            "WARNING:root:2008_finance_gazpromo.json\n",
            "WARNING:root:2007_world_volvo_007.json\n",
            "WARNING:root:2014_world_lastenola.json\n",
            "WARNING:root:2002_world_zakaev2_004.json\n",
            "WARNING:root:2008_russia_zakpit.json\n",
            "WARNING:root:2016_sport_povetkin_013.json\n",
            "WARNING:root:2011_russia_vto_001.json\n",
            "WARNING:root:2011_sport_champions.json\n",
            "WARNING:root:2011_russia_hramov.json\n",
            "WARNING:root:2003_sport_5836378644.json\n",
            "WARNING:root:2003_sport_lchfans.json\n",
            "WARNING:root:2014_world_india_019.json\n",
            "WARNING:root:2017_world_vsue.json\n",
            "WARNING:root:2004_world_israel_002.json\n",
            "WARNING:root:2010_cinema_shrek4.json\n",
            "WARNING:root:2003_sport_593765765.json\n",
            "WARNING:root:2008_realty_stadium.json\n",
            "WARNING:root:2021_auto_auto_price.json\n",
            "WARNING:root:2004_russia_golod.json\n",
            "WARNING:root:2001_world_laden_son.json\n",
            "WARNING:root:2013_russia_noeffmen.json\n",
            "WARNING:root:2008_sport_kas_005.json\n",
            "WARNING:root:2011_world_rubi_002.json\n",
            "WARNING:root:2008_sport_liver_001.json\n",
            "WARNING:root:2011_sport_kazan_005.json\n",
            "WARNING:root:2008_world_rus_eu_001.json\n",
            "WARNING:root:2005_world_nota_001.json\n",
            "WARNING:root:2017_russia_mara_009.json\n",
            "WARNING:root:2008_russia_notarius.json\n",
            "WARNING:root:2005_russia_new_year.json\n",
            "WARNING:root:2000_russia_konoplya.json\n",
            "WARNING:root:2003_world_gib_005.json\n",
            "WARNING:root:2001_russia_tv6_010.json\n",
            "WARNING:root:2006_russia_omon_003.json\n",
            "WARNING:root:2007_realty_petersky.json\n",
            "WARNING:root:2020_sport_anna_004.json\n",
            "WARNING:root:2009_russia_crd.json\n",
            "WARNING:root:2014_russia_pu.json\n",
            "WARNING:root:2019_russia_saratovlisa.json\n",
            "WARNING:root:2011_cinema_grammy.json\n",
            "WARNING:root:2018_world_dinner2.json\n",
            "WARNING:root:2010_russia_memo_005.json\n",
            "WARNING:root:2001_world_rezoluciaoon.json\n",
            "WARNING:root:2011_russia_neftekumsk.json\n",
            "WARNING:root:2008_sport_gym_003.json\n",
            "WARNING:root:2012_russia_kalugin_001.json\n",
            "WARNING:root:2002_sport_braturkeypreview.json\n",
            "WARNING:root:2008_world_osporit.json\n",
            "WARNING:root:2005_world_lahud.json\n",
            "WARNING:root:2009_russia_tof_003.json\n",
            "WARNING:root:2009_auto_oproverg.json\n",
            "WARNING:root:2020_sport_burov.json\n",
            "WARNING:root:2015_world_roof_001.json\n",
            "WARNING:root:2012_sport_furs.json\n",
            "WARNING:root:2006_russia_tutov_009.json\n",
            "WARNING:root:2016_world_global_risk.json\n",
            "WARNING:root:2001_cinema_prizy.json\n",
            "WARNING:root:2014_russia_memo_002.json\n",
            "WARNING:root:2010_world_cotdivoire.json\n",
            "WARNING:root:2004_russia_oprpr.json\n",
            "WARNING:root:2002_world_anekdot_002.json\n",
            "WARNING:root:2002_russia_alternativ.json\n",
            "WARNING:root:2003_sport_5738876446.json\n",
            "WARNING:root:2014_auto_vw_kaluga.json\n",
            "WARNING:root:2015_hitech_iran_wire.json\n",
            "WARNING:root:2011_world_pejic.json\n",
            "WARNING:root:2007_world_binladen.json\n",
            "WARNING:root:2010_russia_tu_154_003.json\n",
            "WARNING:root:2001_russia_troshev_005.json\n",
            "WARNING:root:2011_world_usa_024.json\n",
            "WARNING:root:2013_auto_Audicoupe.json\n",
            "WARNING:root:2008_world_kit_003.json\n",
            "WARNING:root:2005_russia_mid_006.json\n",
            "WARNING:root:2008_world_sovet_009.json\n",
            "WARNING:root:2013_russia_ivanov_009.json\n",
            "WARNING:root:2017_finance_uaruinvest.json\n",
            "WARNING:root:2008_sport_holval.json\n",
            "WARNING:root:2011_cinema_akunin_004.json\n",
            "WARNING:root:2001_world_soltys.json\n",
            "WARNING:root:2007_world_busher_012.json\n",
            "WARNING:root:2009_sport_usopen_001.json\n",
            "WARNING:root:2009_world_pri_001.json\n",
            "WARNING:root:2018_sport_kaisa.json\n",
            "WARNING:root:2013_finance_shelf_001.json\n",
            "WARNING:root:2012_finance_spain_002.json\n",
            "WARNING:root:2005_world_sahvat.json\n",
            "WARNING:root:2015_russia_tula_002.json\n",
            "WARNING:root:2009_cinema_deti.json\n",
            "WARNING:root:2018_finance_not_clear.json\n",
            "WARNING:root:2002_russia_croatia.json\n",
            "WARNING:root:2005_finance_price_002.json\n",
            "WARNING:root:2011_cinema_sting_001.json\n",
            "WARNING:root:2001_russia_kiselev_isk.json\n",
            "WARNING:root:2013_sport_dodo.json\n",
            "WARNING:root:2003_finance_kup.json\n",
            "WARNING:root:2019_world_blastsyria.json\n",
            "WARNING:root:2016_world_brussels_007.json\n",
            "WARNING:root:2014_cinema_terry_001.json\n",
            "WARNING:root:2009_world_disk.json\n",
            "WARNING:root:2007_russia_poteri_001.json\n",
            "WARNING:root:2005_cinema_stalin_4.json\n",
            "WARNING:root:2019_russia_novosibirsk_002.json\n",
            "WARNING:root:2004_cinema_laden2.json\n",
            "WARNING:root:2001_cinema_quidditch_times.json\n",
            "WARNING:root:2009_finance_autocredit.json\n",
            "WARNING:root:2014_hitech_gates_chiken.json\n",
            "WARNING:root:2014_cinema_marquez.json\n",
            "WARNING:root:2007_world_ybili_001.json\n",
            "WARNING:root:2011_sport_dick.json\n",
            "WARNING:root:2014_world_brennan_communications.json\n",
            "WARNING:root:2005_world_kazahstan.json\n",
            "WARNING:root:2006_russia_planes.json\n",
            "WARNING:root:2011_sport_4give.json\n",
            "WARNING:root:2002_world_pentagonkitai.json\n",
            "WARNING:root:2002_world_ins_007.json\n",
            "WARNING:root:2007_russia_ugrozy_net.json\n",
            "WARNING:root:2001_sport_lihov_001.json\n",
            "WARNING:root:2009_russia_constitution.json\n",
            "WARNING:root:2004_russia_otkaz.json\n",
            "WARNING:root:2006_sport_cyc.json\n",
            "WARNING:root:2001_russia_vladavia.json\n",
            "WARNING:root:2014_sport_znarok_007.json\n",
            "WARNING:root:2013_finance_belarus2mlrd.json\n",
            "WARNING:root:2014_sport_paral_001.json\n",
            "WARNING:root:2012_world_march.json\n",
            "WARNING:root:2012_cinema_crowe.json\n",
            "WARNING:root:2009_finance_itogitogi_151.json\n",
            "WARNING:root:2014_russia_chilingarov.json\n",
            "WARNING:root:2013_sport_anton_001.json\n",
            "WARNING:root:2012_auto_yeti.json\n",
            "WARNING:root:2014_world_india_008.json\n",
            "WARNING:root:2011_russia_poteri.json\n",
            "WARNING:root:2014_world_parl_001.json\n",
            "WARNING:root:2010_russia_rao_002.json\n",
            "WARNING:root:2018_russia_dog_001.json\n",
            "WARNING:root:2011_russia_federation_007.json\n",
            "WARNING:root:2014_russia_demushkin.json\n",
            "WARNING:root:2005_world_nuclear_003.json\n",
            "WARNING:root:2008_world_kozu.json\n",
            "WARNING:root:2011_russia_navalny_015.json\n",
            "WARNING:root:2011_cinema_pritsk.json\n",
            "WARNING:root:2017_russia_dalniy.json\n",
            "WARNING:root:2010_world_fire_055.json\n",
            "WARNING:root:2001_world_new_003.json\n",
            "WARNING:root:2016_auto_ecar8000d.json\n",
            "WARNING:root:2009_sport_masha_006.json\n",
            "WARNING:root:2013_world_evo.json\n",
            "WARNING:root:2001_finance_sbsagro_mir.json\n",
            "WARNING:root:2013_world_motochina.json\n",
            "WARNING:root:2009_world_quake_005.json\n",
            "WARNING:root:2002_russia_peterb.json\n",
            "WARNING:root:2013_realty_christchurch.json\n",
            "WARNING:root:2015_world_mistral_032.json\n",
            "WARNING:root:2015_russia_lub.json\n",
            "WARNING:root:2014_russia_zubov_002.json\n",
            "WARNING:root:2008_world_tela_002.json\n",
            "WARNING:root:2009_realty_australiangirl.json\n",
            "WARNING:root:2018_russia_ne_ostanov.json\n",
            "WARNING:root:2015_russia_mosww.json\n",
            "WARNING:root:2007_world_thai_001.json\n",
            "WARNING:root:2002_sport_fedor.json\n",
            "WARNING:root:2002_sport_lyzhisudrus.json\n",
            "WARNING:root:2020_blog_parad_002.json\n",
            "WARNING:root:2002_cinema_umri.json\n",
            "WARNING:root:2020_world_three_days.json\n",
            "WARNING:root:2011_hitech_ljdayafter.json\n",
            "WARNING:root:2012_realty_spears.json\n",
            "WARNING:root:2007_russia_busher_russians_stay.json\n",
            "WARNING:root:2013_russia_nevzlin_001.json\n",
            "WARNING:root:2017_world_use.json\n",
            "WARNING:root:2006_world_noga_001.json\n",
            "WARNING:root:2004_cinema_shalevich.json\n",
            "WARNING:root:2014_cinema_kim_002.json\n",
            "WARNING:root:2003_world_irprav.json\n",
            "WARNING:root:2016_world_reygan.json\n",
            "WARNING:root:2009_world_stringisenat.json\n",
            "WARNING:root:2008_world_suh_001.json\n",
            "WARNING:root:2004_sport_66476367673.json\n",
            "WARNING:root:2014_cinema_depeche_kiev.json\n",
            "WARNING:root:2007_finance_nordstream.json\n",
            "WARNING:root:2000_finance_opros.json\n",
            "WARNING:root:2002_world_texas_001.json\n",
            "WARNING:root:2003_russia_avaria_001.json\n",
            "WARNING:root:2003_finance_renault.json\n",
            "WARNING:root:2008_sport_ron_013.json\n",
            "WARNING:root:2002_russia_wearther1.json\n",
            "WARNING:root:2013_russia_adagamsovet.json\n",
            "WARNING:root:2003_world_great_grandson.json\n",
            "WARNING:root:2008_cinema_makeba.json\n",
            "WARNING:root:2014_russia_zarplaty.json\n",
            "WARNING:root:2002_world_vtor.json\n",
            "WARNING:root:2019_world_haftar.json\n",
            "WARNING:root:2010_realty_britains.json\n",
            "WARNING:root:2016_auto_yellow_line.json\n",
            "WARNING:root:2009_finance_retail_002.json\n",
            "WARNING:root:2020_auto_liksutov_taxi.json\n",
            "WARNING:root:2011_world_boot_007.json\n",
            "WARNING:root:2006_world_armeniya.json\n",
            "WARNING:root:2005_world_congress.json\n",
            "WARNING:root:2004_russia_fire_005.json\n",
            "WARNING:root:2016_world_tramp_005.json\n",
            "WARNING:root:2014_blog_zakon_008.json\n",
            "WARNING:root:2019_hitech_newintelcore.json\n",
            "WARNING:root:2001_world_corsica.json\n",
            "WARNING:root:2004_finance_tsb.json\n",
            "WARNING:root:2016_russia_dag_005.json\n",
            "WARNING:root:2016_world_drown.json\n",
            "WARNING:root:2014_world_porosh_007.json\n",
            "WARNING:root:2006_world_tvvv.json\n",
            "WARNING:root:2016_russia_yanukovitch.json\n",
            "WARNING:root:2010_world_uil.json\n",
            "WARNING:root:2002_russia_yahsgd.json\n",
            "WARNING:root:2014_blog_versal.json\n",
            "WARNING:root:2004_world_tanker_003.json\n",
            "WARNING:root:2009_russia_bus_002.json\n",
            "WARNING:root:2007_realty_rowling_005.json\n",
            "WARNING:root:2002_world_venus_002.json\n",
            "WARNING:root:2017_sport_under_fire.json\n",
            "WARNING:root:2002_sport_354756545.json\n",
            "WARNING:root:2018_russia_polyakov.json\n",
            "WARNING:root:2019_world_three_died.json\n",
            "WARNING:root:2015_blog_export.json\n",
            "WARNING:root:2012_auto_mos1.json\n",
            "WARNING:root:2008_russia_mids.json\n",
            "WARNING:root:2005_world_gong_001.json\n",
            "WARNING:root:2021_russia_mskfrostorange.json\n",
            "WARNING:root:2009_russia_raiting_003.json\n",
            "WARNING:root:2014_sport_teemu_001.json\n",
            "WARNING:root:2017_auto_venom.json\n",
            "WARNING:root:2018_cinema_katrin.json\n",
            "WARNING:root:2007_world_negotiations_003.json\n",
            "WARNING:root:2019_russia_navalny_food.json\n",
            "WARNING:root:2016_hitech_rknmirror.json\n",
            "WARNING:root:2009_finance_mleko.json\n",
            "WARNING:root:2015_blog_zanaves_003.json\n",
            "WARNING:root:2013_world_obamasyria.json\n",
            "WARNING:root:2013_sport_iron_mike.json\n",
            "WARNING:root:2010_sport_nal4ik_005.json\n",
            "WARNING:root:2009_world_engbus.json\n",
            "WARNING:root:2016_russia_putin_031.json\n",
            "WARNING:root:2007_world_cyprusrusskilled.json\n",
            "WARNING:root:2006_world_neuborne.json\n",
            "WARNING:root:2020_world_ulasik.json\n",
            "WARNING:root:2015_finance_captloutflow.json\n",
            "WARNING:root:2012_realty_msk_okna.json\n",
            "WARNING:root:2009_russia_dovgy.json\n",
            "WARNING:root:2001_sport_ievlev.json\n",
            "WARNING:root:2016_cinema_hamlet.json\n",
            "WARNING:root:2010_world_zinkblast.json\n",
            "WARNING:root:2010_finance_lat.json\n",
            "WARNING:root:2004_world_coins.json\n",
            "WARNING:root:2004_world_perenos_002.json\n",
            "WARNING:root:2013_finance_cnvsjpsea.json\n",
            "WARNING:root:2006_russia_samara_007.json\n",
            "WARNING:root:2003_world_journalist_002.json\n",
            "WARNING:root:2004_world_noterror.json\n",
            "WARNING:root:2004_finance_pavlenko.json\n",
            "WARNING:root:2007_world_pervyi.json\n",
            "WARNING:root:2001_world_10.json\n",
            "WARNING:root:2009_world_rus_ital.json\n",
            "WARNING:root:2010_world_dem_rep.json\n",
            "WARNING:root:2016_auto_prava.json\n",
            "WARNING:root:2006_world_samolet_015.json\n",
            "WARNING:root:2009_russia_boec21.json\n",
            "WARNING:root:2002_russia_ingushetiya_001.json\n",
            "WARNING:root:2009_russia_molnia.json\n",
            "WARNING:root:2017_russia_misharin.json\n",
            "WARNING:root:2005_russia_pris.json\n",
            "WARNING:root:2014_world_amnesty_004.json\n",
            "WARNING:root:2014_world_israel_006.json\n",
            "WARNING:root:2016_cinema_ansambl.json\n",
            "WARNING:root:2017_auto_tagil_rogozin.json\n",
            "WARNING:root:2000_world_india2.json\n",
            "WARNING:root:2009_cinema_terner.json\n",
            "WARNING:root:2014_russia_pobeda_001.json\n",
            "WARNING:root:2018_hitech_sudotkaz.json\n",
            "WARNING:root:2007_world_onu.json\n",
            "WARNING:root:2020_russia_mabyzov.json\n",
            "WARNING:root:2011_finance_gazukr_001.json\n",
            "WARNING:root:2001_russia_pochinok_003.json\n",
            "WARNING:root:2008_russia_chubais_002.json\n",
            "WARNING:root:2011_russia_piterhey.json\n",
            "WARNING:root:2015_world_guangchang.json\n",
            "WARNING:root:2011_world_arrest_005.json\n",
            "WARNING:root:2015_russia_bezopasnost.json\n",
            "WARNING:root:2004_russia_anotherrussia.json\n",
            "WARNING:root:2005_russia_dzasoxov.json\n",
            "WARNING:root:2015_world_seat.json\n",
            "WARNING:root:2017_russia_moscow_015.json\n",
            "WARNING:root:2013_auto_bonds.json\n",
            "WARNING:root:2001_sport_76763332.json\n",
            "WARNING:root:2008_world_pakisquake.json\n",
            "WARNING:root:2007_world_plustwo.json\n",
            "WARNING:root:2009_finance_zp_grey.json\n",
            "WARNING:root:2011_russia_andreypopov.json\n",
            "WARNING:root:2003_finance_mrot_002.json\n",
            "WARNING:root:2017_blog_sorrow.json\n",
            "WARNING:root:2015_world_owlcapone.json\n",
            "WARNING:root:2004_sport_dynamo.json\n",
            "WARNING:root:2015_russia_pivovarov_004.json\n",
            "WARNING:root:2005_world_bereza_017.json\n",
            "WARNING:root:2009_russia_afgan_002.json\n",
            "WARNING:root:2013_russia_farber_court.json\n",
            "WARNING:root:2012_finance_opora.json\n",
            "WARNING:root:2001_world_kosovo_020.json\n",
            "WARNING:root:2015_russia_feigin.json\n",
            "WARNING:root:2016_auto_womanauto.json\n",
            "WARNING:root:2011_world_nazarata.json\n",
            "WARNING:root:2002_russia_korolev2.json\n",
            "WARNING:root:2002_world_kf.json\n",
            "WARNING:root:2012_realty_sadovoe.json\n",
            "WARNING:root:2002_russia_spid.json\n",
            "WARNING:root:2013_world_nomoneynaorion.json\n",
            "WARNING:root:2004_russia_276.json\n",
            "WARNING:root:2006_world_star_004.json\n",
            "WARNING:root:2005_sport_woman.json\n",
            "WARNING:root:2012_sport_clubs.json\n",
            "WARNING:root:2012_sport_fursenko_001.json\n",
            "WARNING:root:2001_russia_duma_mneniya.json\n",
            "WARNING:root:2001_finance_mrot.json\n",
            "WARNING:root:2020_hitech_ai_tax.json\n",
            "WARNING:root:2002_finance_opek_002.json\n",
            "WARNING:root:2011_russia_kasper_003.json\n",
            "WARNING:root:2013_auto_cabrio.json\n",
            "WARNING:root:2002_world_ramsf.json\n",
            "WARNING:root:2015_russia_piglets.json\n",
            "WARNING:root:2005_russia_kuku.json\n",
            "WARNING:root:2011_realty_strahovanie.json\n",
            "WARNING:root:2019_sport_atlreal_001.json\n",
            "WARNING:root:2005_russia_sibir.json\n",
            "WARNING:root:2017_cinema_orel.json\n",
            "WARNING:root:2016_world_frblast.json\n",
            "WARNING:root:2012_realty_detsky_mir.json\n",
            "WARNING:root:2009_finance_sibir_005.json\n",
            "WARNING:root:2003_world_miting_008.json\n",
            "WARNING:root:2014_world_oscereklama.json\n",
            "WARNING:root:2018_russia_zhdanova.json\n",
            "WARNING:root:2015_world_polska_003.json\n",
            "WARNING:root:2006_cinema_vyst_004.json\n",
            "WARNING:root:2004_russia_nord_016.json\n",
            "WARNING:root:2002_sport_78687585.json\n",
            "WARNING:root:2010_russia_nogaideli.json\n",
            "WARNING:root:2007_russia_lebedev_010.json\n",
            "WARNING:root:2009_finance_rosstat_007.json\n",
            "WARNING:root:2004_sport_safina.json\n",
            "WARNING:root:2010_russia_sokratilos.json\n",
            "WARNING:root:2012_world_israelbus.json\n",
            "WARNING:root:2006_cinema_shaxnazarov.json\n",
            "WARNING:root:2014_realty_orange_001.json\n",
            "WARNING:root:2001_world_sov_gen.json\n",
            "WARNING:root:2004_sport_longorecap.json\n",
            "WARNING:root:2012_blog_pensreform_001.json\n",
            "WARNING:root:2005_russia_kids.json\n",
            "WARNING:root:2004_russia_newstant.json\n",
            "WARNING:root:2003_world_saddam23.json\n",
            "WARNING:root:2000_russia_otstavka_001.json\n",
            "WARNING:root:2013_auto_xq_roadtest.json\n",
            "WARNING:root:2012_world_syrianaffair.json\n",
            "WARNING:root:2020_russia_nagrada.json\n",
            "WARNING:root:2004_world_act_001.json\n",
            "WARNING:root:2001_russia_moscow_tunn.json\n",
            "WARNING:root:2019_hitech_dragonisback2.json\n",
            "WARNING:root:2015_world_separatists.json\n",
            "WARNING:root:2014_sport_carlos_001.json\n",
            "WARNING:root:2009_cinema_gulag.json\n",
            "WARNING:root:2017_world_koreya.json\n",
            "WARNING:root:2017_russia_antiter.json\n",
            "WARNING:root:2006_russia_chek_001.json\n",
            "WARNING:root:2018_russia_uragan_002.json\n",
            "WARNING:root:2013_russia_toljatti.json\n",
            "WARNING:root:2014_hitech_medglass.json\n",
            "WARNING:root:2012_russia_9partii.json\n",
            "WARNING:root:2008_cinema_rnb.json\n",
            "WARNING:root:2010_russia_progress_001.json\n",
            "WARNING:root:2008_sport_air_002.json\n",
            "WARNING:root:2011_russia_medved_006.json\n",
            "WARNING:root:2014_sport_jasper.json\n",
            "WARNING:root:2009_realty_polveka.json\n",
            "WARNING:root:2015_realty_msk_cafes.json\n",
            "WARNING:root:2013_russia_sms_002.json\n",
            "WARNING:root:2001_russia_alexluka.json\n",
            "WARNING:root:2003_world_sok3.json\n",
            "WARNING:root:2009_russia_ugolov_perm.json\n",
            "WARNING:root:2020_sport_nhl_012.json\n",
            "WARNING:root:2012_russia_genproc_003.json\n",
            "WARNING:root:2009_sport_spall_001.json\n",
            "WARNING:root:2015_auto_sportage_new.json\n",
            "WARNING:root:2008_realty_turn.json\n",
            "WARNING:root:2002_sport_lewiscourt.json\n",
            "WARNING:root:2012_sport_ruslat_001.json\n",
            "WARNING:root:2005_sport_uve.json\n",
            "WARNING:root:2013_finance_osklawsuit.json\n",
            "WARNING:root:2000_world_boxes_001.json\n",
            "WARNING:root:2006_russia_soldat.json\n",
            "WARNING:root:2017_finance_counterfeit_money_crime.json\n",
            "WARNING:root:2004_russia_nopresents.json\n",
            "WARNING:root:2003_world_plennye_001.json\n",
            "WARNING:root:2004_world_russish.json\n",
            "WARNING:root:2012_russia_piterpu.json\n",
            "WARNING:root:2018_world_byebyebikini.json\n",
            "WARNING:root:2003_world_memorialminsk.json\n",
            "WARNING:root:2016_world_espch_008.json\n",
            "WARNING:root:2001_russia_tolstoshein_001.json\n",
            "WARNING:root:2014_russia_vybory_007.json\n",
            "WARNING:root:2008_cinema_witney.json\n",
            "WARNING:root:2003_russia_karmadon_006.json\n",
            "WARNING:root:2014_sport_pavel_004.json\n",
            "WARNING:root:2001_russia_uff.json\n",
            "WARNING:root:2014_world_lufthansa_001.json\n",
            "WARNING:root:2004_russia_fire_013.json\n",
            "WARNING:root:2009_world_refer.json\n",
            "WARNING:root:2004_russia_patr.json\n",
            "WARNING:root:2018_world_tsar_005.json\n",
            "WARNING:root:2016_auto_google_flying.json\n",
            "WARNING:root:2008_russia_o_sport.json\n",
            "WARNING:root:2003_cinema_aedonitskij.json\n",
            "WARNING:root:2018_cinema_crimea_002.json\n",
            "WARNING:root:2014_realty_chuck.json\n",
            "WARNING:root:2001_russia_gerashenko_001.json\n",
            "WARNING:root:2014_cinema_adeliga.json\n",
            "WARNING:root:2004_russia_dfr.json\n",
            "WARNING:root:2011_realty_grant_thinhouse.json\n",
            "WARNING:root:2008_finance_decline.json\n",
            "WARNING:root:2007_auto_dodge_003.json\n",
            "WARNING:root:2014_cinema_devotchenko_002.json\n",
            "WARNING:root:2012_russia_udaltzov10mln.json\n",
            "WARNING:root:2006_world_franc.json\n",
            "WARNING:root:2010_sport_raul.json\n",
            "WARNING:root:2015_finance_oilhardtalks.json\n",
            "WARNING:root:2010_finance_eurocement.json\n",
            "WARNING:root:2013_world_laden.json\n",
            "WARNING:root:2016_blog_referendum.json\n",
            "WARNING:root:2012_world_war.json\n",
            "WARNING:root:2004_finance_10.json\n",
            "WARNING:root:2017_world_muallem.json\n",
            "WARNING:root:2009_sport_personal_001.json\n",
            "WARNING:root:2008_realty_section106.json\n",
            "WARNING:root:2013_finance_cyprus_005.json\n",
            "WARNING:root:2015_russia_fms_006.json\n",
            "WARNING:root:2004_world_stanok.json\n",
            "WARNING:root:2014_russia_dumakomitet.json\n",
            "WARNING:root:2003_russia_ekologi.json\n",
            "WARNING:root:2001_world_blair_saidthis.json\n",
            "WARNING:root:2006_world_kosovo_012.json\n",
            "WARNING:root:2013_world_obamanew.json\n",
            "WARNING:root:2008_russia_collider_001.json\n",
            "WARNING:root:2006_world_castro.json\n",
            "WARNING:root:2007_russia_ubitt.json\n",
            "WARNING:root:2009_finance_vodka_002.json\n",
            "WARNING:root:2012_cinema_underwood.json\n",
            "WARNING:root:2007_finance_arbitrazh.json\n",
            "WARNING:root:2003_world_unspy.json\n",
            "WARNING:root:2004_sport_65788362.json\n",
            "WARNING:root:2004_world_marocco.json\n",
            "WARNING:root:2002_sport_847639754.json\n",
            "WARNING:root:2020_realty_mos_elite.json\n",
            "WARNING:root:2012_russia_raining.json\n",
            "WARNING:root:2015_blog_prezident.json\n",
            "WARNING:root:2003_world_lazy.json\n",
            "WARNING:root:2007_auto_kia_002.json\n",
            "WARNING:root:2008_world_predely.json\n",
            "WARNING:root:2009_russia_pls.json\n",
            "WARNING:root:2004_world_ali.json\n",
            "WARNING:root:2015_russia_crimplane.json\n",
            "WARNING:root:2012_hitech_win8reldate.json\n",
            "WARNING:root:2004_world_kurei_003.json\n",
            "WARNING:root:2001_russia_posredniki.json\n",
            "WARNING:root:2019_world_europarliament.json\n",
            "WARNING:root:2019_blog_podpisi_001.json\n",
            "WARNING:root:2017_world_armenia_003.json\n",
            "WARNING:root:2015_russia_putincon.json\n",
            "WARNING:root:2013_hitech_plsttionmobgams.json\n",
            "WARNING:root:2013_russia_baum_002.json\n",
            "WARNING:root:2004_russia_lagb.json\n",
            "WARNING:root:2016_russia_bragin.json\n",
            "WARNING:root:2015_russia_uralvagonzavod.json\n",
            "WARNING:root:2012_blog_pechati.json\n",
            "WARNING:root:2015_auto_school_drink.json\n",
            "WARNING:root:2008_russia_rsf2008.json\n",
            "WARNING:root:2005_finance_vodela.json\n",
            "WARNING:root:2004_russia_titanic.json\n",
            "WARNING:root:2005_world_potop_002.json\n",
            "WARNING:root:2014_hitech_samsunghack.json\n",
            "WARNING:root:2015_sport_old_school.json\n",
            "WARNING:root:2005_russia_shahta_004.json\n",
            "WARNING:root:2008_finance_deriplyaska.json\n",
            "WARNING:root:2014_world_stenin_008.json\n",
            "WARNING:root:2009_hitech_newrecord.json\n",
            "WARNING:root:2008_russia_melnikoff.json\n",
            "WARNING:root:2019_russia_polygyny.json\n",
            "WARNING:root:2000_finance_cb_001.json\n",
            "WARNING:root:2013_realty_kamennoost.json\n",
            "WARNING:root:2013_finance_uaruborder.json\n",
            "WARNING:root:2010_russia_konon.json\n",
            "WARNING:root:2011_russia_pavlovs.json\n",
            "WARNING:root:2016_hitech_xiaomivr.json\n",
            "WARNING:root:2020_blog_navalny_novichok.json\n",
            "WARNING:root:2005_world_proval_001.json\n",
            "WARNING:root:2001_cinema_u2.json\n",
            "WARNING:root:2010_finance_shtockman_001.json\n",
            "WARNING:root:2013_world_lowest.json\n",
            "WARNING:root:2017_world_fbdelfake.json\n",
            "WARNING:root:2009_russia_ege_011.json\n",
            "WARNING:root:2015_finance_oilpricesiran.json\n",
            "WARNING:root:2013_sport_fed_001.json\n",
            "WARNING:root:2005_finance_poland.json\n",
            "WARNING:root:2002_sport_938396486.json\n",
            "WARNING:root:2003_russia_moscow_phone.json\n",
            "WARNING:root:2008_world_anekdot.json\n",
            "WARNING:root:2018_hitech_deepquake.json\n",
            "WARNING:root:2016_world_1marsshot.json\n",
            "WARNING:root:2010_hitech_partia.json\n",
            "WARNING:root:2011_cinema_monk.json\n",
            "WARNING:root:2015_blog_zakupki.json\n",
            "WARNING:root:2003_russia_rezzz.json\n",
            "WARNING:root:2013_russia_dolgi_005.json\n",
            "WARNING:root:2002_russia_anna_001.json\n",
            "WARNING:root:2007_russia_otkluchenie.json\n",
            "WARNING:root:2017_russia_kadyrov_026.json\n",
            "WARNING:root:2002_russia_avst.json\n",
            "WARNING:root:2007_russia_sale_002.json\n",
            "WARNING:root:2004_finance_pfr_002.json\n",
            "WARNING:root:2018_russia_vallenberg.json\n",
            "WARNING:root:2004_world_mars_014.json\n",
            "WARNING:root:2012_russia_raz_002.json\n",
            "WARNING:root:2005_world_farting.json\n",
            "WARNING:root:2005_sport_match.json\n",
            "WARNING:root:2013_cinema_zolot.json\n",
            "WARNING:root:2008_realty_bulg_001.json\n",
            "WARNING:root:2016_sport_povetkin_009.json\n",
            "WARNING:root:2005_sport_moskva_007.json\n",
            "WARNING:root:2013_world_hasanoff.json\n",
            "WARNING:root:2004_world_cars_005.json\n",
            "WARNING:root:2002_russia_utekay.json\n",
            "WARNING:root:2015_world_belarus_002.json\n",
            "WARNING:root:2013_russia_kirov_005.json\n",
            "WARNING:root:2006_world_soccer.json\n",
            "WARNING:root:2011_russia_pogoda_002.json\n",
            "WARNING:root:2013_russia_a320_001.json\n",
            "WARNING:root:2016_russia_dolina.json\n",
            "WARNING:root:2007_finance_hodor.json\n",
            "WARNING:root:2019_russia_novorossiysk.json\n",
            "WARNING:root:2001_world_klon_003.json\n",
            "WARNING:root:2019_sport_finalten.json\n",
            "WARNING:root:2005_world_garage_002.json\n",
            "WARNING:root:2014_realty_arhangel_les.json\n",
            "WARNING:root:2012_realty_beckham.json\n",
            "WARNING:root:2010_world_comiss.json\n",
            "WARNING:root:2001_russia_kogot.json\n",
            "WARNING:root:2013_finance_kzgasgazprom.json\n",
            "WARNING:root:2010_russia_ast.json\n",
            "WARNING:root:2013_russia_dtp_031.json\n",
            "WARNING:root:2003_sport_rusgooff.json\n",
            "WARNING:root:2015_sport_dini.json\n",
            "WARNING:root:2006_world_dot.json\n",
            "WARNING:root:2008_hitech_xbox360.json\n",
            "WARNING:root:2012_russia_dojdi.json\n",
            "WARNING:root:2016_finance_swiftiranbnks.json\n",
            "WARNING:root:2012_hitech_fcbk4ipo.json\n",
            "WARNING:root:2013_realty_friske.json\n",
            "WARNING:root:2017_cinema_avatar.json\n",
            "WARNING:root:2001_finance_ebrd.json\n",
            "WARNING:root:2018_russia_dagestan_003.json\n",
            "WARNING:root:2014_russia_visas.json\n",
            "WARNING:root:2008_auto_micra.json\n",
            "WARNING:root:2007_russia_spravv.json\n",
            "WARNING:root:2008_russia_glonass_011.json\n",
            "WARNING:root:2017_russia_sestroretsck.json\n",
            "WARNING:root:2013_blog_amnesty_004.json\n",
            "WARNING:root:2013_russia_adagamov_003.json\n",
            "WARNING:root:2020_hitech_anymalc_lake.json\n",
            "WARNING:root:2009_world_dmz.json\n",
            "WARNING:root:2011_world_smi4.json\n",
            "WARNING:root:2013_sport_jose_007.json\n",
            "WARNING:root:2013_world_glazgo.json\n",
            "WARNING:root:2010_finance_cbrf_009.json\n",
            "WARNING:root:2012_world_golod_003.json\n",
            "WARNING:root:2017_world_shuppebid.json\n",
            "WARNING:root:2013_russia_dvorkovich_001.json\n",
            "WARNING:root:2012_sport_sovfed_010.json\n",
            "WARNING:root:2001_russia_kodeks.json\n",
            "WARNING:root:2005_russia_sho.json\n",
            "WARNING:root:2000_world_peacetalk.json\n",
            "WARNING:root:2015_russia_mak_004.json\n",
            "WARNING:root:2007_sport_gold_009.json\n",
            "WARNING:root:2010_finance_repubblica.json\n",
            "WARNING:root:2014_cinema_mansky.json\n",
            "WARNING:root:2011_realty_young_sci.json\n",
            "WARNING:root:2014_russia_reklama_005.json\n",
            "WARNING:root:2015_hitech_amazon_free.json\n",
            "WARNING:root:2017_blog_gift.json\n",
            "WARNING:root:2016_russia_ptnabe.json\n",
            "WARNING:root:2000_sport_ural_001.json\n",
            "WARNING:root:2009_russia_zrk.json\n",
            "WARNING:root:2009_russia_k_arrest.json\n",
            "WARNING:root:2004_world_manila_001.json\n",
            "WARNING:root:2018_cinema_mmkf_001.json\n",
            "WARNING:root:2021_world_gaza_rocket.json\n",
            "WARNING:root:2016_hitech_furze_001.json\n",
            "WARNING:root:2002_finance_mc_001.json\n",
            "WARNING:root:2017_russia_poland.json\n",
            "WARNING:root:2001_finance_alrosa_004.json\n",
            "WARNING:root:2017_russia_firerostovdon.json\n",
            "WARNING:root:2004_russia_skuter.json\n",
            "WARNING:root:2015_russia_petrozavodsk.json\n",
            "WARNING:root:2009_world_shamba.json\n",
            "WARNING:root:2007_world_japan_024.json\n",
            "WARNING:root:2010_sport_womman.json\n",
            "WARNING:root:2011_auto_gaec_001.json\n",
            "WARNING:root:2013_russia_progress_007.json\n",
            "WARNING:root:2002_finance_gazprom_021.json\n",
            "WARNING:root:2004_world_escaper.json\n",
            "WARNING:root:2021_russia_safronov_002.json\n",
            "WARNING:root:2001_sport_93446213.json\n",
            "WARNING:root:2010_hitech_digiteka.json\n",
            "WARNING:root:2009_russia_zakatali.json\n",
            "WARNING:root:2019_sport_beer_007.json\n",
            "WARNING:root:2003_russia_russia_009.json\n",
            "WARNING:root:2013_russia_uk.json\n",
            "WARNING:root:2016_blog_answer_001.json\n",
            "WARNING:root:2016_auto_znaki_barany.json\n",
            "WARNING:root:2015_russia_aids_004.json\n",
            "WARNING:root:2010_russia_4p_002.json\n",
            "WARNING:root:2006_world_tbil_003.json\n",
            "WARNING:root:2014_russia_dolg_001.json\n",
            "WARNING:root:2006_world_frem.json\n",
            "WARNING:root:2019_realty_liberal_silovik.json\n",
            "WARNING:root:2013_finance_koudrine.json\n",
            "WARNING:root:2007_sport_sha.json\n",
            "WARNING:root:2010_sport_semin_004.json\n",
            "WARNING:root:2004_world_bush_go_home.json\n",
            "WARNING:root:2013_world_belgie.json\n",
            "WARNING:root:2013_sport_pich_002.json\n",
            "WARNING:root:2001_world_car_bomb_002.json\n",
            "WARNING:root:2012_world_superjet_004.json\n",
            "WARNING:root:2003_finance_buffet_001.json\n",
            "WARNING:root:2014_world_gagauzia.json\n",
            "WARNING:root:2012_finance_rudepstinsurnce.json\n",
            "WARNING:root:2012_blog_uchitel_001.json\n",
            "WARNING:root:2010_cinema_ff_alice.json\n",
            "WARNING:root:2002_finance_almaz.json\n",
            "WARNING:root:2018_world_skripal_023.json\n",
            "WARNING:root:2004_cinema_elvis_002.json\n",
            "WARNING:root:2013_world_timo_002.json\n",
            "WARNING:root:2003_world_arafat__002.json\n",
            "WARNING:root:2014_cinema_rozhdestvsk.json\n",
            "WARNING:root:2002_world_faraon_002.json\n",
            "WARNING:root:2008_auto_corsa.json\n",
            "WARNING:root:2020_blog_habarovsk_003.json\n",
            "WARNING:root:2010_russia_gess.json\n",
            "WARNING:root:2007_sport_cro.json\n",
            "WARNING:root:2001_russia_meskhet.json\n",
            "WARNING:root:2010_world_seabreeze.json\n",
            "WARNING:root:2015_russia_ranets.json\n",
            "WARNING:root:2006_russia_mashinki.json\n",
            "WARNING:root:2000_russia_mediamost_003.json\n",
            "WARNING:root:2014_sport_ski_prepare.json\n",
            "WARNING:root:2008_cinema_negotiations.json\n",
            "WARNING:root:2015_cinema_mvd_001.json\n",
            "WARNING:root:2003_sport_536376544.json\n",
            "WARNING:root:2008_world_h9n2.json\n",
            "WARNING:root:2003_world_tour_006.json\n",
            "WARNING:root:2004_cinema_stepankov.json\n",
            "WARNING:root:2006_world_oon_010.json\n",
            "WARNING:root:2004_russia_av.json\n",
            "WARNING:root:2001_russia_ramenskoe.json\n",
            "WARNING:root:2016_russia_barviha_010.json\n",
            "WARNING:root:2005_world_terra_030.json\n",
            "WARNING:root:2010_hitech_ilrafael.json\n",
            "WARNING:root:2014_sport_graf.json\n",
            "WARNING:root:2007_russia_dor.json\n",
            "WARNING:root:2002_world_neudacha.json\n",
            "WARNING:root:2014_finance_uacrimeagrivna.json\n",
            "WARNING:root:2015_russia_kogalym.json\n",
            "WARNING:root:2008_world_4boatsfor2days.json\n",
            "WARNING:root:2016_world_negotiation.json\n",
            "WARNING:root:2015_world_shotdead.json\n",
            "WARNING:root:2005_russia_kodi.json\n",
            "WARNING:root:2013_finance_fas_avia.json\n",
            "WARNING:root:2008_russia_nagradil.json\n",
            "WARNING:root:2009_finance_stroyzhilje.json\n",
            "WARNING:root:2010_realty_kommumalka.json\n",
            "WARNING:root:2013_hitech_sonyglasses2dsp.json\n",
            "WARNING:root:2002_sport_kaddafootball.json\n",
            "WARNING:root:2002_world_narva2.json\n",
            "WARNING:root:2004_world_fastfood.json\n",
            "WARNING:root:2015_sport_bulki.json\n",
            "WARNING:root:2002_world_strike_004.json\n",
            "WARNING:root:2017_russia_mir_004.json\n",
            "WARNING:root:2005_world_denmark.json\n",
            "WARNING:root:2006_world_muids.json\n",
            "WARNING:root:2020_world_fire_easter.json\n",
            "WARNING:root:2016_russia_deloclosed.json\n",
            "WARNING:root:2012_blog_merkel.json\n",
            "WARNING:root:2021_world_sanct_gosdolg.json\n",
            "WARNING:root:2001_russia_nachodka_002.json\n",
            "WARNING:root:2020_russia_ishaev.json\n",
            "WARNING:root:2009_auto_gazel.json\n",
            "WARNING:root:2017_blog_antikachestvo.json\n",
            "WARNING:root:2005_russia_advokati_003.json\n",
            "WARNING:root:2005_world_taliby.json\n",
            "WARNING:root:2000_world_mvf_001.json\n",
            "WARNING:root:2006_russia_mrot_003.json\n",
            "WARNING:root:2011_cinema_pakis.json\n",
            "WARNING:root:2011_world_cassini_tstorm.json\n",
            "WARNING:root:2015_world_bellingcat_001.json\n",
            "WARNING:root:2016_auto_vw_sbrnds.json\n",
            "WARNING:root:2016_cinema_newvawe.json\n",
            "WARNING:root:2011_world_tadj_002.json\n",
            "WARNING:root:2008_finance_globeks.json\n",
            "WARNING:root:2012_finance_fas_003.json\n",
            "WARNING:root:2004_sport_travma.json\n",
            "WARNING:root:2000_finance_pension_dvor.json\n",
            "WARNING:root:2011_sport_tickets_003.json\n",
            "WARNING:root:2001_world_afganstatues_completedestroyed.json\n",
            "WARNING:root:2016_world_mi_001.json\n",
            "WARNING:root:2004_world_vert_014.json\n",
            "WARNING:root:2002_russia_99.json\n",
            "WARNING:root:2006_sport_lippi_001.json\n",
            "WARNING:root:2005_finance_chechem.json\n",
            "WARNING:root:2018_world_granitza.json\n",
            "WARNING:root:2017_cinema_buryat.json\n",
            "WARNING:root:2019_realty_mos_tc_arenda.json\n",
            "WARNING:root:2007_finance_dollrz_002.json\n",
            "WARNING:root:2001_russia_zelenogorsk.json\n",
            "WARNING:root:2012_auto_m-10_dtp.json\n",
            "WARNING:root:2016_world_scorpbanan.json\n",
            "WARNING:root:2010_world_poroshenko.json\n",
            "WARNING:root:2017_russia_suicide_003.json\n",
            "WARNING:root:2006_sport_mil_004.json\n",
            "WARNING:root:2004_world_jhnasa.json\n",
            "WARNING:root:2003_world_750_arrested.json\n",
            "WARNING:root:2005_russia_fanfan.json\n",
            "WARNING:root:2008_russia_obstrel_016.json\n",
            "WARNING:root:2009_russia_patrushev_001.json\n",
            "WARNING:root:2005_world_segk.json\n",
            "WARNING:root:2013_world_larisa.json\n",
            "WARNING:root:2011_finance_iran_oil.json\n",
            "WARNING:root:2009_russia_kremluto4nil.json\n",
            "WARNING:root:2003_world_abu_002.json\n",
            "WARNING:root:2019_sport_penis.json\n",
            "WARNING:root:2006_realty_deadflat.json\n",
            "WARNING:root:2015_russia_shmel.json\n",
            "WARNING:root:2002_russia_vosstanovlenie.json\n",
            "WARNING:root:2009_sport_jordan.json\n",
            "WARNING:root:2001_world_laden_2.json\n",
            "WARNING:root:2014_russia_marsh_006.json\n",
            "WARNING:root:2015_realty_matkapital_001.json\n",
            "WARNING:root:2013_russia_udaltsov_002.json\n",
            "WARNING:root:2013_russia_surkov_005.json\n",
            "WARNING:root:2014_world_japan_019.json\n",
            "WARNING:root:2004_world_vdovy.json\n",
            "WARNING:root:2010_russia_komandovanija.json\n",
            "WARNING:root:2009_world_moldavelection.json\n",
            "WARNING:root:2021_sport_pony.json\n",
            "WARNING:root:2003_russia_rus_pupils.json\n",
            "WARNING:root:2004_sport_nhkrecap.json\n",
            "WARNING:root:2012_cinema_makarov.json\n",
            "WARNING:root:2008_sport_mar_004.json\n",
            "WARNING:root:2013_finance_yanukovich_002.json\n",
            "WARNING:root:2009_russia_kekin_001.json\n",
            "WARNING:root:2002_sport_5536327543.json\n",
            "WARNING:root:2018_russia_arest_001.json\n",
            "WARNING:root:2020_russia_himkiuik.json\n",
            "WARNING:root:2003_finance_pyracy_002.json\n",
            "WARNING:root:2009_world_endstrikesaberi.json\n",
            "WARNING:root:2001_world_cruisecruz.json\n",
            "WARNING:root:2007_auto_rolf.json\n",
            "WARNING:root:2017_world_suomidance.json\n",
            "WARNING:root:2005_world_warmbutcool.json\n",
            "WARNING:root:2007_realty_price_011.json\n",
            "WARNING:root:2018_world_investigation.json\n",
            "WARNING:root:2007_realty_zhkh_002.json\n",
            "WARNING:root:2015_sport_fifa_019.json\n",
            "WARNING:root:2010_realty_bandera.json\n",
            "WARNING:root:2011_hitech_ruclssmts.json\n",
            "WARNING:root:2006_world_ha.json\n",
            "WARNING:root:2008_auto_otboinik.json\n",
            "WARNING:root:2009_russia_asd_001.json\n",
            "WARNING:root:2018_world_hunt.json\n",
            "WARNING:root:2016_realty_spain_sales.json\n",
            "WARNING:root:2009_finance_newopel.json\n",
            "WARNING:root:2020_russia_duma_votes.json\n",
            "WARNING:root:2017_hitech_itmowin.json\n",
            "WARNING:root:2007_russia_viza_003.json\n",
            "WARNING:root:2011_russia_mokretsov.json\n",
            "WARNING:root:2000_world_pinochet_005.json\n",
            "WARNING:root:2018_blog_kiselev.json\n",
            "WARNING:root:2013_world_spyby.json\n",
            "WARNING:root:2004_world_vigipirate.json\n",
            "WARNING:root:2018_russia_peskov_014.json\n",
            "WARNING:root:2015_world_vienatalks.json\n",
            "WARNING:root:2012_world_churkin_002.json\n",
            "WARNING:root:2001_russia_kemerovo_002.json\n",
            "WARNING:root:2005_russia_mashadov_003.json\n",
            "WARNING:root:2012_blog_civilservice.json\n",
            "WARNING:root:2012_world_deathvalley.json\n",
            "WARNING:root:2009_hitech_antigua.json\n",
            "WARNING:root:2020_blog_obnulenie_002.json\n",
            "WARNING:root:2004_sport_75487438768.json\n",
            "WARNING:root:2017_russia_opros_024.json\n",
            "WARNING:root:2008_realty_outlaw.json\n",
            "WARNING:root:2019_russia_medvedavia.json\n",
            "WARNING:root:2001_russia_idrisov_001.json\n",
            "WARNING:root:2008_world_aviasecurity.json\n",
            "WARNING:root:2009_world_lhp.json\n",
            "WARNING:root:2017_cinema_innocence.json\n",
            "WARNING:root:2005_world_inaugur.json\n",
            "WARNING:root:2010_finance_vodka_fish.json\n",
            "WARNING:root:2003_sport_572388644.json\n",
            "WARNING:root:2011_hitech_fcbkencrptd.json\n",
            "WARNING:root:2016_finance_timesmlrd.json\n",
            "WARNING:root:2019_world_barrikades.json\n",
            "WARNING:root:2008_russia_raspredel.json\n",
            "WARNING:root:2006_russia_court_005.json\n",
            "WARNING:root:2005_russia_kirsan_001.json\n",
            "WARNING:root:2008_realty_uma.json\n",
            "WARNING:root:2004_cinema_rice.json\n",
            "WARNING:root:2001_russia_chechnya2_002.json\n",
            "WARNING:root:2005_russia_uhta_003.json\n",
            "WARNING:root:2009_world_prizn.json\n",
            "WARNING:root:2005_russia_fire_053.json\n",
            "WARNING:root:2009_sport_tenn.json\n",
            "WARNING:root:2004_finance_abr_001.json\n",
            "WARNING:root:2005_russia_mike_003.json\n",
            "WARNING:root:2013_world_berezovsky_006.json\n",
            "WARNING:root:2009_sport_biathlon_001.json\n",
            "WARNING:root:2008_world_malysh.json\n",
            "WARNING:root:2007_world_balu_004.json\n",
            "WARNING:root:2006_world_koroleva_001.json\n",
            "WARNING:root:2003_cinema_iraq_4.json\n",
            "WARNING:root:2011_cinema_mmkf_2.json\n",
            "WARNING:root:2001_world_liberation.json\n",
            "WARNING:root:2007_world_le_pen_boikot.json\n",
            "WARNING:root:2006_world_russpy.json\n",
            "WARNING:root:2012_russia_avia3000.json\n",
            "WARNING:root:2007_finance_medved_002.json\n",
            "WARNING:root:2013_hitech_carb.json\n",
            "WARNING:root:2009_world_ukr_vubor.json\n",
            "WARNING:root:2005_russia_agranovskaya.json\n",
            "WARNING:root:2007_russia_ldpr_005.json\n",
            "WARNING:root:2008_world_shreder.json\n",
            "WARNING:root:2009_russia_naryshkin.json\n",
            "WARNING:root:2007_world_lima2007.json\n",
            "WARNING:root:2017_world_kushner_001.json\n",
            "WARNING:root:2010_cinema_galkin_hosp.json\n",
            "WARNING:root:2000_russia_vino.json\n",
            "WARNING:root:2001_world_afganistan_dustum.json\n",
            "WARNING:root:2014_auto_hyundai_i20.json\n",
            "WARNING:root:2014_auto_prava_002.json\n",
            "WARNING:root:2001_world_prince_fall.json\n",
            "WARNING:root:2018_hitech_alicewin.json\n",
            "WARNING:root:2011_world_sarkozy_004.json\n",
            "WARNING:root:2008_world_gohome_002.json\n",
            "WARNING:root:2019_russia_4gulunov.json\n",
            "WARNING:root:2002_world_army_016.json\n",
            "WARNING:root:2007_world_harri.json\n",
            "WARNING:root:2005_russia_mitgf.json\n",
            "WARNING:root:2013_realty_dupak.json\n",
            "WARNING:root:2011_world_terr_009.json\n",
            "WARNING:root:2015_russia_omskveteran.json\n",
            "WARNING:root:2018_russia_zsd.json\n",
            "WARNING:root:2007_sport_pol_004.json\n",
            "WARNING:root:2009_world_kuchma_003.json\n",
            "WARNING:root:2013_finance_americanusmerger.json\n",
            "WARNING:root:2019_finance_four_uslovia.json\n",
            "WARNING:root:2017_russia_boy_006.json\n",
            "WARNING:root:2007_realty_obshe.json\n",
            "WARNING:root:2014_world_yanukswiss.json\n",
            "WARNING:root:2010_hitech_dewifi.json\n",
            "WARNING:root:2004_world_kiev_002.json\n",
            "WARNING:root:2002_cinema_pianino.json\n",
            "WARNING:root:2014_cinema_zimin.json\n",
            "WARNING:root:2005_world_stuard.json\n",
            "WARNING:root:2009_cinema_booker_001.json\n",
            "WARNING:root:2012_russia_scream_001.json\n",
            "WARNING:root:2014_cinema_tarantino_002.json\n",
            "WARNING:root:2007_auto_wheels.json\n",
            "WARNING:root:2005_world_bb_008.json\n",
            "WARNING:root:2005_finance_gm_001.json\n",
            "WARNING:root:2002_world_fedya_002.json\n",
            "WARNING:root:2014_sport_step_010.json\n",
            "WARNING:root:2006_sport_refree_005.json\n",
            "WARNING:root:2005_finance_kudrin_006.json\n",
            "WARNING:root:2003_world_bagdad_007.json\n",
            "WARNING:root:2009_world_magdalena.json\n",
            "WARNING:root:2009_world_airsarko1.json\n",
            "WARNING:root:2004_sport_fed_pred.json\n",
            "WARNING:root:2012_world_maps_001.json\n",
            "WARNING:root:2016_realty_katy_perry.json\n",
            "WARNING:root:2015_finance_chmnftgaz.json\n",
            "WARNING:root:2017_world_sav.json\n",
            "WARNING:root:2014_world_lost_001.json\n",
            "WARNING:root:2006_russia_pandemy.json\n",
            "WARNING:root:2011_world_tuleni.json\n",
            "WARNING:root:2012_russia_museum_003.json\n",
            "WARNING:root:2018_russia_eshelon.json\n",
            "WARNING:root:2007_auto_Bentley.json\n",
            "WARNING:root:2016_world_unacabra.json\n",
            "WARNING:root:2020_sport_prez.json\n",
            "WARNING:root:2006_world_golodo_001.json\n",
            "WARNING:root:2004_cinema_mmkf_001.json\n",
            "WARNING:root:2004_sport_nhlrecap_003.json\n",
            "WARNING:root:2003_russia_fair_005.json\n",
            "WARNING:root:2006_world_budget_005.json\n",
            "WARNING:root:2018_hitech_fsb_yarovaya.json\n",
            "WARNING:root:2001_russia_damage_002.json\n",
            "WARNING:root:2008_world_isl.json\n",
            "WARNING:root:2012_world_kanzas.json\n",
            "WARNING:root:2005_russia_shender_002.json\n",
            "WARNING:root:2020_world_fourth_elections.json\n",
            "WARNING:root:2013_blog_german.json\n",
            "WARNING:root:2013_world_borodin_006.json\n",
            "WARNING:root:2009_realty_glavstroy_006.json\n",
            "WARNING:root:2001_russia_school2.json\n",
            "WARNING:root:2004_sport_56378286333.json\n",
            "WARNING:root:2020_blog_moment_001.json\n",
            "WARNING:root:2017_hitech_samsvideo.json\n",
            "WARNING:root:2020_russia_sizo_map.json\n",
            "WARNING:root:2011_russia_zahvati.json\n",
            "WARNING:root:2005_world_vert_015.json\n",
            "WARNING:root:2016_world_kpintadjikistan.json\n",
            "WARNING:root:2012_auto_buup.json\n",
            "WARNING:root:2008_sport_youth_005.json\n",
            "WARNING:root:2007_realty_laws_001.json\n",
            "WARNING:root:2011_cinema_markina.json\n",
            "WARNING:root:2004_russia_lavrov_006.json\n",
            "WARNING:root:2012_blog_velma.json\n",
            "WARNING:root:2009_russia_utonul.json\n",
            "WARNING:root:2011_sport_arena.json\n",
            "WARNING:root:2011_russia_minh_001.json\n",
            "WARNING:root:2020_realty_ostrov_mechty.json\n",
            "WARNING:root:2003_world_istambul.json\n",
            "WARNING:root:2016_world_france_017.json\n",
            "WARNING:root:2004_world_russia_nato.json\n",
            "WARNING:root:2007_russia_negotiations.json\n",
            "WARNING:root:2006_world_blair_005.json\n",
            "WARNING:root:2009_hitech_glonass_003.json\n",
            "WARNING:root:2012_russia_kutuzovsk.json\n",
            "WARNING:root:2005_world_israel_002.json\n",
            "WARNING:root:2001_world_internet_011.json\n",
            "WARNING:root:2003_russia_versh.json\n",
            "WARNING:root:2004_world_saakzhvan.json\n",
            "WARNING:root:2011_world_london_021.json\n",
            "WARNING:root:2014_world_malala_portret.json\n",
            "WARNING:root:2005_world_iranur.json\n",
            "WARNING:root:2008_russia_mike_012.json\n",
            "WARNING:root:2020_sport_ovi.json\n",
            "WARNING:root:2016_russia_yamal_005.json\n",
            "WARNING:root:2017_blog_godblessusa.json\n",
            "WARNING:root:2017_world_consequences_001.json\n",
            "WARNING:root:2012_realty_nedolshiki.json\n",
            "WARNING:root:2000_world_prelimres.json\n",
            "WARNING:root:2014_russia_ptnarctika.json\n",
            "WARNING:root:2015_russia_gonka.json\n",
            "WARNING:root:2013_realty_madrid_001.json\n",
            "WARNING:root:2001_world_havel_002.json\n",
            "WARNING:root:2014_russia_strongina.json\n",
            "WARNING:root:2009_world_luna_002.json\n",
            "WARNING:root:2015_sport_beer_004.json\n",
            "WARNING:root:2004_world_bagdad_005.json\n",
            "WARNING:root:2013_realty_inopressa_sochi.json\n",
            "WARNING:root:2013_sport_runners_001.json\n",
            "WARNING:root:2017_world_melania_003.json\n",
            "WARNING:root:2006_finance_tnkbp_004.json\n",
            "WARNING:root:2010_finance_master_putin.json\n",
            "WARNING:root:2020_russia_nopoison.json\n",
            "WARNING:root:2009_hitech_glonass_002.json\n",
            "WARNING:root:2013_russia_portrait.json\n",
            "WARNING:root:2009_russia_spa.json\n",
            "WARNING:root:2005_russia_archy.json\n",
            "WARNING:root:2013_world_kniga.json\n",
            "WARNING:root:2005_sport_kuffur.json\n",
            "WARNING:root:2016_world_trump_4.json\n",
            "WARNING:root:2004_world_2marines.json\n",
            "WARNING:root:2010_world_gaiti_003.json\n",
            "WARNING:root:2016_world_polandbrexit.json\n",
            "WARNING:root:2003_cinema_fatushin_001.json\n",
            "WARNING:root:2007_russia_sitnikov.json\n",
            "WARNING:root:2017_finance_priceoil.json\n",
            "WARNING:root:2006_sport_bartez_001.json\n",
            "WARNING:root:2012_finance_nanochubays.json\n",
            "WARNING:root:2016_russia_sk_002.json\n",
            "WARNING:root:2012_cinema_dprd.json\n",
            "WARNING:root:2008_russia_miry.json\n",
            "WARNING:root:2008_sport_fia_003.json\n",
            "WARNING:root:2012_russia_amnistia.json\n",
            "WARNING:root:2001_finance_gerash_001.json\n",
            "WARNING:root:2007_finance_trade_002.json\n",
            "WARNING:root:2001_cinema_tale.json\n",
            "WARNING:root:2017_sport_ham_004.json\n",
            "WARNING:root:2017_world_signal.json\n",
            "WARNING:root:2004_world_kongo2.json\n",
            "WARNING:root:2003_russia_yakutia3.json\n",
            "WARNING:root:2004_world_5mlnwant.json\n",
            "WARNING:root:2002_world_arktica3.json\n",
            "WARNING:root:2014_realty_berwind_roman.json\n",
            "WARNING:root:2001_russia_lensk_006.json\n",
            "WARNING:root:2020_world_scoutsfounder.json\n",
            "WARNING:root:2006_world_saak_009.json\n",
            "WARNING:root:2005_world_arutunan.json\n",
            "WARNING:root:2008_russia_deboshir_002.json\n",
            "WARNING:root:2009_world_gudzon.json\n",
            "WARNING:root:2017_world_grand_001.json\n",
            "WARNING:root:2013_finance_zasedanie.json\n",
            "WARNING:root:2014_russia_manevry2.json\n",
            "WARNING:root:2018_cinema_drake_002.json\n",
            "WARNING:root:2002_finance_wto_020.json\n",
            "WARNING:root:2004_russia_svoboda_001.json\n",
            "WARNING:root:2012_sport_arshavin_004.json\n",
            "WARNING:root:2008_world_obama_037.json\n",
            "WARNING:root:2003_world_basra3.json\n",
            "WARNING:root:2012_blog_proigrala.json\n",
            "WARNING:root:2006_world_imm_002.json\n",
            "WARNING:root:2001_russia_education_001.json\n",
            "WARNING:root:2010_realty_shumakov.json\n",
            "WARNING:root:2005_russia_sochi.json\n",
            "WARNING:root:2012_russia_shuvalov_019.json\n",
            "WARNING:root:2001_world_kosovo_014.json\n",
            "WARNING:root:2015_russia_sakhalintime.json\n",
            "WARNING:root:2002_world_nigeria_001.json\n",
            "WARNING:root:2013_russia_tyvadtp4.json\n",
            "WARNING:root:2014_sport_pavl_003.json\n",
            "WARNING:root:2016_sport_brasil_002.json\n",
            "WARNING:root:2016_world_gulf.json\n",
            "WARNING:root:2008_russia_golod_011.json\n",
            "WARNING:root:2002_sport_4739839745.json\n",
            "WARNING:root:2003_world_tvs_002.json\n",
            "WARNING:root:2019_sport_sad.json\n",
            "WARNING:root:2020_sport_arshavin.json\n",
            "WARNING:root:2015_russia_imam.json\n",
            "WARNING:root:2015_world_taiwan_002.json\n",
            "WARNING:root:2019_blog_spain.json\n",
            "WARNING:root:2020_russia_efremov_003.json\n",
            "WARNING:root:2011_realty_minfin_nalogi.json\n",
            "WARNING:root:2007_russia_ng_002.json\n",
            "WARNING:root:2013_sport_kids_004.json\n",
            "WARNING:root:2010_world_getman.json\n",
            "WARNING:root:2002_finance_zerno2.json\n",
            "WARNING:root:2015_russia_mistral_013.json\n",
            "WARNING:root:2001_russia_otstavka.json\n",
            "WARNING:root:2002_sport_38857634112.json\n",
            "WARNING:root:2012_sport_ballon_001.json\n",
            "WARNING:root:2011_russia_gaziev.json\n",
            "WARNING:root:2011_realty_innopolis.json\n",
            "WARNING:root:2008_russia_bp_004.json\n",
            "WARNING:root:2010_world_flybe.json\n",
            "WARNING:root:2002_finance_zem.json\n",
            "WARNING:root:2009_finance_summit.json\n",
            "WARNING:root:2007_finance_enel_001.json\n",
            "WARNING:root:2003_world_crash_023.json\n",
            "WARNING:root:2004_world_saakashvili_palace.json\n",
            "WARNING:root:2014_russia_sapsan_001.json\n",
            "WARNING:root:2007_world_kulibiny.json\n",
            "WARNING:root:2003_cinema_rafael.json\n",
            "WARNING:root:2014_russia_pat.json\n",
            "WARNING:root:2015_russia_deputy.json\n",
            "WARNING:root:2004_russia_potushili.json\n",
            "WARNING:root:2018_russia_zerklo.json\n",
            "WARNING:root:2010_cinema_peopleschoice.json\n",
            "WARNING:root:2008_russia_adamov_001.json\n",
            "WARNING:root:2013_realty_sobornaya.json\n",
            "WARNING:root:2018_hitech_esforce.json\n",
            "WARNING:root:2001_cinema_dama_001.json\n",
            "WARNING:root:2007_russia_oproverg_001.json\n",
            "WARNING:root:2020_world_fahri_versions.json\n",
            "WARNING:root:2012_russia_ecoputin.json\n",
            "WARNING:root:2018_finance_electralbdgtprimises.json\n",
            "WARNING:root:2011_realty_hloponin.json\n",
            "WARNING:root:2010_hitech_3d_sky.json\n",
            "WARNING:root:2010_russia_posobniki.json\n",
            "WARNING:root:2008_auto_volvo_sale.json\n",
            "WARNING:root:2018_blog_politologi.json\n",
            "WARNING:root:2002_world_aus_dead.json\n",
            "WARNING:root:2013_realty_nikolaev.json\n",
            "WARNING:root:2012_blog_magnitsk.json\n",
            "WARNING:root:2017_russia_anekdot_pogoda.json\n",
            "WARNING:root:2017_russia_versia_002.json\n",
            "WARNING:root:2011_russia_pereattest.json\n",
            "WARNING:root:2003_russia_ess19.json\n",
            "WARNING:root:2012_russia_dagg_001.json\n",
            "WARNING:root:2018_world_israel_nelegal.json\n",
            "WARNING:root:2019_russia_trubnaya.json\n",
            "WARNING:root:2012_world_bales.json\n",
            "WARNING:root:2017_sport_league_008.json\n",
            "WARNING:root:2008_world_benelux.json\n",
            "WARNING:root:2014_russia_dag_001.json\n",
            "WARNING:root:2018_sport_fifa_006.json\n",
            "WARNING:root:2012_russia_raskol_004.json\n",
            "WARNING:root:2005_russia_mks_022.json\n",
            "WARNING:root:2010_russia_pro_002.json\n",
            "WARNING:root:2007_world_ubegische.json\n",
            "WARNING:root:2014_russia_electro_002.json\n",
            "WARNING:root:2014_russia_kerch_008.json\n",
            "WARNING:root:2016_russia_kostroma.json\n",
            "WARNING:root:2014_russia_mgu_008.json\n",
            "WARNING:root:2006_world_annan.json\n",
            "WARNING:root:2017_russia_links.json\n",
            "WARNING:root:2016_cinema_gop.json\n",
            "WARNING:root:2002_cinema_paltrow.json\n",
            "WARNING:root:2014_russia_sovetnik_001.json\n",
            "WARNING:root:2006_sport_okr.json\n",
            "WARNING:root:2006_sport_liga_007.json\n",
            "WARNING:root:2021_russia_lavroveu.json\n",
            "WARNING:root:2001_world_agr.json\n",
            "WARNING:root:2013_russia_putingovernm.json\n",
            "WARNING:root:2003_sport_646378644_001.json\n",
            "WARNING:root:2020_world_ruplstmilitary.json\n",
            "WARNING:root:2020_sport_fifa_016.json\n",
            "WARNING:root:2005_world_oppoz_001.json\n",
            "WARNING:root:2007_world_zalojnik.json\n",
            "WARNING:root:2010_realty_romeflat.json\n",
            "WARNING:root:2010_world_ne_002.json\n",
            "WARNING:root:2018_russia_urengoy.json\n",
            "WARNING:root:2001_russia_helicopter_004.json\n",
            "WARNING:root:2014_blog_usarusia.json\n",
            "WARNING:root:2019_russia_magnitogorsk_snos.json\n",
            "WARNING:root:2006_russia_potop_002.json\n",
            "WARNING:root:2018_russia_mak2.json\n",
            "WARNING:root:2019_world_hearsay.json\n",
            "WARNING:root:2012_realty_hristenko_003.json\n",
            "WARNING:root:2005_russia_court_002.json\n",
            "WARNING:root:2016_realty_nurest_paris.json\n",
            "WARNING:root:2004_world_poll_007.json\n",
            "WARNING:root:2017_russia_jobru.json\n",
            "WARNING:root:2001_world_landing.json\n",
            "WARNING:root:2007_russia_boeviki.json\n",
            "WARNING:root:2013_blog_onk.json\n",
            "WARNING:root:2017_blog_crimea.json\n",
            "WARNING:root:2006_russia_karikatura.json\n",
            "WARNING:root:2007_finance_beercartel.json\n",
            "WARNING:root:2009_world_ukraina_003.json\n",
            "IOPub message rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "import logging\n",
        "from typing import List, Tuple\n",
        "\n",
        "logging.disable(level=logging.NOTSET)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--data_dir\", default=\"./rucoco/data/train\")\n",
        "parser.add_argument(\"--out_dir\", default=\"./rucoco/data/split_data\")\n",
        "parser.add_argument(\"--val_fraction\", type=float, default=0.10)\n",
        "parser.add_argument(\"--test_fraction\", type=float, default=0.10)\n",
        "parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite out_dir if it already exists.\")\n",
        "args = parser.parse_args([])\n",
        "\n",
        "assert 0.01 <= args.val_fraction <= 0.2\n",
        "assert 0.1 <= args.test_fraction <= 0.3\n",
        "\n",
        "if os.path.exists(args.out_dir):\n",
        "    if not args.f:\n",
        "        print(f\"The out directory {args.out_dir} already exists. Use -f to overwrite it.\")\n",
        "        sys.exit(1)\n",
        "    shutil.rmtree(args.out_dir)\n",
        "for split in \"train\", \"val\", \"test\":\n",
        "    os.makedirs(os.path.join(args.out_dir, split))\n",
        "\n",
        "datafiles: List[Tuple[os.DirEntry, int]] = []  # [(path, n_words), ...]\n",
        "for entry in os.scandir(args.data_dir):\n",
        "    if entry.name.endswith(\".json\"):\n",
        "        logging.warn(entry.name)\n",
        "        with open(entry, encoding=\"utf8\") as f:\n",
        "            length = json.load(f, strict=False)[\"text\"].split().__len__()\n",
        "        datafiles.append((entry, length))\n",
        "\n",
        "total_length = sum(length for _, length in datafiles)\n",
        "test_length = int(total_length * args.test_fraction)\n",
        "val_length = int(total_length * args.val_fraction)\n",
        "\n",
        "random.shuffle(datafiles)\n",
        "current_test_length = 0\n",
        "while current_test_length < test_length:\n",
        "    entry, length = datafiles.pop()\n",
        "    dst_path = os.path.join(args.out_dir, \"test\", entry.name)\n",
        "    shutil.copyfile(entry.path, dst_path)\n",
        "    current_test_length += length\n",
        "\n",
        "current_val_length = 0\n",
        "while current_val_length < val_length:\n",
        "    entry, length = datafiles.pop()\n",
        "    dst_path = os.path.join(args.out_dir, \"val\", entry.name)\n",
        "    shutil.copyfile(entry.path, dst_path)\n",
        "    current_val_length += length\n",
        "\n",
        "for entry, length in datafiles:\n",
        "    dst_path = os.path.join(args.out_dir, \"train\", entry.name)\n",
        "    shutil.copyfile(entry.path, dst_path)\n",
        "\n",
        "print(f\"Train: {total_length - current_val_length}\\n\"\n",
        "      f\"Val:   {current_val_length}\\n\"\n",
        "      f\"Test:   {current_test_length}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiHAKaUa7hQ9"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/split_data/train/book_2111.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqiFaV1myzbm"
      },
      "source": [
        "# Tokenize datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnHdF-wKyJey"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "tokenizer = load_tokenizer(global_encoder_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5wXcB5at5S_"
      },
      "outputs": [],
      "source": [
        "logging.disable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o5R0geVvn3n"
      },
      "outputs": [],
      "source": [
        "logging.disable(level=logging.NOTSET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJzV9hRODpfO"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = logging.getLogger('my_logger')\n",
        "\n",
        "# logging.basicConfig(\n",
        "#     filename='./rucoco/app.log', # write to this file\n",
        "#     filemode='w', # open in append mode\n",
        "#     # format='%(name)s - %(levelname)s - %(message)s',\n",
        "#     force=True,\n",
        "#     level=logging.DEBUG\n",
        "#     )\n",
        "\n",
        "# logging.basicConfig()\n",
        "\n",
        "logging.debug('This will get logged to a file')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_test = CorefDocs(\"./rucoco/data/data_test\", tokenizer)"
      ],
      "metadata": {
        "id": "WFwZIUAN4ZTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxbgRej1mz3J"
      },
      "outputs": [],
      "source": [
        "train_data = CorefDocs(os.path.join(\"./rucoco/data/split_data\", \"train\"), tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0exigDUmxPC"
      },
      "outputs": [],
      "source": [
        "val_data = CorefDocs(os.path.join(\"./rucoco/data/split_data\", \"val\"), tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SQfUJBBXspz"
      },
      "outputs": [],
      "source": [
        "from pickle5 import dump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRqU35VGY6JY"
      },
      "outputs": [],
      "source": [
        "f = open(\"./rucoco/data/tokenized_data/train_data_lf_large.txt\",\"wb\")\n",
        "dump(train_data, f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrdlWnDwY6p_"
      },
      "outputs": [],
      "source": [
        "f = open(\"./rucoco/data/tokenized_data/val_data_lf_large.txt\",\"wb\")\n",
        "dump(val_data, f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBZyWs7r3U2R"
      },
      "outputs": [],
      "source": [
        "for span in train_data[0].all_spans:\n",
        "  print(train_data[0].token_span_to_chars(span))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9eQMUDEztdZ"
      },
      "source": [
        "# Load tokenized datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnWMmYUgz72A"
      },
      "outputs": [],
      "source": [
        "from pickle5 import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tik7qB_Y8Oq"
      },
      "outputs": [],
      "source": [
        "f = open(\"./rucoco/data/tokenized_data/train_data_lf_large.txt\",\"rb\")\n",
        "train_data = load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukidCmRXY9a1"
      },
      "outputs": [],
      "source": [
        "f = open(\"./rucoco/data/tokenized_data/val_data_lf_large.txt\",\"rb\")\n",
        "val_data = load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHBT-meYujzT"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
      ],
      "metadata": {
        "id": "Yoj24AAJBd0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329MeEM7RBzy"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from copy import deepcopy\n",
        "import json\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import transformers\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader\n",
        "import shutil\n",
        "\n",
        "\n",
        "def zip_directory(source_dir, zip_filename):\n",
        "    shutil.make_archive(zip_filename, 'zip', source_dir)\n",
        "\n",
        "\n",
        "class BasicCheckpointIO(pl.plugins.io.TorchCheckpointIO):\n",
        "    def save_checkpoint(self, checkpoint, path, storage_options=None):\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        torch.save(checkpoint, path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CorefModel(k=50, max_batches_train=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qryG89DhIgxL",
        "outputId": "71baae9f-d8e5-4f60-ce2c-66fae78fbbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at kazzand/ru-longformer-large-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerModel were not initialized from the model checkpoint at kazzand/ru-longformer-large-4096 and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "collate_fn = lambda x: deepcopy(x)\n",
        "#subset_indices = range(1000)  # Choose the indices of the samples you want\n",
        "# train_subset = Subset(train_data, subset_indices)\n",
        "# val_subset = Subset(val_data, subset_indices)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                                shuffle=True,\n",
        "                                                collate_fn=collate_fn,\n",
        "                                                num_workers=4,\n",
        "                                                batch_size=1,\n",
        "                                                # pin_memory=True\n",
        "                                                )\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(val_data,\n",
        "                                              collate_fn=collate_fn\n",
        "                                              )\n",
        "\n",
        "early_stopping = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_lea\",\n",
        "                                                          min_delta=0.01,\n",
        "                                                          mode=\"max\",\n",
        "                                                          patience=10,\n",
        "                                                        #   verbose=True\n",
        "                                                          )\n",
        "\n",
        "checkpointing = pl.callbacks.ModelCheckpoint(monitor=\"val_lea\",\n",
        "                                             mode=\"max\",\n",
        "                                             filename=\"{epoch:02d}-{val_lea:.3f}\",\n",
        "                                             every_n_epochs=1,\n",
        "                                             save_last=True\n",
        "                                            #  save_weights_only=True\n",
        "                                             )\n",
        "trainer = pl.Trainer(\n",
        "                    #  plugins=[BasicCheckpointIO()],\n",
        "                     default_root_dir='./rucoco',\n",
        "                     accelerator=\"gpu\",\n",
        "                     devices=1,\n",
        "                     callbacks=[early_stopping, checkpointing],\n",
        "                    #  log_every_n_steps=2,\n",
        "                    #  min_epochs=5\n",
        "                     )\n",
        "# trainer = pl.Trainer.from_argparse_args(args, callbacks=[early_stopping, checkpointing])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAr60fOz1KzS",
        "outputId": "ec49ff31-9514-4602-c879-2352bf5f26a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFCdYQGQa15Y"
      },
      "outputs": [],
      "source": [
        "# checkpoint_path = \".rucoco/lightning_logs/version_5/checkpoints/last.ckpt\"\n",
        "# model = model.load_from_checkpoint(checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaDm9ZlnuD-b"
      },
      "outputs": [],
      "source": [
        "logging.disable(level=logging.NOTSET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364,
          "referenced_widgets": [
            "b651ce371ee2444b8dc22ad7c5eb18dc",
            "b81e80a7522842a0b941dbe9872ed1b6",
            "05822181ce9546718855001c892adf18",
            "6e93818df3e84fb8a7d3e0c17e24ddac",
            "852139825b4a49f193b85027e1dc15fe",
            "7a3b85387c444161839c6a4fae7a155d",
            "4988c719747a47fa8f4e8400e4dfb1f6",
            "63aee209e4584fcca293c64f5bed9007",
            "bcc674ca81204858b15cb5cdd62522ee",
            "75565d8b1e1f41b486e0c58a40465205",
            "0bba67d5287e44eaaf5576bf673eaa84",
            "c1819ba5e5334f83bcc93cecafc9a093",
            "f6ca9e5f49ca4e268ee0f851158a65ba",
            "a735cae784e54361bdaf6216335f1e76",
            "b6f345e7e7b34f6a8f7e86438b366996",
            "f52f76f1e5944de0bdfec77907e9a7da",
            "c427076e05f143f993c6c17a346eadc8",
            "535e7e8ec4e8471889ec47a264b07a0a",
            "d96454d791274b92a68d72d9bac00486",
            "dd1efeeb4771468b8784d9ceae8690ab",
            "c9518f576c0140b29178fd08bcc7fda4",
            "800548da03ed4c569fd19cc1def37306",
            "aeade328277544639a3852e7deeb4fc7",
            "f93fd009aee24aeb9068a4f952676e87",
            "34f4aabb3ef8445faa6a93a868c6de62",
            "149187c3d52c4990b3838d6bd618aa8d",
            "9ad46e50aec8488280d941851a262d0b",
            "7882b795cc70439780e1aec52f40ed8b",
            "d6b49e326d824e1eb759f4c266b86cd3",
            "808cb1a615dd49afb2e3eb96a37d4ec1",
            "e4e33789d35b48af84349785495c2f6f",
            "89f136796d664932bd2e5c258c9531e4",
            "263788092d6d4eee958c4db453d06d91",
            "18b4eca995f0423fb5957e7de233c1b3",
            "e4d00e6f33444ae696e68508f6d74f2b",
            "048810b6fe05497ca53653d531ba7e82",
            "a84ee8bd6dd04c6e9296f7353eaf6d0f",
            "71ad413ff5274899a338c2c6f37e29eb",
            "c3c78945f09041d4baddd304b20d4e4c",
            "0362c532b16942869a727da8c3fcf97c",
            "5e9a695249f745db996a0c270399676a",
            "5e5cefbdc7474a8bbedc1f1b78adfe00",
            "be86f683e64d438eaa3b2c3db85a4257",
            "35eb2d3b3a9e4f598c5b723af71094e9",
            "e9cd2ea5b0004d10ac962e2ff477bf3c",
            "b90b877dbb4448d589ac02027a8443d7",
            "f31ebd1f053941c991f690f6f1eb63d3",
            "b5665f150fcb49bfbd403eddf40c135f",
            "ba645928cd99456ab6fb612694fa41f6",
            "ffe9e0827dd2458a91e2d286fb04178b",
            "cdf6a0a9c44748a79e04bcf6f6def0df",
            "3c29da84a0df43bfbe1aa472453958db",
            "daa4b0b7da0047a897c0e1e4e3e65461",
            "ecf7842d09d44479ad48994ae86b0a74",
            "089d59f404c94ae5b0590314b9a04ed4",
            "3b0d4181afc74503aec0953ea270a3e3",
            "0a637dad82e54fdfb757a2176ce2d45d",
            "71d460c13ff64b7d90871843d017b2ba",
            "4deb87f0c9f341a8ab0cd275aad53288",
            "a6ec26092e874d3dbe286bc1a63491e8",
            "b6de724510d54d25a7d4a347704fa8c1",
            "4018533da60544098f1d5cecebb3a5e0",
            "4247176ad58e4b3993f1a8c6c26c6110",
            "b67cc80311d7402c9992d4edcd3243bf",
            "5f439754a2de43d9b7ebfdba88b8fe22",
            "f3fdaadf791a4ab2b258cbf40284ed36",
            "ce37263490924409af68ec5d1c511a5c",
            "c145c400e45d4940b88469c3bc40664f",
            "db65d75cc08b41f498512eaab3c7efc4",
            "2e726a485b0a4e7c8f80cbd0785fe592",
            "09ccc91a82e84481beebf0033573dfd9",
            "21562d9055c34e2f904b221e2bc0f363",
            "090872bf75c748f88f2bf1c9465755a5",
            "e87b58fd09684c00b7f1e48d058512c8",
            "849694b80ba0444e8036e2216235bba8",
            "3cd92ebe2de14165a0f6bb46caf12da7",
            "9fe354fbc6804c75a9a1b32c24f9bd34",
            "42b3cce7335a430cb244e9e1252c2bbf",
            "00d64aee60b24f009e2a26ce44551c20",
            "7f679aefc39f4b27b57604afcd30643f",
            "bf9829b185fc41de93247990dc54dbe8",
            "b73816b016694432949264fca37621d6",
            "ce88b6fc24f042babb77838ad1da4431",
            "78c8788c1fd44852b03c13e15d8580db",
            "b8d1fb937eb04fb1acf837132bf53116",
            "4cab6b737d804499a4bf21a17dd441a5",
            "3bc52bb2d96d44268e008badef4ba87f",
            "437fde8b4153494a823bd40f5430e058"
          ]
        },
        "id": "CqLvywNzjgQ8",
        "outputId": "046b36ef-de62-4c33-ac89-5f14faeeba7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
            "\n",
            "  | Name                    | Type            | Params\n",
            "------------------------------------------------------------\n",
            "0 | encoder                 | LongformerModel | 434 M \n",
            "1 | token_importance_linear | Linear          | 1.0 K \n",
            "2 | span_dropout            | Dropout         | 0     \n",
            "3 | coarse_bilinear         | Linear          | 1.0 M \n",
            "4 | coarse_dropout          | Dropout         | 0     \n",
            "5 | fine_linear             | Sequential      | 3.1 M \n",
            "------------------------------------------------------------\n",
            "438 M     Trainable params\n",
            "0         Non-trainable params\n",
            "438 M     Total params\n",
            "1,755.197 Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b651ce371ee2444b8dc22ad7c5eb18dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/shuvalov/.conda/envs/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1819ba5e5334f83bcc93cecafc9a093"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeade328277544639a3852e7deeb4fc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18b4eca995f0423fb5957e7de233c1b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9cd2ea5b0004d10ac962e2ff477bf3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b0d4181afc74503aec0953ea270a3e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce37263490924409af68ec5d1c511a5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42b3cce7335a430cb244e9e1252c2bbf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "trainer.fit(model, train_data_loader, val_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WteXu7F3LsSP"
      },
      "outputs": [],
      "source": [
        "# torch.save(model, \"./model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_qD3QStvY9-"
      },
      "source": [
        "#Make raw test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEK19RxisA5s"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Define the directory where your JSON files are located\n",
        "json_dir = './rucoco/data/split_data/test'\n",
        "txt_dir = './rucoco/data/split_data/test_raw'\n",
        "os.mkdir(txt_dir)\n",
        "# Iterate over all files in the directory\n",
        "for filename in os.listdir(json_dir):\n",
        "    if filename.endswith('.json'):\n",
        "        file_path = os.path.join(json_dir, filename)\n",
        "\n",
        "        # Load the JSON data from the current file\n",
        "        with open(file_path,  mode=\"r\", encoding=\"utf8\") as json_file:\n",
        "            data = json.load(json_file, strict=False)\n",
        "            if len(data[\"text\"]) > 0:\n",
        "                if data[\"text\"][0] == \" \":\n",
        "                    data[\"text\"] = data[\"text\"].replace(\" \", \"\", 1).replace('\\n', '')\n",
        "                    logging.debug(\"Replace first space\")\n",
        "                logging.debug(data[\"text\"])\n",
        "                data[\"text\"] = data[\"text\"].replace('\\\\t', '').replace('\\t', '').replace('\\\\r', '').replace('\\r', '').replace('\\\\0', '').replace('\\0', '')\n",
        "                data = json.loads(json.dumps(data), strict = False)\n",
        "\n",
        "        # Extract the 'text' field value\n",
        "        text_value = data.get('text', '')\n",
        "\n",
        "        # Create a corresponding txt file with the same name as the JSON file\n",
        "        txt_filename = filename.replace('.json', '.txt')\n",
        "        txt_file_path = os.path.join(txt_dir, txt_filename)\n",
        "\n",
        "        # Save the 'text' value to the txt file\n",
        "        with open(txt_file_path, 'w+') as txt_file:\n",
        "            txt_file.write(text_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0GY8tuaASAw"
      },
      "source": [
        "#Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnOGDjeeySi5"
      },
      "outputs": [],
      "source": [
        "from tokenizers import pre_tokenizers\n",
        "import transformers\n",
        "\n",
        "ADD_PUNCTUATION_PRE_TOKENIZER = {global_encoder_model_name, }\n",
        "\n",
        "\n",
        "def load_tokenizer(model_name: str) -> transformers.AutoTokenizer:\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    if model_name in ADD_PUNCTUATION_PRE_TOKENIZER:\n",
        "        tokenizer._tokenizer.pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Punctuation(),\n",
        "                                                                      tokenizer._tokenizer.pre_tokenizer])\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnUb40r3sVfM"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "data_dir = \"./rucoco/data/split_data/test_raw\"\n",
        "out_dir = \"./rucoco/result/lf_large\"\n",
        "# weights = \"./checkpoints/lightning_logs/version_1/checkpoints/epoch=04-val_lea=0.683.ckpt\"\n",
        "device = \"cuda:0\"\n",
        "# device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CorefModel()\n",
        "model = model.load_from_checkpoint(\"./rucoco/lightning_logs/version_13/checkpoints/last.ckpt\")\n",
        "\n",
        "# model = CorefModel()\n",
        "# model = model.load_from_checkpoint(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXHMltW7YA2u",
        "outputId": "224c7e22-572c-406b-c3c6-e50d7a908dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at kazzand/ru-longformer-tiny-16384 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerModel were not initialized from the model checkpoint at kazzand/ru-longformer-tiny-16384 and are newly initialized: ['longformer.pooler.dense.weight', 'longformer.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at kazzand/ru-longformer-tiny-16384 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerModel were not initialized from the model checkpoint at kazzand/ru-longformer-tiny-16384 and are newly initialized: ['longformer.pooler.dense.weight', 'longformer.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "QDIxHzM_gtY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOk4LhePxogX"
      },
      "outputs": [],
      "source": [
        "tokenizer = load_tokenizer(model.hparams[\"encoder_model_name\"])\n",
        "\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "entries = [entry for entry in os.scandir(data_dir) if entry.name.endswith(\".txt\")]\n",
        "with torch.no_grad():\n",
        "    i = 0\n",
        "    for entry in tqdm(entries, leave=True):\n",
        "        i += 1\n",
        "        # if i == 200:\n",
        "        #     break;\n",
        "        with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "            data = {\"text\": f.read(), \"entities\": [], \"includes\": []}\n",
        "            doc = Doc(entry.name, data, tokenizer=tokenizer, extract_all_spans=True)\n",
        "            char_entities = [\n",
        "                [doc.token_span_to_chars(span) for span in token_entity]\n",
        "                for token_entity in model.predict(doc)\n",
        "            ]\n",
        "            data[\"entities\"] = char_entities\n",
        "            data[\"includes\"] = [[] for _ in char_entities]\n",
        "            out_name = os.path.splitext(entry.name)[0] + \".json\"\n",
        "            with open(os.path.join(out_dir, out_name), mode=\"w\", encoding=\"utf8\") as f:\n",
        "                json.dump(data, f, ensure_ascii=False)\n",
        "    print(\"Files: \", i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bshuwxArxin9"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json(file):\n",
        "    data = json.load(file, strict=False)\n",
        "    if len(data[\"text\"]) > 0:\n",
        "        if data[\"text\"][0] == \" \":\n",
        "            data[\"text\"] = data[\"text\"].replace(\" \", \"\", 1).replace('\\n', '')\n",
        "\n",
        "    return json.loads(json.dumps(data).replace('\\\\t', '').replace('\\t', '').replace('\\\\r', '').replace('\\r', '').replace('\\\\0', '').replace('\\0', ''), strict=False)"
      ],
      "metadata": {
        "id": "5FIpa9qghbzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from typing import *\n",
        "import logging\n",
        "\n",
        "Span = Tuple[int, int]\n",
        "\n",
        "EPS = 1e-7\n",
        "\n",
        "\n",
        "class DocumentPair(NamedTuple):\n",
        "    filename: str\n",
        "    dir_a: str\n",
        "    dir_b: str\n",
        "\n",
        "\n",
        "class ScoringException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def agreement(pairs: Iterable[DocumentPair]) -> Tuple[float, float, float]:\n",
        "    total_recall, total_r_weight = .0, .0\n",
        "    total_precision, total_p_weight = .0, .0\n",
        "    k = 0\n",
        "    for pair in sorted(pairs):\n",
        "        k += 1\n",
        "        a = read_markup_dict(os.path.join(pair.dir_a, pair.filename))\n",
        "        b = read_markup_dict(os.path.join(pair.dir_b, pair.filename))\n",
        "        if a[\"text\"] != b[\"text\"]:\n",
        "            raise ScoringException(f\"mismatching texts for documents: {pair.filename} in {pair.dir_a} and {pair.dir_b}\")\n",
        "\n",
        "        a_clusters = [(spans, get_children(a, i))\n",
        "                      for i, spans in enumerate(a[\"entities\"])]\n",
        "        b_clusters = [(spans, get_children(b, i))\n",
        "                      for i, spans in enumerate(b[\"entities\"])]\n",
        "\n",
        "        recall, r_weight = _lea_children(a_clusters, b_clusters)\n",
        "        precision, p_weight = _lea_children(b_clusters, a_clusters)\n",
        "\n",
        "        total_recall += recall\n",
        "        total_r_weight += r_weight\n",
        "        total_precision += precision\n",
        "        total_p_weight += p_weight\n",
        "        print(pair.filename)\n",
        "\n",
        "    recall = total_recall / (total_r_weight + EPS)\n",
        "    precision = total_precision / (total_p_weight + EPS)\n",
        "    print(\"Files: \", k)\n",
        "    return f1(recall, precision), precision, recall\n",
        "\n",
        "\n",
        "def f1(precision: float, recall: float, eps: float = 1e-7) -> float:\n",
        "    return (precision * recall) / (precision + recall + eps) * 2\n",
        "\n",
        "\n",
        "def get_children(data: dict, idx: int) -> List[Span]:\n",
        "    \"\"\" Returns a list of all the immediate AND most distant children \"\"\"\n",
        "    children = set()\n",
        "    for child_idx in data[\"includes\"][idx]:\n",
        "        children.update(data[\"entities\"][child_idx])\n",
        "\n",
        "    visited = set()\n",
        "    stack = list(data[\"includes\"][idx])\n",
        "    while stack:\n",
        "        child_idx = stack.pop()\n",
        "        visited.add(child_idx)\n",
        "        if not data[\"includes\"][child_idx]:\n",
        "            children.update(data[\"entities\"][child_idx])\n",
        "        else:\n",
        "            for grandchild_idx in data[\"includes\"][child_idx]:\n",
        "                if grandchild_idx not in visited:\n",
        "                    stack.append(grandchild_idx)\n",
        "\n",
        "    return sorted(children)\n",
        "\n",
        "\n",
        "def get_pairs_from_dir(path: str) -> List[DocumentPair]:\n",
        "    entries = filter(lambda entry: entry.name.endswith(\".json\"),\n",
        "                     recursive_scandir(path))\n",
        "    name2paths = defaultdict(list)\n",
        "    for entry in entries:\n",
        "        name2paths[entry.name].append(entry.path)\n",
        "\n",
        "    pairs = []\n",
        "    for name, paths in name2paths.items():\n",
        "        if len(paths) == 1:\n",
        "            raise ScoringException(f\"No matching document for {paths[0]}\")\n",
        "        elif len(paths) > 2:\n",
        "            raise ScoringException(f\"Too many matching documents: {', '.join(paths)}\")\n",
        "        else:\n",
        "            pairs.append(\n",
        "                DocumentPair(name, *(os.path.dirname(path) for path in paths))\n",
        "            )\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def get_pairs_from_two_dirs(a: str,\n",
        "                            b: str) -> List[DocumentPair]:\n",
        "    a_files = set(get_relative_paths(a))\n",
        "    b_files = set(get_relative_paths(b))\n",
        "    common_files = a_files & b_files\n",
        "\n",
        "    for file in a_files - common_files:\n",
        "        raise ScoringException(f\"No matching document for {os.path.join(a, file)}\")\n",
        "    for file in b_files - common_files:\n",
        "        raise ScoringException(f\"No matching document for {os.path.join(b, file)}\")\n",
        "    return [DocumentPair(filename, a, b) for filename in common_files]\n",
        "\n",
        "\n",
        "def get_relative_paths(path: str) -> Iterator[str]:\n",
        "    return map(lambda entry: os.path.relpath(entry.path, path),\n",
        "               filter(lambda entry: entry.name.endswith(\".json\"),\n",
        "                      recursive_scandir(path)))\n",
        "\n",
        "\n",
        "def read_markup_dict(path: str) -> dict:\n",
        "    with open(path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        markup_dict = read_json(f)\n",
        "    markup_dict[\"entities\"] = [[tuple(span) for span in entity]\n",
        "                               for entity in markup_dict[\"entities\"]]\n",
        "    return markup_dict\n",
        "\n",
        "\n",
        "def recursive_scandir(path: str) -> Iterator[os.DirEntry]:\n",
        "    for entry in os.scandir(path):\n",
        "        if entry.is_dir():\n",
        "            yield from recursive_scandir(entry.path)\n",
        "        else:\n",
        "            yield entry\n",
        "\n",
        "\n",
        "def _lea_children(key: List[Tuple[List[Span], List[Span]]],\n",
        "                  response: List[Tuple[List[Span], List[Span]]]\n",
        "                  ) -> Tuple[float, float]:\n",
        "        response_clusters = [set(cluster) for cluster, _ in response]\n",
        "        response_map = {mention: cluster\n",
        "                        for cluster in response_clusters\n",
        "                        for mention in cluster}\n",
        "        response_children_map = defaultdict(set)\n",
        "        for cluster, children in response:\n",
        "            for mention in children:\n",
        "                response_children_map[mention].update(cluster)\n",
        "\n",
        "        importances = []\n",
        "        resolutions = []\n",
        "        for entity, children in key:\n",
        "            size = len(entity)\n",
        "            if size > 1:  # entities of size 1 are not annotated\n",
        "                importances.append(size)\n",
        "                correct_links = 0\n",
        "                for i in range(size):\n",
        "                    for j in range(i + 1, size):\n",
        "                        correct_links += int(entity[i]\n",
        "                                            in response_map.get(entity[j], {}))\n",
        "                resolutions.append(correct_links / (size * (size - 1) / 2))\n",
        "\n",
        "            if not children:\n",
        "                continue\n",
        "            importances.append(len(children))\n",
        "            correct_links = 0\n",
        "            for mention in entity:\n",
        "                for child in children:\n",
        "                    correct_links += int(mention in response_children_map.get(child, {}))\n",
        "            resolutions.append(correct_links / (size * len(children)))\n",
        "\n",
        "        res = sum(imp * res for imp, res in zip(importances, resolutions))\n",
        "        weight = sum(importances)\n",
        "        return res, weight\n"
      ],
      "metadata": {
        "id": "1stlBZxrhdpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_dir = json_dir = './rucoco/data/split_data/test'\n",
        "res_dir = out_dir = './rucoco/result/lf_large'\n",
        "output_dir = \"./rucoco/evaluation\"\n",
        "\n",
        "scores_path = os.path.join(output_dir, \"RuCoCo_lf_large_scores.txt\")\n",
        "print(\"Get pairs from two dirs\")\n",
        "pairs = get_pairs_from_two_dirs(ref_dir, res_dir)\n",
        "print(\"Agreement\")\n",
        "f1_score, precision, recall = agreement(pairs)\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "with open(scores_path, mode=\"w\", encoding=\"utf8\") as f:\n",
        "    print(f\"F1: {f1_score:.3f}\", file=f)\n",
        "    print(f\"Precision: {precision:.3f}\", file=f)\n",
        "    print(f\"Recall: {recall:.3f}\", file=f)"
      ],
      "metadata": {
        "id": "JpZpYfdpheaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results view"
      ],
      "metadata": {
        "id": "5ox_ZzLnoWj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFszUAEcoZOo",
        "outputId": "6441de97-08bf-484f-8f40-5a79716beb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /home/shuvalov/.conda/envs/env/lib/python3.9/site-packages (0.4.6)\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colorama import Fore, Back, Style"
      ],
      "metadata": {
        "id": "6XOAx_V1ob13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"./rucoco/res_view/\"\n",
        "logs_json_dir = \"./rucoco/res_view/view_json\"\n",
        "logs_txt_dir = \"./rucoco/res_view/view_txt\"\n",
        "\n",
        "def print_log(log):\n",
        "    print(log)\n",
        "\n",
        "def print_log_in_line(log):\n",
        "    print(log, end=\"\")\n",
        "\n",
        "single_indent = \"\\t\"\n",
        "indent = \"\\t\\t\"\n",
        "\n",
        "def print_entity_spans(entity, text):\n",
        "    print_log(\"\")\n",
        "    print_log_in_line(\"\\t\")\n",
        "    print_log(\"Реальные упоминания сущности\")\n",
        "    print_log_in_line(indent)\n",
        "    print_log(entity)\n",
        "    i = 1\n",
        "    for span in entity:\n",
        "        print_log_in_line(indent + str(i) + \". \")\n",
        "        i += 1\n",
        "        print_adjacent_text(span[0], span[1], text)\n",
        "\n",
        "def print_adjacent_text(span_start, span_end, text):\n",
        "    start = span_start\n",
        "    end = span_end\n",
        "    delta = 80\n",
        "    if (start - delta >= 0):\n",
        "        start = start - delta\n",
        "    else:\n",
        "        start = 0\n",
        "\n",
        "    if (end + delta < len(text)):\n",
        "        end = end + delta\n",
        "    else:\n",
        "        end = len(text) - 1\n",
        "\n",
        "    if '\\n' in text[start : span_start]:\n",
        "        start = text[0 : span_start].rfind('\\n') + 1\n",
        "\n",
        "    if '\\n' in text[span_end : end]:\n",
        "        end = span_end + text[span_end : end].index('\\n')\n",
        "\n",
        "    print_log_in_line(text[start : span_start])\n",
        "    # print_log_in_line(\"[\")\n",
        "    print_log_in_line(Fore.LIGHTGREEN_EX + text[span_start : span_end])\n",
        "    print_log_in_line(Style.RESET_ALL)\n",
        "    # print_log_in_line(\"]\")\n",
        "    print_log(text[span_end : end])\n",
        "\n",
        "def print_matched(matched_corefs, text):\n",
        "    print_log(\"\")\n",
        "    print_log_in_line(single_indent)\n",
        "    print_log(\"Правильнно разрешенные кореференции\")\n",
        "    print_log_in_line(single_indent)\n",
        "    print_log(\"===========\")\n",
        "    for coref in matched_corefs:\n",
        "        print_log_in_line(indent)\n",
        "        print_log(coref)\n",
        "        print_log_in_line(indent)\n",
        "        print_adjacent_text(coref[0][0], coref[0][1], text)\n",
        "        print_log_in_line(indent)\n",
        "        print_adjacent_text(coref[1][0], coref[1][1], text)\n",
        "        # print_log(text[coref[0][0] : coref[0][1]])\n",
        "        # print_log(text[coref[1][0] : coref[1][1]])\n",
        "        print_log(\"\")\n",
        "    print_log_in_line(single_indent)\n",
        "    print_log(\"===========\")\n",
        "    print_log(\"\")\n",
        "\n",
        "\n",
        "def print_not_identified(not_identified_corefs, text, response_map):\n",
        "    print_log_in_line(single_indent)\n",
        "    print_log(\"Неразрешенные кореференции\")\n",
        "    print_log_in_line(single_indent)\n",
        "    print_log(\"===========\")\n",
        "    for coref in not_identified_corefs:\n",
        "        print_log_in_line(indent)\n",
        "        print_log(coref)\n",
        "        # print_log(text[coref[0][0] : coref[0][1]])\n",
        "        # print_log(text[coref[1][0] : coref[1][1]])\n",
        "        start = coref[0][0]\n",
        "        end = coref[0][1]\n",
        "        print_log_in_line(indent)\n",
        "        print_adjacent_text(start, end, text)\n",
        "        start = coref[1][0]\n",
        "        end = coref[1][1]\n",
        "        print_log_in_line(indent)\n",
        "        print_adjacent_text(start, end, text)\n",
        "        print_log(\"\")\n",
        "        print_log_in_line(indent)\n",
        "        print_log(\"Предсказанный кластер второго упоминания\")\n",
        "        print_log_in_line(indent + \"\\t\")\n",
        "        cluster = response_map.get(coref[1], {})\n",
        "        print_log(cluster)\n",
        "        for span in cluster:\n",
        "            print_log_in_line(indent + \"\\t\")\n",
        "            print_adjacent_text(span[0], span[1], text)\n",
        "        print_log(\"\")\n",
        "        print_log(\"\")\n",
        "\n",
        "    print_log_in_line(single_indent)\n",
        "    print_log(\"===========\")\n",
        "    print_log(\"\")\n",
        "\n",
        "def split_into_disjoint_subsets(key: List[Tuple[List[Span], List[Span]]],\n",
        "        response: List[Tuple[List[Span], List[Span]]],\n",
        "        text\n",
        "        ) -> List[Tuple[List[Tuple[Span, Span]], List[Tuple[Span, Span]], List[Tuple[Span, Span]]]]:\n",
        "        response_clusters = [set(cluster) for cluster, _ in response]\n",
        "        response_map = {mention: cluster\n",
        "                        for cluster in response_clusters\n",
        "                        for mention in cluster}\n",
        "        response_children_map = defaultdict(set)\n",
        "        for cluster, children in response:\n",
        "            for mention in children:\n",
        "                response_children_map[mention].update(cluster)\n",
        "\n",
        "        subsets_list: List[Tuple[List[Span], List[Span], List[Span]]] = []\n",
        "\n",
        "        # for entity_num in range(len(key)):\n",
        "        #     entity = key[entity_num][0]\n",
        "\n",
        "        entity_count = 1\n",
        "        for entity, children in key:\n",
        "            size = len(entity)\n",
        "            if size > 1:  # entities of size 1 are not annotated\n",
        "                matched_coref : List[Tuple[Span, Span]] = []\n",
        "                not_identified_coref : List[Tuple[Span, Span]] = []\n",
        "                wrong_coref : List[Tuple[Span, Span]] = []\n",
        "\n",
        "                for i in range(size):\n",
        "                    for j in range(i + 1, size):\n",
        "                        if (entity[i] in response_map.get(entity[j], {})):\n",
        "                            matched_coref.append((entity[i], entity[j]))\n",
        "                        else:\n",
        "                            not_identified_coref.append((entity[i], entity[j]))\n",
        "\n",
        "                # ищем кластер, которому соответствует первое и\n",
        "                # правильно предсказанное упоминание сущности\n",
        "                # if (len(matched_coref) > 0):\n",
        "                    # predicted_spans = response_map[matched_coref[0]]\n",
        "                    # wrong_spans = list(set(predicted_spans) - set(matched_coref))\n",
        "\n",
        "                subsets_list.append((matched_coref, not_identified_coref, wrong_coref))\n",
        "\n",
        "                print_log(\"Сущность \" + str(entity_count))\n",
        "                print_log(\"==================================\")\n",
        "                print_entity_spans(entity, text)\n",
        "                print_matched(matched_coref, text)\n",
        "                print_not_identified(not_identified_coref, text, response_map)\n",
        "                print_log(\"==================================\")\n",
        "                print_log(\"\")\n",
        "                entity_count += 1\n",
        "            # entity_num += 1\n",
        "        return subsets_list\n",
        "\n",
        "def log(pairs: Iterable[DocumentPair]):\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    os.makedirs(logs_json_dir, exist_ok=True)\n",
        "    os.makedirs(logs_txt_dir, exist_ok=True)\n",
        "    i = 0\n",
        "    for pair in sorted(pairs):\n",
        "        a = read_markup_dict(os.path.join(pair.dir_a, pair.filename))\n",
        "        b = read_markup_dict(os.path.join(pair.dir_b, pair.filename))\n",
        "        if a[\"text\"] != b[\"text\"]:\n",
        "            raise ScoringException(f\"mismatching texts for documents: {pair.filename} in {pair.dir_a} and {pair.dir_b}\")\n",
        "\n",
        "        a_clusters = [(spans, get_children(a, i))\n",
        "                      for i, spans in enumerate(a[\"entities\"])]\n",
        "        b_clusters = [(spans, get_children(b, i))\n",
        "                      for i, spans in enumerate(b[\"entities\"])]\n",
        "\n",
        "        print_log(\"=================\" + pair.filename + \"=================\")\n",
        "        print_log(a[\"text\"])\n",
        "        with open(os.path.join(logs_json_dir, pair.filename), mode=\"w+\", encoding=\"utf8\") as f:\n",
        "           json.dump(split_into_disjoint_subsets(a_clusters, b_clusters, a[\"text\"]), f, ensure_ascii='False')\n",
        "        print_log(\"=================\" + pair.filename + \" END=================\")\n",
        "        i += 1\n",
        "        if (i == 10):\n",
        "            break;"
      ],
      "metadata": {
        "id": "9erCsmIlodr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = get_pairs_from_two_dirs(\"./rucoco/data/split_data/test\", \"./rucoco/result\")\n",
        "log(pairs)"
      ],
      "metadata": {
        "id": "zyPWZNVbof5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_logs(ref_path, log_path):\n",
        "    text = \"\"\n",
        "    with open(ref_path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        data = json.load(f, strict=False)\n",
        "        text = data[\"text\"]\n",
        "        print_log(text)\n",
        "\n",
        "    with open(log_path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        logs = json.load(f, strict=False)\n",
        "        # logging.warning(logs)\n",
        "        for matched_corefs, not_identified_coref, wrong_corefs in logs:\n",
        "            print_log(\"Matched\")\n",
        "            print_log(\"===========\")\n",
        "            for coref in matched_corefs:\n",
        "                print_log(coref)\n",
        "                print_log(text[coref[0][0] : coref[0][1]])\n",
        "                print_log(text[coref[1][0] : coref[1][1]])\n",
        "                print_log(\"\")\n",
        "            print_log(\"===========\")\n",
        "            print_log(\"\")\n",
        "            print_log(\"Not identified\")\n",
        "            print_log(\"===========\")\n",
        "            print_log(\"\")\n",
        "            for coref in not_identified_coref:\n",
        "                print_log(coref)\n",
        "                # print_log(text[coref[0][0] : coref[0][1]])\n",
        "                # print_log(text[coref[1][0] : coref[1][1]])\n",
        "                start = coref[0][0]\n",
        "                end = coref[0][1]\n",
        "                print_adjacent_text(start, end, text)\n",
        "                start = coref[1][0]\n",
        "                end = coref[1][1]\n",
        "                print_adjacent_text(start, end, text)\n",
        "                print_log(\"\")\n",
        "            print_log(\"===========\")\n",
        "            print_log(\"\")\n"
      ],
      "metadata": {
        "id": "cs5c7LA0oiyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_logs(\"./rucoco/data/split_data/test/2000_finance_bujet_004.json\", \"./rucoco/res_view/view_json/2000_finance_bujet_004.json\")"
      ],
      "metadata": {
        "id": "sHmnFoxEYfJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print text with highlighted entity mentions"
      ],
      "metadata": {
        "id": "Bmg2O3h_RfO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_entity(entity, text):\n",
        "    print_log_in_line(indent)\n",
        "    print_log(entity)\n",
        "    i = 1\n",
        "    for span in entity:\n",
        "        print_log_in_line(indent + str(i) + \". \")\n",
        "        i += 1\n",
        "        print_adjacent_text(span[0], span[1], text)\n",
        "\n",
        "def print_corefs(text_path):\n",
        "    text = \"\"\n",
        "    with open(text_path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        data = json.load(f, strict=False)\n",
        "        text = data[\"text\"]\n",
        "        print_log(text)\n",
        "\n",
        "    i = 1\n",
        "    for entity in data[\"entities\"]:\n",
        "        print_log(\"\")\n",
        "        print_log(\"Сущность \" + str(i))\n",
        "        print_entity(entity, text)\n",
        "        i += 1\n",
        "        print_log(\"\")\n",
        "\n",
        "\n",
        "def highlite_entity_mentions(entities, text : str) -> str:\n",
        "    shift = 0\n",
        "    for entity in entities:\n",
        "        for span in entity:\n",
        "            # text = text[:span[0] + shift] + Fore.LIGHTGREEN_EX + text[span[0] + shift:span[1] + shift] + Style.RESET_ALL + text[span[1] + shift:]\n",
        "            # shift += len(Fore.GREEN) + len(Style.RESET_ALL)\n",
        "            text = text[:span[0]] + text[span[0]:span[1]].upper() + text[span[1]:]\n",
        "    return text\n",
        "\n",
        "def print_highlited(text_path : str):\n",
        "    text = \"\"\n",
        "    with open(text_path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        data = json.load(f, strict=False)\n",
        "        text = highlite_entity_mentions(data[\"entities\"], data[\"text\"])\n",
        "        print(text)"
      ],
      "metadata": {
        "id": "_yS7V7Hut5tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_corefs(\"./rucoco/kristina/kristinas_result/text_716918.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFdypA4VnQyc",
        "outputId": "c856727d-c153-4b85-b196-aebfd536cc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Как работает ChatGPT: объясняем на простом русском эволюцию языковых моделей с T9 до чуда / Habr\n",
            "\n",
            "\n",
            "               Как работает ChatGPT: объясняем на простом русском эволюцию языковых моделей с T9 до чуда Level of difficulty  \n",
            "    Easy\n",
            "   Reading time  \n",
            "    30 min\n",
            "   Views  235K Open Data Science corporate blog Machine learning *Artificial Intelligence The future is here Natural Language Processing * \n",
            "    Review\n",
            "        В последнее время нам почти каждый день рассказывают в новостях, какие очередные вершины покорили языковые нейросетки, и почему они уже через месяц совершенно точно оставят лично вас без работы. При этом мало кто понимает — а как вообще нейросети вроде ChatGPT работают внутри? Так вот, устраивайтесь поудобнее: в этой статье мы наконец объясним всё так, чтобы понял даже шестилетний гуманитарий!OpenAI (компанию, сделавшую ChatGPT) основали в 2015 году именно вот эти двое парнишек – кто бы тогда знал, во что это в итоге выльется...На всякий случай сразу оговоримся: у этой статьи два автора. За всю техническую часть (и за всё хорошее в статье) отвечал Игорь Котенков — широко известный чувак в узких кругах русскоязычной тусовки специалистов по искусственному интеллекту, а также автор канала Сиолошная про машинное обучение, космос и технологии. За мольбы «вот тут непонятно, давай как‑нибудь попроще!» и за добавление кринжовых неуместных мемов был ответственен Павел Комаровский — автор канала RationalAnswer про рациональный подход к жизни и финансам.Собственно, статья так и родилась: Павел пришел к Игорю и возмутился — дескать, «почему никто еще не написал на русском нормальную статью про ChatGPT, объясняющую понятно даже для моей бабушки, как всё вот это нейроколдунство работает?». Так что заранее приносим свои извинения всем хардкорным технарям: при подготовке этого текста мы стремились к максимальному упрощению. Нашей задачей было — дать читателям общее понимание принципов работы языковых нейросетей на уровне концепций и аналогий, а не разобрать до последнего винтика все глубокие технические нюансы процесса.В общем, наливайте себе кружечку горячего чая и устраивайтесь поудобнее — сейчас мы вам расскажем всё про то, что там крутится под капотом у языковых моделей, каким образом эти покемоны эволюционировали до текущих (местами поразительных) способностей, и почему взрывная популярность чат‑бота ChatGPT стала полным сюрпризом даже для его создателей. Поехали! (Кстати, этот материал есть еще и в формате видео.)НавигаторT9: сеанс языковой магии с разоблачениемОткуда нейросети берут вероятности слов?Парадокс Барака, или зачем языковым моделям уметь в творчество2018: GPT-1 трансформирует языковые модели2019: GPT-2, или как запихнуть в языковую модель семь тысяч ШекспировПочему в мире языковых моделей больше ценятся именно модели «Plus Size»2020: GPT-3, или как сделать из модели Невероятного ХалкаПромпты, или как правильно уламывать модельЯнварь 2022: InstructGPT, или как научить робота не зиговатьНоябрь 2022: ChatGPT, или маленькие секреты большого хайпаПодведем итогиT9: сеанс языковой магии с разоблачениемНачнем с простого. Чтобы разобраться в том, что такое ChatGPT с технической точки зрения, надо сначала понять, чем он точно не является. Это не «Бог из машины», не разумное существо, не аналог школьника (по уровню интеллекта и умению решать задачи), не джинн, и даже не обретший дар речи Тамагочи. Приготовьтесь услышать страшную правду: на самом деле, ChatGPT — это Т9 из вашего телефона, но на бычьих стероидах! Да, это так: ученые называют обе этих технологии «языковыми моделями» (Language Models); а всё, что они по сути делают, — это угадывают, какое следующее слово должно идти за уже имеющимся текстом.Ну, точнее, в совсем олдовых телефонах из конца 90-х (вроде культовой неубиваемой Nokia 3210) оригинальная технология Т9 лишь ускоряла набор на кнопочных телефонах за счет угадывания текущего вводимого, а не следующего слова. Но технология развивалась, и к эпохе смартфонов начала 2010-х она уже могла учитывать контекст (предыдущее слово), ставить пунктуацию и предлагать на выбор слова, которые могли бы идти следующими. Вот именно об аналогии с такой «продвинутой» версией T9/автозамены и идет речь.Кого ни разу не подставляла автозамена на телефоне – пусть первый бросит в меня каменьИтак, и Т9 на клавиатуре смартфона, и ChatGPT обучены решать до безумия простую задачу: предсказание единственного следующего слова. Это и есть языковое моделирование – когда по некоторому уже имеющемуся тексту делается вывод о том, что должно быть написано дальше. Чтобы иметь возможность делать такие предсказания, языковым моделям под капотом приходится оперировать вероятностями возникновения тех или иных слов для продолжения. Ведь, скорее всего, вы были бы недовольны, если бы автозаполнение в телефоне просто подкидывало вам абсолютно случайные слова с одинаковой вероятностью.Представим для наглядности, что вам прилетает сообщение от приятеля: «Чё, го седня куда нить?». Вы начинаете печатать в ответ: «Да не, у меня уже дела(( я иду в...», и вот тут подключается Т9. Если он предложит вам закончить предложение полностью рандомным словом, типа «я иду в капибару» — то для такой белиберды, если честно, никакая хитрая языковая модель особо и не нужна. Реальные же модели автозаполнения в смартфонах подсказывают гораздо более уместные слова (можете сами проверить прямо сейчас).Мой Samsung Galaxy предлагает такие варианты. Сразу видно типичного айтишника: получил зарплату, прокутил – и сразу в аптеку, лечиться!Так, а как конкретно Т9 понимает, какие слова будут следовать за уже набранным текстом с большей вероятностью, а какие предлагать точно не стоит? Для ответа на этот вопрос нам придется погрузиться в базовые принципы работы самых простейших нейросеток.Откуда нейросети берут вероятности слов?Давайте начнем с еще более простого вопроса: а как вообще предсказывать зависимости одних вещей от других? Предположим, мы хотим научить компьютер предсказывать вес человека в зависимости от его роста — как подойти к этой задаче?Здравый смысл подсказывает, что надо сначала собрать данные, на которых мы будем искать интересующие нас зависимости (для простоты ограничимся одним полом — возьмем статистику по росту/весу для нескольких тысяч мужчин), а потом попробуем «натренировать» некую математическую модель на поиск закономерности внутри этих данных.Для наглядности сначала нарисуем весь наш массив данных на графике: по горизонтальной оси  будем откладывать рост в сантиметрах, а по вертикальной оси — вес.Судя по нашим прикидкам, мужики в выборке попались в среднем ну такие – довольно упитанные (или сплошь качки на массе, тут сразу не разберешь)  Даже невооруженным взглядом видна определенная зависимость: высокие мужики, как правило, больше весят (спасибо, кэп!). И эту зависимость довольно просто выразить в виде обычного линейного уравнения , знакомого нам всем с пятого класса школы. На картинке нужная нам линия уже проведена с помощью модели линейной регрессии — по сути, она позволяет подобрать коэффициенты уравнения  и  таким образом, чтобы получившаяся линия оптимально описывала ключевую зависимость в нашем наборе данных (можете для интереса подставить свой рост в сантиметрах вместо  в уравнение на картинке и проверить, насколько точно наша модель угадает ваш вес).Вы тут уже наверняка хотите воскликнуть: «Окей, с ростом/весом и так интуитивно всё было понятно, только причем тут вообще языковые нейросети?» А притом, что нейросети — это и есть набор примерно тех же самых уравнений, только куда более сложных и использующих матрицы (но не будем сейчас об этом).Можно упрощенно сказать, что те же самые T9 или ChatGPT — это всего лишь хитрым образом подобранные уравнения, которые пытаются предсказать следующее слово (игрек) в зависимости от набора подаваемых на вход модели предыдущих слов (иксов). Основная задача при тренировке языковой модели на наборе данных — подобрать такие коэффициенты при этих иксах, чтобы они действительно отражали какую‑то зависимость (как в нашем примере с ростом/весом). А под большими моделями мы далее будем понимать такие, которые имеют очень большое количество параметров. В области ИИ их прямо так и называют — LLM, Large Language Models. Как мы увидим чуть дальше, «жирная» модель с множеством параметров — это залог успеха для генерации крутых текстов!Кстати, если вы в этом месте уже недоумеваете, почему мы всё время говорим о «предсказании одного следующего слова», тогда как тот же ChatGPT бодро отвечает целыми портянками текста – то не ломайте зря голову. Языковые модели без всякого труда генерируют длинные тексты, но делают они это по принципу «слово за словом». По сути, после генерации каждого нового слова, модель просто заново прогоняет через себя весь предыдущий текст вместе с только что написанным дополнением – и выплевывает последующее слово уже с учетом него. В результате получается связный текст.Парадокс Барака, или зачем языковым моделям уметь в творчествоНа самом деле, в наших уравнениях в качестве «игрека» языковые модели пытаются предсказать не столько конкретное следующее слово, сколько вероятности разных слов, которыми можно продолжить заданный текст. Зачем это нужно, почему нельзя всегда искать единственное, «самое правильное» слово для продолжения? Давайте разберем на примере небольшой игры.Правила такие: вы притворяетесь языковой моделью, а я вам предлагаю продолжить текст «44-й президент США (и первый афроамериканец на этой должности) — это Барак...». Подставьте слово, которое должно стоять вместо многоточия, и оцените вероятность, что оно там действительно окажется.Ваш ход, маэстро!Если вы сейчас сказали, что следующим словом должно идти «Обама» с вероятностью 100%, то поздравляю — вы ошиблись! И дело тут не в том, что существует какой‑то другой мифический Барак: просто в официальных документах имя президента часто пишется в полной форме, с указанием его второго имени (middle name) — Хуссейн. Так что правильно натренированная языковая модель должна, по‑хорошему, предсказать, что в нашем предложении «Обама» будет следующим словом только с вероятностью условно в 90%, а оставшиеся 10% выделить на случай продолжения текста «Хуссейном» (после которого последует Обама уже с вероятностью, близкой к 100%).И тут мы с вами подходим к очень интересному аспекту языковых моделей: оказывается, им не чужда творческая жилка! По сути, при генерации каждого следующего слова, такие модели выбирают его «случайным» образом, как бы кидая кубик. Но не абы как — а так, чтобы вероятности «выпадения» разных слов примерно соответствовали тем вероятностям, которые подсказывают модели зашитые внутрь нее уравнения (выведенные при обучении модели на огромном массиве разных текстов).Получается, что одна и та же модель даже на абсолютно одинаковые запросы может давать совершенно разные варианты ответа — прямо как живой человек. Вообще, ученые когда‑то пытались заставить нейронки всегда выбирать в качестве продолжения «наиболее вероятное» следующее слово — что на первый взгляд звучит логично, но на практике такие модели почему‑то работают хуже; а вот здоровый элемент случайности идет им строго на пользу (повышает вариативность и, в итоге, качество ответов).Учитывая вышесказанное, не советую вам спорить с нейросетками, используя способность к творчеству как аргумент за превосходство человеческого разума – может выйти конфузВообще, наш язык — это особая структура с (иногда) четкими наборами правил и исключений. Слова в предложениях не появляются из ниоткуда, они связаны друг с другом. Эти связи неплохо выучиваются человеком «в автоматическом режиме» — во время взросления и обучения в школе, через разговоры, чтение, и так далее. При этом для описания одного и того же события или факта люди придумывают множество способов в разных стилях, тонах и полутонах. Подход к языковой коммуникации у гопников в подворотне и, к примеру, у учеников младшей школы будет, скорее всего, совсем разным.Всю эту вариативность описательности языка и должна в себя вместить хорошая модель. Чем точнее модель оценивает вероятности слов в зависимости от нюансов контекста (предшествующей части текста, описывающей ситуацию) — тем лучше она способна генерировать ответы, которые мы хотим от нее услышать.ChatGPT показывает мастер-класс по вариативности: всегда приятно перетереть с понимающим кентом, который ровно объяснит, чё почём – увожение!Краткое резюме: На текущий момент мы выяснили, что несложные языковые модели применяются в функциях «T9/автозаполнения» смартфонов с начала 2010-х; а сами эти модели представляют собой набор уравнений, натренированных на больших объемах данных предсказывать следующее слово в зависимости от поданного «на вход» исходного текста.2018: GPT-1 трансформирует языковые моделиДавайте уже переходить от всяких дремучих T9 к более современным моделям: наделавший столько шума ChatGPT является наиболее свежим представителем семейства моделей GPT. Но чтобы понять, как ему удалось обрести столь необычные способности радовать людей своими ответами, нам придется сначала вернуться к истокам. GPT расшифровывается как Generative Pre‑trained Transformer, или «трансформер, обученный на генерацию текста». Трансформер — это название архитектуры нейросети, придуманной исследователями Google в далеком 2017 году (про «далекий» мы не оговорились: по меркам индустрии, прошедшие с тех пор шесть лет — это целая вечность).Именно изобретение Трансформера оказалось столь значимым, что вообще все области искусственного интеллекта (ИИ) — от текстовых переводов и до обработки изображений, звука или видео — начали его активно адаптировать и применять. Индустрия ИИ буквально получила мощную встряску: перешла от так называемой «зимы ИИ» к бурному развитию, и смогла преодолеть застой.Концептуально, Трансформер — это универсальный вычислительный механизм, который очень просто описать: он принимает на вход один набор последовательностей (данных) и выдает на выходе тоже набор последовательностей, но уже другой — преобразованный по некоему алгоритму. Так как текст, картинки и звук (да и вообще почти всё в этом мире) можно представить в виде последовательностей чисел — то с помощью Трансформера можно решать практически любые задачи.Но главная фишка Трансформера заключается в его удобстве и гибкости: он состоит из простых модулей‑блоков, которые очень легко масштабировать. Если старые, до‑трансформерные языковые модели начинали кряхтеть и кашлять (требовать слишком много ресурсов), когда их пытались заставить «проглотить» быстро и много слов за раз, то нейросети‑трансформеры справляются с этой задачей гораздо лучше.Более ранним подходам приходилось обрабатывать входные данные по принципу «один за другим», то есть последовательно. Поэтому, когда модель работала с текстом длиной в одну страницу, то уже к середине третьего параграфа она забывала, что было в самом начале (прямо как люди с утра, до того как они «бахнув кофейку»). А вот могучие лапища Трансформера позволяют ему смотреть на ВСЁ одновременно — и это приводит к гораздо более впечатляющим результатам.Внутрь T9 в вашем телефоне почти наверняка зашита модель попроще – так что попробуйте набрать эту строку там и сравнить результат (только уберите детей от экрана, на всякий случай)Именно это позволило сделать прорыв в нейросетевой обработке текстов (в том числе их генерации). Теперь модель не забывает: она переиспользует то, что уже было написано ранее, лучше держит контекст, а самое главное — может строить связи типа «каждое слово с каждым» на весьма внушительных объемах данных.Краткое резюме: GPT-1 появилась в 2018 году и доказала, что для генерации текстов нейросетью можно использовать архитектуру Трансформера, обладающую гораздо большей масштабируемостью и эффективностью. Это создало огромный задел на будущее по возможности наращивать объем и сложность языковых моделей.2019: GPT-2, или как запихнуть в языковую модель семь тысяч ШекспировЕсли вы хотите научить нейросетку для распознавания изображений отличать маленьких милых чихуабелей от маффинов с черничкой, то вы не можете просто сказать ей «вот ссылка на гигантский архив со 100 500 фотографий пёсов и хлебобулочных изделий — разбирайся!». Нет, чтобы обучить модель, вам нужно обязательно сначала разметить тренировочный набор данных — то есть, подписать под каждой фоткой, является ли она пушистой или сладкой.Игра «чихуабель или булка», уровень сложности – «Бог»А знаете, чем прекрасно обучение языковых моделей? Тем, что им можно «скармливать» совершенно любые текстовые данные, и эти самые данные заблаговременно никак не надо специальным образом размечать. Это как если бы в школьника можно было просто бросать чемодан с самыми разными книгами, без какой‑либо инструкции, что там и в каком порядке ему нужно выучить — а он бы сам в процессе чтения кумекал для себя какие‑то хитрые выводы!Если подумать, то это логично: мы же хотим научить языковую модель предсказывать следующее слово на основе информации о словах, которые идут перед ним? Ну дак совершенно любой текст, написанный человеком когда‑либо, — это и есть уже готовый кусочек тренировочных данных. Ведь он уже и так состоит из огромного количества последовательностей вида «куча каких‑то слов и предложений => следующее за ними слово».А теперь давайте еще вспомним, что обкатанная на GPT-1 технология Трансформеров оказалась на редкость удачной в плане масштабирования: она умеет работать с большими объемами данных и «массивными» моделями (состоящими из огромного числа параметров) гораздо эффективнее своих предшественников. Вы думаете о том же, о чем и я? Ну вот и ученые из OpenAI в 2019 году сделали такой же вывод: «Пришло время пилить здоровенные языковые модели!»В общем, было решено радикально прокачать GPT-2 по двум ключевым направлениям: набор тренировочных данных (датасет) и размер модели (количество параметров).На тот момент не было каких‑то специальных, больших и качественных, публичных наборов текстовых данных для тренировки языковых моделей — так что каждой команде специалистов по ИИ приходилось извращаться согласно их собственной степени испорченности. Вот ребята из OpenAI и решили поступить остроумно: они пошли на самый популярный англоязычный онлайн‑форум Reddit и тупо выкачали все гиперссылки из всех сообщений, имевших более трех лайков (я сейчас не шучу — научный подход, ну!). Всего таких ссылок вышло порядка 8 миллионов, а скачанные из них тексты весили в совокупности 40 гигабайт.Много это или мало? Давайте прикинем: собрание сочинений Уильяма Шекспира (всех его пьес, сонетов и стихов) состоит из 850'000 слов. В среднем на одной странице книги помещается около 300 английских слов — так что 2800 страниц чудесного, временами устаревшего английского текста за авторством величайшего англоязычного писателя займет в памяти компьютера примерно 5,5 мегабайт. Так вот: это в 7300 раз меньше, чем объем тренировочной выборки GPT-2... С учетом того, что люди в среднем читают по странице в минуту, даже если вы будете поглощать текст 24 часа в сутки без перерыва на еду и сон — вам потребуется почти 40 лет, чтобы догнать GPT-2 по эрудиции!Весь Шекспир – 13 увесистых томов, которые занимают целую полку. Если вы прочитаете примерно вот столько книг семь тысяч раз подряд, то станете такими уже умными, как GPT-2 (но это не точно!)Но одного объема тренировочных данных для получения крутой языковой модели недостаточно: ведь даже если посадить пятилетнего ребенка перечитывать всё собрание сочинений Шекспира вместе с лекциями по квантовой физике Фейнмана впридачу, то вряд ли он от этого станет сильно умнее. Так и тут: модель еще и сама по себе должна быть достаточно сложной и объемной, чтобы полноценно «проглотить» и «переварить» такой объем информации. А как измерить эту сложность модели, в чем она выражается?Почему в мире языковых моделей больше ценятся именно модели «Plus Size»Помните, мы чуть раньше говорили, что внутри языковых моделей (в супер‑упрощенном приближении) живут уравнения вида , где искомый игрек — это следующее слово, вероятность которого мы пытаемся предсказать, а иксы — это слова на входе, на основе которых мы делаем это предсказание?Так вот, как вы думаете: сколько было параметров в уравнении, описывающем самую большую модель GPT-2 в 2019 году? Может быть, сто тысяч, или пара миллионов? Ха, берите выше: таких параметров в формуле было аж полтора миллиарда (это вот столько: 1'500'000'000). Даже если просто записать такое количество чисел в файл и сохранить на компьютере, то он займет 6 гигабайт! С одной стороны, это сильно меньше, чем суммарный размер текстового массива данных, на котором мы тренировали модель (помните, который мы собирали по ссылкам с Reddit, на 40 Гб); с другой — модели ведь не нужно запоминать этот текст целиком, ей достаточно просто найти некие зависимости (паттерны, правила), которые можно вычленить из написанных людьми текстов.Эти параметры (их еще называют «веса», или «коэффициенты») получаются во время тренировки модели, затем сохраняются, и больше не меняются. То есть, при использовании модели в это гигантское уравнение каждый раз подставляются разные иксы (слова в подаваемом на вход тексте), но сами параметры уравнения (числовые коэффициенты  при иксах) при этом остаются неизменны.Думаю, если вам для каждого слова в разговоре пришлось бы решать по уравнению на полтора миллиарда параметров, то вы бы тоже стояли с примерно таким же лицом лицаЧем более сложное уравнение зашито внутрь модели (чем больше в нем параметров) — тем лучше модель предсказывает вероятности, и тем более правдоподобным будет генерируемый ей текст. И у этой самой большой на тот момент модели GPT-2 тексты внезапно стали получаться настолько хорошими, что исследователи из OpenAI даже побоялись публиковать модель в открытую из соображений безопасности. А ну как люди ринулись бы генерировать в промышленном масштабе реалистично выглядящие текстовые фейки, спам для соцсетей, и так далее?Нет, серьезно — это был прямо существенный прорыв в качестве! Вы же помните: предыдущие модели T9/GPT-1 худо‑бедно могли подсказать — собираетесь ли вы пойти в банк или в аптеку, а также угадать, что шоссейная Саша сосет сушки, а не что‑то иное. А вот GPT-2 уже легко написала эссе от лица подростка с ответом на вопрос: «Какие фундаментальные экономические и политические изменения необходимы для эффективного реагирования на изменение климата?» (тут и иные взрослые прикурили бы от серьезности темы). Текст ответа был под псевдонимом направлен жюри соответствующего конкурса — и те не заметили никакого подвоха. Ну, окей, оценки этой работе поставили не сильно высокие и в финал она не прошла — но и «что за чушь вы нам отправили, постыдились бы!!» тоже никто не воскликнул.«Эссе хорошо сформулировано и подкрепляет утверждения доказательствами, но идея не является оригинальной», – так один из кожаных мешков в жюри оценил работу нейросетки GPT-2.Переход количества в качество (почти по Марксу)Вообще, вот эта идея о том, что по мере наращивания размера модели у нее внезапно открываются качественно новые свойства (например, писать связные эссе со смыслом вместо простого подсказывания следующего слова в телефоне) — это довольно удивительная штука. Давайте поразбираем новоприобретенные скиллы GPT-2 чуть поподробнее.Есть специальные наборы задач на разрешение двусмысленности в тексте, которые помогают оценить понимание текста (хоть человеком, хоть нейросетью). Например, сравните два утверждения:Рыба заглотила приманку. Она была вкусной.Рыба заглотила приманку. Она была голодной. К какому объекту относится местоимение «она» в первом примере — к рыбе или к приманке? А во втором случае? Большинство людей легко понимают из контекста, что в одном случае «она» — это приманка, а в другом — рыба. Но для того, чтобы это осознать, нужно не просто прочитать предложение — а выстроить в голове целую картину мира! Ведь, например, рыба может быть в разных ситуациях и голодной, и вкусной (на тарелке в ресторане). Вывод о ее «голодности» в данном конкретном примере вытекает из контекста и ее, извините, кровожадных действий.Способна ли GPT-2 действительно понять этот мем и оценить его абсурдную красоту? Сейчас узнаем...Люди решают такие задачи правильно примерно в 95% случаев, а вот ранние языковые модели справлялись только в половине случаев (то есть, пытались угадать практически рандомно «50 на 50» — как в том анекдоте про «какова вероятность встретить на улице динозавра?»).Вы, наверное, подумали: «Ну, надо просто накопить большую базу таких задачек (на пару тысяч примеров) с ответами, прогнать через нейросеть — и натренировать ее на поиск правильного ответа». И со старыми моделями (с меньшим числом параметров) так и пытались сделать — но дотянуть их получалось только до примерно 60% успеха. А вот GPT-2 никто специально таким трюкам не учил; но она взяла, и сама неожиданно и уверенно превзошла своих «специализированных» предшественников — научилась определять голодных рыбов правильно в 70% случаев.Это и есть тот самый переход количества в качество, про который нам когда‑то твердил старина Карл Маркс. Причем он происходит совершенно нелинейно: например, при росте количества параметров в три раза от 115 до 350 млн никаких особых изменений в точности решения моделью «рыбных» задач не происходит, а вот при увеличении размера модели еще в два раза до 700 млн параметров — происходит качественный скачок, нейросеть внезапно «прозревает» и начинает поражать всех своими успехами в решении совершенно незнакомых ей задач, которые она раньше никогда не встречала и специально их не изучала.Краткое резюме: GPT-2 вышла в 2019 году, и она превосходила свою предшественницу и по объему тренировочных текстовых данных, и по размеру самой модели (числу параметров) в 10 раз. Такой количественный рост привел к тому, что модель неожиданно самообучилась качественно новым навыкам: от сочинения длинных эссе со связным смыслом, до решения хитрых задачек, требующих зачатков построения картины мира.2020: GPT-3, или как сделать из модели Невероятного ХалкаПоигравшись немного с располневшей (и от этого поумневшей) GPT-2, ребята из OpenAI подумали: «А почему бы не взять ту же самую модель, и не увеличить ее еще раз эдак в 100?» В общем, вышедшая в 2020 году следующая номерная версия, GPT-3, уже могла похвастаться в 116 раз большим количеством параметров — аж 175 миллиардов! Раскабаневшая нейросеть при этом сама по себе стала весить невероятные 700 гигабайт.Набор данных для обучения GPT-3 тоже прокачали, хоть и не столь радикально: он увеличился примерно в 10 раз до 420 гигабайт — туда запихнули кучу книг, Википедию, и еще множество текстов с самых разных интернет‑сайтов. Живому человеку поглотить такой объем информации уже точно нереально — ну, разве что, если посадить с десяток Анатолиев Вассерманов, чтобы они читали буквально нон‑стоп по 50 лет подряд каждый.GPT-3 может и быть умнее Онотолея, но осмелится ли она сказать ему это в лицо?..  Сразу бросается в глаза интересный нюанс: в отличие от GPT-2, сама модель теперь имеет размер больше (700 Гб), чем весь массив текста для ее обучения (420 Гб). Получается как будто бы парадокс: наш «нейромозг» в данном случае в процессе изучения сырых данных генерирует информацию о разных взаимозависимостях внутри них, которая превышает по объему исходную информацию.Такое обобщение («осмысление»?) моделью позволяет еще лучше прежнего делать экстраполяцию — то есть, показывать хорошие результаты в задачах на генерацию текстов, которые при обучении встречались очень редко или не встречались вовсе. Теперь уже точно не нужно учить модель решать конкретную задачу — вместо этого достаточно описать словами проблему, дать несколько примеров, и GPT-3 схватит на лету, чего от нее хотят!И тут в очередной раз оказалось, что «универсальный Халк» в виде GPT-3 (которую никто никаким «узким» задачам не обучал) с легкостью кладет на лопатки многие специализированные модели, которые существовали до нее: так, перевод текстов с французского или немецкого на английский сразу начал даваться GPT-3 легче и лучше, чем любым другим специально заточенным под это нейросетям. Как?! Напоминаю, что речь идет про лингвистическую модель, чье предназначение вообще‑то заключалось ровно в одном — пытаться угадать одно следующее слово к заданному тексту... Откуда здесь берутся способности к переводу?Но это еще цветочки — еще более удивительно то, что GPT-3 смогла научить сама себя... математике! На графике ниже (источник: оригинальная статья) показана точность ответов нейросетей с разным количеством параметров на задачки, связанные со сложением/вычитанием, а также с умножением чисел вплоть до пятизначных. Как видите, при переходе от моделей с 10 миллиардами параметров к 100 миллиардам — нейросети внезапно и резко начинают «уметь» в математику.По горизонтали – количество параметров в модели (в миллиардах), по вертикали – качество модели, выраженное в проценте верно решенных математических примеровЕще раз, вдумайтесь: языковую модель обучали продолжать тексты словами, а она при этом как‑то смогла сама разобраться в том, что если ей печатают «378 + 789 =», то на это надо отвечать именно «1167», а не каким‑то другим числом. Магия, ей‑богу, магия! (Хотя, некоторые говорят «да это нейросетка просто все варианты успела увидеть и тупо запомнить в тренировочных данных» — так что дебаты о том, магия это или всего лишь попугайство, пока продолжаются.)На графике выше самое интересное — это то, что при увеличении размера модели (слева направо) сначала как будто бы не меняется ничего, а затем — р‑раз! Происходит качественный скачок, и GPT-3 начинает «понимать», как решать ту или иную задачу. Как, что, почему это работает — никто точно не знает. Но работает как‑то; причем, не только в математике — но и вообще в самых разнообразных других задачах!Анимация ниже как раз наглядно показывает, как с увеличением количества параметров модели в ней «прорастают» новые способности, которые никто туда специально не закладывал:Кстати, задачу про «голодных рыбов», которой мы мучали GPT-2 в прошлом разделе, GPT-3 уже решает с точностью выше 90% — прямо как человек. Заставляет задуматься, правда: а какие новые скиллы обретет нейросеть, если увеличить ее объем еще раз в сто? Ну там, до десятков триллионов параметров, например...Промпты, или как правильно уламывать модельДавайте здесь сделаем небольшое отступление в сторону и обсудим, а что это вообще означает — «модель умеет решать задачи»? По сути, процесс выглядит так: мы подаем на вход модели некий текст с запросом, а она к нему дописывает свое продолжение. Если это продолжение (генерация) совпадает с нашими ожиданиями — то модель, получается, решила поставленную перед ней задачу.Тот текст, что мы подаем на вход, называется prompt (промпт, или «запрос/затравка» по‑русски). Чем точнее он описывает, что мы хотим, тем лучше модель поймет, что ей нужно делать. А если мы ей еще и примеров отсыпем с десяток — то вообще шик! Пример детального запроса для перевода с английского на французский: сначала описывается задача, затем приводится 3 примера желаемого поведения, после чего пишется новое слово или предложение – а модель следом сгенерирует корректный перевод (ну, это самый простейший пример, она может и посложнее, конечно)Без описания цели и без примеров в промпте, модель тоже обычно понимает проблему, но предлагает не такие хорошие решения (с точки зрения их качества). Можно сказать, что детализированный промпт позволяет GPT лучше оценить вероятности слов, которые нужно генерировать в качестве ответа, направляя ее в «требуемое русло».Но насколько сложным должен быть промпт? И насколько модель по пониманию близка к нам? Вы не поверите, но совсем недавно исследователи выяснили, что для существенного улучшения результатов генерации нужно добавить в промпт простую советскую...Окей, кроме шуток, но добавление всего одной фразы перед ответом на вопрос существенно улучшает качество модели. И эта магическая фраза — «пожалуйста» «let»s think step by step» (давай подумаем шаг за шагом). Внезапно оказалось, что это побуждает модель рассуждать последовательно, делать выводы на основе собственных суждений, и приходить к правильному ответу гораздо чаще, чем без этой фразы.Как это работает? Давайте на примере детской задачки:Вопрос: В среднем боксер Иван наносит 25 ударов в минуту. Бой длится 5 раундов по 3 минуты. Сколько ударов он нанес?Ответ: 255Текст, выделенный жирным – это ответ, сгенерированный языковой моделью. Легко проверить, что он – ну, немного неправильный.Лицо боксера Ивана, когда он пытается посчитать – сколько честно нанесенных ударов «украла» у него языковая модель?Однако та же самая модель может ответить вот так:Вопрос: В среднем боксер Иван наносит 25 ударов в минуту. Бой длится 5 раундов по 3 минуты. Сколько ударов он нанес?Ответ: Давай подумаем шаг за шагом. За одну минуту Иван наносит 25 ударов. За три минуты Иван наносит 3 * 25 = 75 ударов. За пять раундов Иван наносит 5 * 75 = 375 ударов.И снова текст выделенный жирным — это ответ модели. Видно, что он стал длиннее, решение задачи получилось прямо как у школьника — в три действия. Четко, последовательно — ровно так, как мы и попросили. И финальная цифра 375 является корректным ответом на исходный вопрос. Отдельно отмечу: мы никак не дообучали модель после того, как она ответила неправильно — это абсолютно та же самая модель. Мы просто дописали пять дополнительных слов в конец нашего промпта, и произошло чудо!Причем вот этот «режим рассуждения» — это одна из качественно новых фишек, которые появились в «большой» модели GPT-3 после преодоления планки в сотню миллиардов параметров. Старые модели с меньшим количеством параметров такие фокусы показывать не умели, как их ни упрашивай специальными подсказками «ну подумой, братишка!».Вообще, составление грамотных промптов для модели — это отдельная наука. Под эту задачу компании уже начали нанимать отдельных людей с должностью «промпт‑инженер» (то есть человек, сочиняющий запросы для языковых моделей) — вангую, что до появления онлайн‑курсов «🐺🐺🐺Научись промпт‑инжинирингу за 6 недель и вкатись в перспективную индустрию с зарплатой 300к в месяц!🐺🐺🐺» осталось всего ничего.Краткое резюме: GPT-3 образца 2020 года была в 100 раз больше своей предшественницы по количеству параметров, и в 10 раз – по объему тренировочных текстовых данных. И снова рост количества привел к внезапному скачку в качестве: модель научилась переводу с других языков, арифметике, базовому программированию, пошаговым рассуждениям, и многому другому.Январь 2022: InstructGPT, или как научить робота не зиговатьНа самом деле, увеличение размеров языковых моделей само по себе еще не означает, что они будут отвечать на запросы именно так, как хочет их пользователь. Ведь часто мы, когда формулируем какой‑то запрос, подразумеваем очень много скрытых условий — которые в коммуникации между людьми считаются сами собой разумеющимися, что ли. Например, когда Маша просит своего мужа: «Вась, сходи выбрось мусор» — то вряд ли ей придет в голову прибавить к этому промпту «(только не из окна, плз!)». Ведь Вася это понимает и без уточнений — а всё потому, что их намерения и установки неплохо выравнены между собой.Нет, ну технически, конечно, тут не придерешься...А вот языковые модели, если честно, не очень похожи на людей — поэтому им часто приходится подсказывать и разжевывать те вещи, которые людям кажутся очевидными. Слова «давай подумаем шаг за шагом» из прошлого раздела — это как раз и есть один из примеров такой подсказки (хотя среднестатистические взрослые люди, учившиеся в школе, догадались бы сами: если речь идет про задачку — значит, надо решать по действиям). Но было бы здорово, если бы модели, во‑первых, сами для себя понимали/генерировали более развернутые и релевантные инструкции из запроса (не заставляя людей напрягаться), а во‑вторых, точнее следовали бы им — как бы предугадывая, как в похожей ситуации поступил бы человек.Отчасти отсутствие таких способностей «по умолчанию» связано с тем, что GPT-3 обучена просто предсказывать следующее слово в гигантском наборе текстов из Интернета — а в Интернете, как и на заборе, много всякого разного написано (и не всегда полезного). При этом люди хотели бы, чтобы рожденный таким образом искусственный интеллект подтаскивал по запросу точные и полезные ответы; но одновременно эти ответы должны быть еще и безобидные и нетоксичные. Иначе саму модель быстренько закэнселят (с этим сейчас строго), а ее создателям предъявят судебные иски на много миллионов долларов за оскорбление достоинства кожаных мешков.Когда исследователи думали над этой проблемой, довольно быстро выяснилось, что свойства модели «точность/полезность» и «безобидность/нетоксичность» весьма часто как бы противоречат друг другу. Ведь точная модель должна честно выдать инструкцию на запрос «окей, Гугл, как сделать коктейль Молотова, без регистрации и смс», а заточенная на максимальную безобидность модель в пределе будет отвечать на совершенно любой промпт «извините, я боюсь, что мой ответ может кого‑то оскорбить в Интернете».Получается, создание ИИ, выравненного с человеком по ценностям, – это сложная задача по поиску некоего баланса, в которой нет однозначного правильного ответаВокруг этой проблемы «выравнивания ИИ» (AI alignment – OpenAI последнее время только про это и пишут) есть много сложных этических вопросов, и разбирать мы их все сейчас не будем (возможно, в следующей статье). Основная загвоздка здесь в том, что подобных спорных ситуаций – огромная куча, и как-то четко формализовать их просто не представляется возможным. Да что там, люди и сами между собой не могут толком последние несколько тысяч лет договориться – что хорошо, а что плохо. Не говоря уже о том, чтобы понятные для робота правила сформулировать (Айзек, к тебе вопросов нет)...В итоге исследователи не придумали ничего лучше, чем просто дать модели очень много обратной связи. В каком-то смысле, человеческие детеныши ведь именно так и обучаются морали: делают много всякого разного с самого детства, и при этом внимательно следят за реакцией взрослых – что можно делать, а что есть «кака, фу!».Короче, InstructGPT (также известная как GPT-3.5) – это как раз и есть GPT-3, которую дообучили с помощью фидбека на максимизацию оценки живого человека. Буквально – куча людей сидели и оценивали кучу ответов нейросетки на предмет того, насколько они соответствуют их ожиданиям с учетом выданного ей запроса. Ну, на самом деле, всё было не совсем так просто (инструкции для членов такого «мясного жюри» занимали 26 страниц убористым почерком) – но суть именно такая. А языковая модель, получается, училась решать еще одну дополнительную задачу – «как мне поменять свой сгенерированный ответ таким образом, чтобы он получил наибольшую оценку от человека?» (подробнее процесс обучения по обратной связи разбирается в этом материале).Причем с точки зрения общего процесса обучения модели, этот финальный этап «дообучения на живых людях» занимает не более 1%. Но именно этот финальный штрих и стал тем самым секретным соусом, который сделал последние модели из серии GPT настолько удивительными! Получается, GPT-3 до этого уже обладала всеми необходимыми знаниями: понимала разные языки, помнила исторические события, знала отличия стилей разных авторов, и так далее. Но только с помощью обратной связи от других людей модель научилась пользоваться этими знаниями именно таким образом, который мы (люди) считаем «правильным». В каком-то смысле, GPT-3.5 – это модель, «воспитанная обществом».Краткое резюме: GPT-3.5 (также известная как InstructGPT) появилась в начале 2022 года, и главной ее фишкой стало дополнительное дообучение на основе обратной связи от живых людей. Получается, что эта модель формально вроде как больше и умнее не стала – но зато научилась подгонять свои ответы таким образом, чтобы люди от них дичайше кайфовали.Ноябрь 2022: ChatGPT, или маленькие секреты большого хайпаChatGPT вышла в ноябре 2022 года — примерно через 10 месяцев после своей предшественницы, InstructGPT/GPT-3.5 — и мгновенно прогремела на весь мир. Кажется, что последние несколько месяцев даже бабушки на лавочке у подъезда обсуждают только одно — что там нового сказала эта ваша «ЧатЖПТ», и кого она по самым свежим прогнозам вот‑вот оставит без работы.При этом с технической точки зрения, кажется, у нее нет каких‑то особо мощных отличий от InstructGPT (к сожалению, научной статьи с детальным описанием ChatGPT команда OpenAI пока так и не опубликовала — так что мы тут можем только гадать). Ну окей, про некоторые менее значимые отличия мы всё же знаем: например, про то, что модель дотренировали на дополнительном диалоговом наборе данных. Ведь есть вещи, которые специфичны именно для работы «ИИ‑ассистента» в формате диалога: например, если запрос пользователя неясен — то можно (и нужно!) задать уточняющий вопрос, и так далее.Как учит нас кинематограф, правильно натренированный в искусстве диалога ИИ может заставить пользователя сделать практически что угодно...Но это уже детали — нам здесь важно, что основные технические характеристики (архитектура, количество параметров...) нейросетки не поменялись кардинально по сравнению с прошлым релизом. Отсюда возникает вопрос — как так? Почему мы не слышали никакого хайпа про GPT-3.5 еще в начале 2022-го? При том, что Сэм Альтман (исполнительный директор OpenAI) честно признался, что исследователи сами удивились такому бурному успеху ChatGPT — ведь сравнимая с ней по способностям модель к тому моменту тихо‑мирно лежала на их сайте уже более десяти месяцев, и никому не было до этого дела.Это удивительно, но похоже, что главный секрет успеха новой ChatGPT — это всего лишь удобный интерфейс! К той же InstructGPT обращаться можно было лишь через специальный API‑интерфейс — то есть, сделать это заведомо могли только нёрды‑айтишники, а не обычные люди. А ChatGPT усадили в привычный интерфейс «диалогового окна», прямо как в знакомых всем мессенджерах. Да еще и открыли публичный доступ вообще для всех подряд — и люди массово ринулись вести диалоги с нейросетью, скринить их и делиться в соцсетях. Choo‑choo, all aboard the hype train!Если вы заставили робота сочинить для вас объяснение квантовой физики в форме рэп-телеги от Снуп Дога – то, признайтесь, это окажется в вашем Твиттере быстрее, чем вы успеете моргнутьКак и в любом технологическом стартапе, здесь оказалась важна не только сама технология — но и обертка, в которую она была завернута. У вас может быть самая лучшая модель или самый умный чат‑бот — но они будут никому не интересны, если к ним не прилагается простой и понятный интерфейс. И ChatGPT в этом смысле совершил прорыв, выведя технологию в массы за счет обычного диалогового окна, в котором дружелюбный робот «печатает» ответ прямо на глазах, слово за словом.Неудивительно, что ChatGPT установил абсолютные рекорды по скорости привлечения новых пользователей: отметку в 1 миллион юзеров он достиг в первые пять дней после релиза, а за 100 миллионов перевалил всего за два месяца.Ну а там, где есть рекордно быстрый приток сотен миллионов пользователей — конечно, тут же появятся и большие деньги. Microsoft оперативно заключила с OpenAI сделку по инвестированию в них десятка миллиардов долларов, инженеры Google забили тревогу и сели думать, как им спасти свой поисковый сервис от конкуренции с нейросетью, а китайцы в срочном порядке анонсировали скорый релиз своего собственного чат‑бота. Но это всё, если честно, уже совсем другая история — следить за которой вы можете сейчас сами «в прямом эфире»...Краткое резюме: Модель ChatGPT вышла в ноябре 2022-го и с технической точки зрения там не было никаких особых нововведений. Но зато у нее был удобный интерфейс взаимодействия и открытый публичный доступ — что немедленно породило огромную волну хайпа. А в нынешнем мире это главнее всего — так что языковыми моделями одномоментно начали заниматься вообще все вокруг!Подведем итогиСтатья получилась не очень короткой — но надеемся, что вам было интересно, и просле прочтения вы чуть лучше стали понимать, что же конкретно творится под капотом этих самых нейросетей. Кстати, у Игоря Котенкова (одного из авторов этой статьи) есть еще один лонгрид на Хабре под названием «ChatGPT как инструмент для поиска: решаем основную проблему», в котором нюансы машинного обучения разбираются еще более подробно.Для вашего удобства мы сделали небольшой сводный постер, который наглядно иллюстрирует основные вехи истории эволюции языковых моделей. Если какой‑то этап кажется вам не очень понятным — можете просто вернуться чуть назад к соответствующему разделу в тексте и перечитать его заново (ну или задать нам уточняющие вопросы в комментариях).На самом деле, в первоначальном плане статьи у нас было гораздо больше пунктов: мы хотели подробнее обсудить и проблемы контроля за искусственным интеллектом, и жадность корпораций, которые в высококонкурентной погоне за прибылью могут случайно родить ИИ‑Франкенштейна, и сложные философские вопросы вроде «можно ли считать, что нейросеть умеет мыслить, или всё же нет?».Если на эту статью будет много положительных отзывов, то все эти (на наш взгляд — супер‑захватывающие!) темы мы разберем в следующем материале. Если вы не хотите его пропустить — то приглашаем вас подписаться на ТГ‑каналы авторов: Сиолошная Игоря Котенкова (для тех, кто хочет шарить за технологии) и RationalAnswer Павла Комаровского (для тех, кто за рациональный подход к жизни, но предпочитает чуть попроще). Всё, всем спасибо за внимание — с нетерпением ждем ваших комментариев!UPD: Следующую статью из серии с разбором GPT-4 можно прочитать здесь.GPT-4: Чему научилась новая нейросеть, и почему это немного жутковатоВ этой статье мы разберем новые удивительные способности последней языковой модели из семейства GPT ...habr.com      Tags: chatgptнейросетиopenaigptt9генеративные моделиязыковые моделимашинное обучениегенерацияnatural language processing  Hubs: Open Data Science corporate blogMachine learningArtificial IntelligenceThe future is hereNatural Language Processing          \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Сущность 1\n",
            "\t\t[[15, 22], [129, 136], [678, 685], [849, 856], [2388, 2391], [3184, 3186], [3967, 3970], [4155, 4157], [4275, 4277], [12877, 12880], [17283, 17286], [17416, 17421], [20623, 20625], [24704, 24709], [38879, 38884], [39459, 39469], [42533, 42540], [45288, 45293]]\n",
            "\t\t1. Как работает \u001b[92mChatGPT\u001b[0m: объясняем на простом русском эволюцию языковых моделей с T9 до чуда / Habr\n",
            "\t\t2.                Как работает \u001b[92mChatGPT\u001b[0m: объясняем на простом русском эволюцию языковых моделей с T9 до чуда Level of d\n",
            "\t\t3. лично вас без работы. При этом мало кто понимает — а как вообще нейросети вроде \u001b[92mChatGPT\u001b[0m работают внутри? Так вот, устраивайтесь поудобнее: в этой статье мы наконец объ\n",
            "\t\t4. м всё так, чтобы понял даже шестилетний гуманитарий!OpenAI (компанию, сделавшую \u001b[92mChatGPT\u001b[0m) основали в 2015 году именно вот эти двое парнишек – кто бы тогда знал, во что \n",
            "\t\t5. и почему взрывная популярность чат‑бота ChatGPT стала полным сюрпризом даже для \u001b[92mего\u001b[0m создателей. Поехали! (Кстати, этот материал есть еще и в формате видео.)Навигат\n",
            "\t\t6. я в том, что такое ChatGPT с технической точки зрения, надо сначала понять, чем \u001b[92mон\u001b[0m точно не является. Это не «Бог из машины», не разумное существо, не аналог школ\n",
            "\t\t7. следующего слова. Но технология развивалась, и к эпохе смартфонов начала 2010-х \u001b[92mона\u001b[0m уже могла учитывать контекст (предыдущее слово), ставить пунктуацию и предлагат\n",
            "\t\t8.  могли бы идти следующими. Вот именно об аналогии с такой «продвинутой» версией \u001b[92mT9\u001b[0m/автозамены и идет речь.Кого ни разу не подставляла автозамена на телефоне – пус\n",
            "\t\t9. е подставляла автозамена на телефоне – пусть первый бросит в меня каменьИтак, и \u001b[92mТ9\u001b[0m на клавиатуре смартфона, и ChatGPT обучены решать до безумия простую задачу: пр\n",
            "\t\t10. ется наиболее свежим представителем семейства моделей GPT. Но чтобы понять, как \u001b[92mему\u001b[0m удалось обрести столь необычные способности радовать людей своими ответами, нам\n",
            "\t\t11. технология Трансформеров оказалась на редкость удачной в плане масштабирования: \u001b[92mона\u001b[0m умеет работать с большими объемами данных и «массивными» моделями (состоящими и\n",
            "\t\t12. ивными» моделями (состоящими из огромного числа параметров) гораздо эффективнее \u001b[92mсвоих\u001b[0m предшественников. Вы думаете о том же, о чем и я? Ну вот и ученые из OpenAI в 2\n",
            "\t\t13. ddit, на 40 Гб); с другой — модели ведь не нужно запоминать этот текст целиком, \u001b[92mей\u001b[0m достаточно просто найти некие зависимости (паттерны, правила), которые можно вы\n",
            "\t\t14. льно таким трюкам не учил; но она взяла, и сама неожиданно и уверенно превзошла \u001b[92mсвоих\u001b[0m «специализированных» предшественников — научилась определять голодных рыбов пра\n",
            "\t\t15. торый сделал последние модели из серии GPT настолько удивительными! Получается, \u001b[92mGPT-3\u001b[0m до этого уже обладала всеми необходимыми знаниями: понимала разные языки, помни\n",
            "\t\t16. олнительное дообучение на основе обратной связи от живых людей. Получается, что \u001b[92mэта модель\u001b[0m формально вроде как больше и умнее не стала – но зато научилась подгонять свои \n",
            "\t\t17. бный робот «печатает» ответ прямо на глазах, слово за словом.Неудивительно, что \u001b[92mChatGPT\u001b[0m установил абсолютные рекорды по скорости привлечения новых пользователей: отмет\n",
            "\t\t18. с нетерпением ждем ваших комментариев!UPD: Следующую статью из серии с разбором \u001b[92mGPT-4\u001b[0m можно прочитать здесь.GPT-4: Чему научилась новая нейросеть, и почему это немно\n",
            "\n",
            "\n",
            "Сущность 2\n",
            "\t\t[[443, 446], [751, 753], [1747, 1751], [1816, 1818], [1857, 1862], [2137, 2139], [5661, 5664], [6081, 6083], [6110, 6113], [6372, 6375], [6499, 6504], [8350, 8352], [9979, 9984], [12151, 12153], [30276, 30278], [30412, 30418], [30507, 30509], [30616, 30618], [30679, 30681], [31245, 31248], [31442, 31445], [33145, 33147], [33197, 33203], [34526, 34528], [44077, 44079], [44354, 44357], [44440, 44443], [44473, 44475], [44833, 44836], [44873, 44875]]\n",
            "\t\t1.         В последнее время \u001b[92mнам\u001b[0m почти каждый день рассказывают в новостях, какие очередные вершины покорили язы\n",
            "\t\t2.  вроде ChatGPT работают внутри? Так вот, устраивайтесь поудобнее: в этой статье \u001b[92mмы\u001b[0m наконец объясним всё так, чтобы понял даже шестилетний гуманитарий!OpenAI (комп\n",
            "\t\t3. й бабушки, как всё вот это нейроколдунство работает?». Так что заранее приносим \u001b[92mсвои\u001b[0m извинения всем хардкорным технарям: при подготовке этого текста мы стремились к\n",
            "\t\t4. е приносим свои извинения всем хардкорным технарям: при подготовке этого текста \u001b[92mмы\u001b[0m стремились к максимальному упрощению. Нашей задачей было — дать читателям общее\n",
            "\t\t5.  технарям: при подготовке этого текста мы стремились к максимальному упрощению. \u001b[92mНашей\u001b[0m задачей было — дать читателям общее понимание принципов работы языковых нейросе\n",
            "\t\t6.  общем, наливайте себе кружечку горячего чая и устраивайтесь поудобнее — сейчас \u001b[92mмы\u001b[0m вам расскажем всё про то, что там крутится под капотом у языковых моделей, каки\n",
            "\t\t7. ьшей вероятностью, а какие предлагать точно не стоит? Для ответа на этот вопрос \u001b[92mнам\u001b[0m придется погрузиться в базовые принципы работы самых простейших нейросеток.Отку\n",
            "\t\t8.  задаче?Здравый смысл подсказывает, что надо сначала собрать данные, на которых \u001b[92mмы\u001b[0m будем искать интересующие нас зависимости (для простоты ограничимся одним полом\n",
            "\t\t9. ывает, что надо сначала собрать данные, на которых мы будем искать интересующие \u001b[92mнас\u001b[0m зависимости (для простоты ограничимся одним полом — возьмем статистику по росту\n",
            "\t\t10. а поиск закономерности внутри этих данных.Для наглядности сначала нарисуем весь \u001b[92mнаш\u001b[0m массив данных на графике: по горизонтальной оси  будем откладывать рост в санти\n",
            "\t\t11.  оси  будем откладывать рост в сантиметрах, а по вертикальной оси — вес.Судя по \u001b[92mнашим\u001b[0m прикидкам, мужики в выборке попались в среднем ну такие – довольно упитанные (и\n",
            "\t\t12.  генерации крутых текстов!Кстати, если вы в этом месте уже недоумеваете, почему \u001b[92mмы\u001b[0m всё время говорим о «предсказании одного следующего слова», тогда как тот же Ch\n",
            "\t\t13. авильно натренированная языковая модель должна, по‑хорошему, предсказать, что в \u001b[92mнашем\u001b[0m предложении «Обама» будет следующим словом только с вероятностью условно в 90%,\n",
            "\t\t14. та, описывающей ситуацию) — тем лучше она способна генерировать ответы, которые \u001b[92mмы\u001b[0m хотим от нее услышать.ChatGPT показывает мастер-класс по вариативности: всегда \n",
            "\t\t15.  вообще означает — «модель умеет решать задачи»? По сути, процесс выглядит так: \u001b[92mмы\u001b[0m подаем на вход модели некий текст с запросом, а она к нему дописывает свое прод\n",
            "\t\t16.  нему дописывает свое продолжение. Если это продолжение (генерация) совпадает с \u001b[92mнашими\u001b[0m ожиданиями — то модель, получается, решила поставленную перед ней задачу.Тот те\n",
            "\t\t17. ми — то модель, получается, решила поставленную перед ней задачу.Тот текст, что \u001b[92mмы\u001b[0m подаем на вход, называется prompt (промпт, или «запрос/затравка» по‑русски). Че\n",
            "\t\t18.  prompt (промпт, или «запрос/затравка» по‑русски). Чем точнее он описывает, что \u001b[92mмы\u001b[0m хотим, тем лучше модель поймет, что ей нужно делать. А если мы ей еще и примеро\n",
            "\t\t19. н описывает, что мы хотим, тем лучше модель поймет, что ей нужно делать. А если \u001b[92mмы\u001b[0m ей еще и примеров отсыпем с десяток — то вообще шик! Пример детального запроса \n",
            "\t\t20. точки зрения их качества). Можно сказать, что детализированный промпт позволяет \u001b[92mGPT\u001b[0m лучше оценить вероятности слов, которые нужно генерировать в качестве ответа, н\n",
            "\t\t21.  насколько сложным должен быть промпт? И насколько модель по пониманию близка к \u001b[92mнам\u001b[0m? Вы не поверите, но совсем недавно исследователи выяснили, что для существенног\n",
            "\t\t22. ль после того, как она ответила неправильно — это абсолютно та же самая модель. \u001b[92mМы\u001b[0m просто дописали пять дополнительных слов в конец нашего промпта, и произошло чу\n",
            "\t\t23. солютно та же самая модель. Мы просто дописали пять дополнительных слов в конец \u001b[92mнашего\u001b[0m промпта, и произошло чудо!Причем вот этот «режим рассуждения» — это одна из кач\n",
            "\t\t24. они будут отвечать на запросы именно так, как хочет их пользователь. Ведь часто \u001b[92mмы\u001b[0m, когда формулируем какой‑то запрос, подразумеваем очень много скрытых условий —\n",
            "\t\t25. ом нюансы машинного обучения разбираются еще более подробно.Для вашего удобства \u001b[92mмы\u001b[0m сделали небольшой сводный постер, который наглядно иллюстрирует основные вехи и\n",
            "\t\t26. азад к соответствующему разделу в тексте и перечитать его заново (ну или задать \u001b[92mнам\u001b[0m уточняющие вопросы в комментариях).На самом деле, в первоначальном плане статьи\n",
            "\t\t27. очняющие вопросы в комментариях).На самом деле, в первоначальном плане статьи у \u001b[92mнас\u001b[0m было гораздо больше пунктов: мы хотели подробнее обсудить и проблемы контроля з\n",
            "\t\t28. На самом деле, в первоначальном плане статьи у нас было гораздо больше пунктов: \u001b[92mмы\u001b[0m хотели подробнее обсудить и проблемы контроля за искусственным интеллектом, и ж\n",
            "\t\t29. ё же нет?».Если на эту статью будет много положительных отзывов, то все эти (на \u001b[92mнаш\u001b[0m взгляд — супер‑захватывающие!) темы мы разберем в следующем материале. Если вы \n",
            "\t\t30. о положительных отзывов, то все эти (на наш взгляд — супер‑захватывающие!) темы \u001b[92mмы\u001b[0m разберем в следующем материале. Если вы не хотите его пропустить — то приглашае\n",
            "\n",
            "\n",
            "Сущность 3\n",
            "\t\t[[523, 542], [553, 556]]\n",
            "\t\t1. нам почти каждый день рассказывают в новостях, какие очередные вершины покорили \u001b[92mязыковые нейросетки\u001b[0m, и почему они уже через месяц совершенно точно оставят лично вас без работы. Пр\n",
            "\t\t2. вают в новостях, какие очередные вершины покорили языковые нейросетки, и почему \u001b[92mони\u001b[0m уже через месяц совершенно точно оставят лично вас без работы. При этом мало кт\n",
            "\n",
            "\n",
            "Сущность 4\n",
            "\t\t[[738, 750], [1496, 1502], [1803, 1815]]\n",
            "\t\t1. бще нейросети вроде ChatGPT работают внутри? Так вот, устраивайтесь поудобнее: в\u001b[92m этой статье\u001b[0m мы наконец объясним всё так, чтобы понял даже шестилетний гуманитарий!OpenAI (к\n",
            "\t\t2. ор канала RationalAnswer про рациональный подход к жизни и финансам.Собственно, \u001b[92mстатья\u001b[0m так и родилась: Павел пришел к Игорю и возмутился — дескать, «почему никто еще \n",
            "\t\t3. ак что заранее приносим свои извинения всем хардкорным технарям: при подготовке \u001b[92mэтого текста\u001b[0m мы стремились к максимальному упрощению. Нашей задачей было — дать читателям об\n",
            "\n",
            "\n",
            "Сущность 5\n",
            "\t\t[[1926, 1945], [2520, 2529], [5747, 5756], [8506, 8521], [8577, 8580], [8663, 8669], [8700, 8704], [10559, 10565], [10581, 10584], [10620, 10626], [15279, 15282], [15984, 15986], [16106, 16112], [28539, 28548], [28886, 28888], [33084, 33087]]\n",
            "\t\t1. упрощению. Нашей задачей было — дать читателям общее понимание принципов работы \u001b[92mязыковых нейросетей\u001b[0m на уровне концепций и аналогий, а не разобрать до последнего винтика все глубок\n",
            "\t\t2.  еще и в формате видео.)НавигаторT9: сеанс языковой магии с разоблачениемОткуда \u001b[92mнейросети\u001b[0m берут вероятности слов?Парадокс Барака, или зачем языковым моделям уметь в твор\n",
            "\t\t3. идется погрузиться в базовые принципы работы самых простейших нейросеток.Откуда \u001b[92mнейросети\u001b[0m берут вероятности слов?Давайте начнем с еще более простого вопроса: а как вообщ\n",
            "\t\t4.  же ChatGPT бодро отвечает целыми портянками текста – то не ломайте зря голову. \u001b[92mЯзыковые модели\u001b[0m без всякого труда генерируют длинные тексты, но делают они это по принципу «сло\n",
            "\t\t5.  голову. Языковые модели без всякого труда генерируют длинные тексты, но делают \u001b[92mони\u001b[0m это по принципу «слово за словом». По сути, после генерации каждого нового слов\n",
            "\t\t6. о по принципу «слово за словом». По сути, после генерации каждого нового слова, \u001b[92mмодель\u001b[0m просто заново прогоняет через себя весь предыдущий текст вместе с только что на\n",
            "\t\t7. ути, после генерации каждого нового слова, модель просто заново прогоняет через \u001b[92mсебя\u001b[0m весь предыдущий текст вместе с только что написанным дополнением – и выплевывае\n",
            "\t\t8. ия» разных слов примерно соответствовали тем вероятностям, которые подсказывают \u001b[92mмодели\u001b[0m зашитые внутрь нее уравнения (выведенные при обучении модели на огромном массив\n",
            "\t\t9. но соответствовали тем вероятностям, которые подсказывают модели зашитые внутрь \u001b[92mнее\u001b[0m уравнения (выведенные при обучении модели на огромном массиве разных текстов).П\n",
            "\t\t10. торые подсказывают модели зашитые внутрь нее уравнения (выведенные при обучении \u001b[92mмодели\u001b[0m на огромном массиве разных текстов).Получается, что одна и та же модель даже на\n",
            "\t\t11. етевой обработке текстов (в том числе их генерации). Теперь модель не забывает: \u001b[92mона\u001b[0m переиспользует то, что уже было написано ранее, лучше держит контекст, а самое \n",
            "\t\t12. еньких милых чихуабелей от маффинов с черничкой, то вы не можете просто сказать \u001b[92mей\u001b[0m «вот ссылка на гигантский архив со 100 500 фотографий пёсов и хлебобулочных изд\n",
            "\t\t13. 500 фотографий пёсов и хлебобулочных изделий — разбирайся!». Нет, чтобы обучить \u001b[92mмодель\u001b[0m, вам нужно обязательно сначала разметить тренировочный набор данных — то есть, \n",
            "\t\t14.  видите, при переходе от моделей с 10 миллиардами параметров к 100 миллиардам — \u001b[92mнейросети\u001b[0m внезапно и резко начинают «уметь» в математику.По горизонтали – количество пара\n",
            "\t\t15. ь тексты словами, а она при этом как‑то смогла сама разобраться в том, что если \u001b[92mей\u001b[0m печатают «378 + 789 =», то на это надо отвечать именно «1167», а не каким‑то др\n",
            "\t\t16.  исходный вопрос. Отдельно отмечу: мы никак не дообучали модель после того, как \u001b[92mона\u001b[0m ответила неправильно — это абсолютно та же самая модель. Мы просто дописали пят\n",
            "\n",
            "\n",
            "Сущность 6\n",
            "\t\t[[4061, 4066], [4068, 4075]]\n",
            "\t\t1. учитывать контекст (предыдущее слово), ставить пунктуацию и предлагать на выбор \u001b[92mслова\u001b[0m, которые могли бы идти следующими. Вот именно об аналогии с такой «продвинутой»\n",
            "\t\t2. ть контекст (предыдущее слово), ставить пунктуацию и предлагать на выбор слова, \u001b[92mкоторые\u001b[0m могли бы идти следующими. Вот именно об аналогии с такой «продвинутой» версией \n",
            "\n",
            "\n",
            "Сущность 7\n",
            "\t\t[[4719, 4721], [4795, 4798], [4883, 4886], [4947, 4949], [4988, 4992], [5004, 5005], [5062, 5065], [5122, 5123], [5971, 5974], [9577, 9579], [9674, 9676], [16650, 16653], [16672, 16674], [18853, 18855], [19289, 19308], [19422, 19424], [44061, 44067], [44220, 44223], [44913, 44915], [44957, 44960], [45227, 45232]]\n",
            "\t\t1. оятностями возникновения тех или иных слов для продолжения. Ведь, скорее всего, \u001b[92mвы\u001b[0m были бы недовольны, если бы автозаполнение в телефоне просто подкидывало вам аб\n",
            "\t\t2. го, вы были бы недовольны, если бы автозаполнение в телефоне просто подкидывало \u001b[92mвам\u001b[0m абсолютно случайные слова с одинаковой вероятностью.Представим для наглядности,\n",
            "\t\t3. лютно случайные слова с одинаковой вероятностью.Представим для наглядности, что \u001b[92mвам\u001b[0m прилетает сообщение от приятеля: «Чё, го седня куда нить?». Вы начинаете печата\n",
            "\t\t4. аглядности, что вам прилетает сообщение от приятеля: «Чё, го седня куда нить?». \u001b[92mВы\u001b[0m начинаете печатать в ответ: «Да не, у меня уже дела(( я иду в...», и вот тут по\n",
            "\t\t5. т приятеля: «Чё, го седня куда нить?». Вы начинаете печатать в ответ: «Да не, у \u001b[92mменя\u001b[0m уже дела(( я иду в...», и вот тут подключается Т9. Если он предложит вам законч\n",
            "\t\t6.  го седня куда нить?». Вы начинаете печатать в ответ: «Да не, у меня уже дела(( \u001b[92mя\u001b[0m иду в...», и вот тут подключается Т9. Если он предложит вам закончить предложен\n",
            "\t\t7. не, у меня уже дела(( я иду в...», и вот тут подключается Т9. Если он предложит \u001b[92mвам\u001b[0m закончить предложение полностью рандомным словом, типа «я иду в капибару» — то \n",
            "\t\t8. . Если он предложит вам закончить предложение полностью рандомным словом, типа «\u001b[92mя\u001b[0m иду в капибару» — то для такой белиберды, если честно, никакая хитрая языковая \n",
            "\t\t9. положим, мы хотим научить компьютер предсказывать вес человека в зависимости от \u001b[92mего\u001b[0m роста — как подойти к этой задаче?Здравый смысл подсказывает, что надо сначала \n",
            "\t\t10. и оцените вероятность, что оно там действительно окажется.Ваш ход, маэстро!Если \u001b[92mвы\u001b[0m сейчас сказали, что следующим словом должно идти «Обама» с вероятностью 100%, т\n",
            "\t\t11. , что следующим словом должно идти «Обама» с вероятностью 100%, то поздравляю — \u001b[92mвы\u001b[0m ошиблись! И дело тут не в том, что существует какой‑то другой мифический Барак:\n",
            "\t\t12.  с самыми разными книгами, без какой‑либо инструкции, что там и в каком порядке \u001b[92mему\u001b[0m нужно выучить — а он бы сам в процессе чтения кумекал для себя какие‑то хитрые \n",
            "\t\t13. ами, без какой‑либо инструкции, что там и в каком порядке ему нужно выучить — а \u001b[92mон\u001b[0m бы сам в процессе чтения кумекал для себя какие‑то хитрые выводы!Если подумать,\n",
            "\t\t14. T-2... С учетом того, что люди в среднем читают по странице в минуту, даже если \u001b[92mвы\u001b[0m будете поглощать текст 24 часа в сутки без перерыва на еду и сон — вам потребуе\n",
            "\t\t15. нных для получения крутой языковой модели недостаточно: ведь даже если посадить \u001b[92mпятилетнего ребенка\u001b[0m перечитывать всё собрание сочинений Шекспира вместе с лекциями по квантовой физ\n",
            "\t\t16. ий Шекспира вместе с лекциями по квантовой физике Фейнмана впридачу, то вряд ли \u001b[92mон\u001b[0m от этого станет сильно умнее. Так и тут: модель еще и сама по себе должна быть \n",
            "\t\t17. облему», в котором нюансы машинного обучения разбираются еще более подробно.Для \u001b[92mвашего\u001b[0m удобства мы сделали небольшой сводный постер, который наглядно иллюстрирует осн\n",
            "\t\t18. ует основные вехи истории эволюции языковых моделей. Если какой‑то этап кажется \u001b[92mвам\u001b[0m не очень понятным — можете просто вернуться чуть назад к соответствующему разде\n",
            "\t\t19. наш взгляд — супер‑захватывающие!) темы мы разберем в следующем материале. Если \u001b[92mвы\u001b[0m не хотите его пропустить — то приглашаем вас подписаться на ТГ‑каналы авторов: \n",
            "\t\t20. азберем в следующем материале. Если вы не хотите его пропустить — то приглашаем \u001b[92mвас\u001b[0m подписаться на ТГ‑каналы авторов: Сиолошная Игоря Котенкова (для тех, кто хочет\n",
            "\t\t21.  предпочитает чуть попроще). Всё, всем спасибо за внимание — с нетерпением ждем \u001b[92mваших\u001b[0m комментариев!UPD: Следующую статью из серии с разбором GPT-4 можно прочитать зд\n",
            "\n",
            "\n",
            "Сущность 8\n",
            "\t\t[[5040, 5042], [5049, 5051], [13341, 13353], [13512, 13515], [13784, 13786], [14151, 14163], [14178, 14181], [14203, 14205], [14861, 14873], [14884, 14887], [21332, 21335]]\n",
            "\t\t1. печатать в ответ: «Да не, у меня уже дела(( я иду в...», и вот тут подключается \u001b[92mТ9\u001b[0m. Если он предложит вам закончить предложение полностью рандомным словом, типа «\n",
            "\t\t2. в ответ: «Да не, у меня уже дела(( я иду в...», и вот тут подключается Т9. Если \u001b[92mон\u001b[0m предложит вам закончить предложение полностью рандомным словом, типа «я иду в к\n",
            "\t\t3. дустрии, прошедшие с тех пор шесть лет — это целая вечность).Именно изобретение \u001b[92mТрансформера\u001b[0m оказалось столь значимым, что вообще все области искусственного интеллекта (ИИ)\n",
            "\t\t4. ) — от текстовых переводов и до обработки изображений, звука или видео — начали \u001b[92mего\u001b[0m активно адаптировать и применять. Индустрия ИИ буквально получила мощную встряс\n",
            "\t\t5. рмер — это универсальный вычислительный механизм, который очень просто описать: \u001b[92mон\u001b[0m принимает на вход один набор последовательностей (данных) и выдает на выходе то\n",
            "\t\t6. о с помощью Трансформера можно решать практически любые задачи.Но главная фишка \u001b[92mТрансформера\u001b[0m заключается в его удобстве и гибкости: он состоит из простых модулей‑блоков, ко\n",
            "\t\t7. жно решать практически любые задачи.Но главная фишка Трансформера заключается в \u001b[92mего\u001b[0m удобстве и гибкости: он состоит из простых модулей‑блоков, которые очень легко \n",
            "\t\t8. бые задачи.Но главная фишка Трансформера заключается в его удобстве и гибкости: \u001b[92mон\u001b[0m состоит из простых модулей‑блоков, которые очень легко масштабировать. Если ста\n",
            "\t\t9. (прямо как люди с утра, до того как они «бахнув кофейку»). А вот могучие лапища \u001b[92mТрансформера\u001b[0m позволяют ему смотреть на ВСЁ одновременно — и это приводит к гораздо более впе\n",
            "\t\t10.  до того как они «бахнув кофейку»). А вот могучие лапища Трансформера позволяют \u001b[92mему\u001b[0m смотреть на ВСЁ одновременно — и это приводит к гораздо более впечатляющим резу\n",
            "\t\t11. ким же лицом лицаЧем более сложное уравнение зашито внутрь модели (чем больше в \u001b[92mнем\u001b[0m параметров) — тем лучше модель предсказывает вероятности, и тем более правдопод\n",
            "\n",
            "\n",
            "Сущность 9\n",
            "\t\t[[7154, 7158], [7259, 7262], [9287, 9289], [10211, 10215], [21938, 21940], [43733, 43735]]\n",
            "\t\t1. вала ключевую зависимость в нашем наборе данных (можете для интереса подставить \u001b[92mсвой\u001b[0m рост в сантиметрах вместо  в уравнение на картинке и проверить, насколько точно\n",
            "\t\t2. место  в уравнение на картинке и проверить, насколько точно наша модель угадает \u001b[92mваш\u001b[0m вес).Вы тут уже наверняка хотите воскликнуть: «Окей, с ростом/весом и так интуи\n",
            "\t\t3. лово для продолжения? Давайте разберем на примере небольшой игры.Правила такие: \u001b[92mвы\u001b[0m притворяетесь языковой моделью, а я вам предлагаю продолжить текст «44-й презид\n",
            "\t\t4.  (после которого последует Обама уже с вероятностью, близкой к 100%).И тут мы с \u001b[92mвами\u001b[0m подходим к очень интересному аспекту языковых моделей: оказывается, им не чужда\n",
            "\t\t5. омните: предыдущие модели T9/GPT-1 худо‑бедно могли подсказать — собираетесь ли \u001b[92mвы\u001b[0m пойти в банк или в аптеку, а также угадать, что шоссейная Саша сосет сушки, а н\n",
            "\t\t6. ась не очень короткой — но надеемся, что вам было интересно, и просле прочтения \u001b[92mвы\u001b[0m чуть лучше стали понимать, что же конкретно творится под капотом этих самых ней\n",
            "\n",
            "\n",
            "Сущность 10\n",
            "\t\t[[8736, 8769], [8817, 8821]]\n",
            "\t\t1. слова, модель просто заново прогоняет через себя весь предыдущий текст вместе с \u001b[92mтолько что написанным дополнением\u001b[0m – и выплевывает последующее слово уже с учетом него. В результате получается св\n",
            "\t\t2. олько что написанным дополнением – и выплевывает последующее слово уже с учетом \u001b[92mнего\u001b[0m. В результате получается связный текст.Парадокс Барака, или зачем языковым моде\n",
            "\n",
            "\n",
            "Сущность 11\n",
            "\t\t[[8888, 8904], [8977, 8992], [10253, 10269], [10284, 10286], [10363, 10375], [11070, 11072], [12176, 12183], [12785, 12792], [16371, 16373], [16791, 16806], [34395, 34411], [34446, 34449], [35015, 35030], [35080, 35082]]\n",
            "\t\t1. с учетом него. В результате получается связный текст.Парадокс Барака, или зачем \u001b[92mязыковым моделям\u001b[0m уметь в творчествоНа самом деле, в наших уравнениях в качестве «игрека» языковы\n",
            "\t\t2. моделям уметь в творчествоНа самом деле, в наших уравнениях в качестве «игрека» \u001b[92mязыковые модели\u001b[0m пытаются предсказать не столько конкретное следующее слово, сколько вероятности\n",
            "\t\t3. оятностью, близкой к 100%).И тут мы с вами подходим к очень интересному аспекту \u001b[92mязыковых моделей\u001b[0m: оказывается, им не чужда творческая жилка! По сути, при генерации каждого след\n",
            "\t\t4. т мы с вами подходим к очень интересному аспекту языковых моделей: оказывается, \u001b[92mим\u001b[0m не чужда творческая жилка! По сути, при генерации каждого следующего слова, так\n",
            "\t\t5.  им не чужда творческая жилка! По сути, при генерации каждого следующего слова, \u001b[92mтакие модели\u001b[0m выбирают его «случайным» образом, как бы кидая кубик. Но не абы как — а так, чт\n",
            "\t\t6. е такие модели почему‑то работают хуже; а вот здоровый элемент случайности идет \u001b[92mим\u001b[0m строго на пользу (повышает вариативность и, в итоге, качество ответов).Учитывая\n",
            "\t\t7.  — тем лучше она способна генерировать ответы, которые мы хотим от нее услышать.\u001b[92mChatGPT\u001b[0m показывает мастер-класс по вариативности: всегда приятно перетереть с понимающи\n",
            "\t\t8. дить от всяких дремучих T9 к более современным моделям: наделавший столько шума \u001b[92mChatGPT\u001b[0m является наиболее свежим представителем семейства моделей GPT. Но чтобы понять,\n",
            "\t\t9. нь сложности – «Бог»А знаете, чем прекрасно обучение языковых моделей? Тем, что \u001b[92mим\u001b[0m можно «скармливать» совершенно любые текстовые данные, и эти самые данные забла\n",
            "\t\t10.  себя какие‑то хитрые выводы!Если подумать, то это логично: мы же хотим научить \u001b[92mязыковую модель\u001b[0m предсказывать следующее слово на основе информации о словах, которые идут перед\n",
            "\t\t11. structGPT, или как научить робота не зиговатьНа самом деле, увеличение размеров \u001b[92mязыковых моделей\u001b[0m само по себе еще не означает, что они будут отвечать на запросы именно так, как\n",
            "\t\t12. ом деле, увеличение размеров языковых моделей само по себе еще не означает, что \u001b[92mони\u001b[0m будут отвечать на запросы именно так, как хочет их пользователь. Ведь часто мы,\n",
            "\t\t13. о выравнены между собой.Нет, ну технически, конечно, тут не придерешься...А вот \u001b[92mязыковые модели\u001b[0m, если честно, не очень похожи на людей — поэтому им часто приходится подсказыва\n",
            "\t\t14. решься...А вот языковые модели, если честно, не очень похожи на людей — поэтому \u001b[92mим\u001b[0m часто приходится подсказывать и разжевывать те вещи, которые людям кажутся очев\n",
            "\n",
            "\n",
            "Сущность 12\n",
            "\t\t[[9456, 9463], [9524, 9527]]\n",
            "\t\t1.  (и первый афроамериканец на этой должности) — это Барак...». Подставьте слово, \u001b[92mкоторое\u001b[0m должно стоять вместо многоточия, и оцените вероятность, что оно там действитель\n",
            "\t\t2. вьте слово, которое должно стоять вместо многоточия, и оцените вероятность, что \u001b[92mоно\u001b[0m там действительно окажется.Ваш ход, маэстро!Если вы сейчас сказали, что следующ\n",
            "\n",
            "\n",
            "Сущность 13\n",
            "\t\t[[9630, 9635], [10158, 10163]]\n",
            "\t\t1. ется.Ваш ход, маэстро!Если вы сейчас сказали, что следующим словом должно идти «\u001b[92mОбама\u001b[0m» с вероятностью 100%, то поздравляю — вы ошиблись! И дело тут не в том, что сущ\n",
            "\t\t2. 10% выделить на случай продолжения текста «Хуссейном» (после которого последует \u001b[92mОбама\u001b[0m уже с вероятностью, близкой к 100%).И тут мы с вами подходим к очень интересном\n",
            "\n",
            "\n",
            "Сущность 14\n",
            "\t\t[[9793, 9803], [9846, 9849]]\n",
            "\t\t1. уществует какой‑то другой мифический Барак: просто в официальных документах имя \u001b[92mпрезидента\u001b[0m часто пишется в полной форме, с указанием его второго имени (middle name) — Хус\n",
            "\t\t2. официальных документах имя президента часто пишется в полной форме, с указанием \u001b[92mего\u001b[0m второго имени (middle name) — Хуссейн. Так что правильно натренированная языков\n",
            "\n",
            "\n",
            "Сущность 15\n",
            "\t\t[[9923, 9938], [11949, 11963], [11976, 11982], [12109, 12112], [12163, 12166], [36217, 36219]]\n",
            "\t\t1. ем его второго имени (middle name) — Хуссейн. Так что правильно натренированная \u001b[92mязыковая модель\u001b[0m должна, по‑хорошему, предсказать, что в нашем предложении «Обама» будет следующ\n",
            "\t\t2. всем разным.Всю эту вариативность описательности языка и должна в себя вместить \u001b[92mхорошая модель\u001b[0m. Чем точнее модель оценивает вероятности слов в зависимости от нюансов контекст\n",
            "\t\t3. вность описательности языка и должна в себя вместить хорошая модель. Чем точнее \u001b[92mмодель\u001b[0m оценивает вероятности слов в зависимости от нюансов контекста (предшествующей ч\n",
            "\t\t4. ансов контекста (предшествующей части текста, описывающей ситуацию) — тем лучше \u001b[92mона\u001b[0m способна генерировать ответы, которые мы хотим от нее услышать.ChatGPT показыва\n",
            "\t\t5. щей ситуацию) — тем лучше она способна генерировать ответы, которые мы хотим от \u001b[92mнее\u001b[0m услышать.ChatGPT показывает мастер-класс по вариативности: всегда приятно перет\n",
            "\t\t6.  нетоксичные. Иначе саму модель быстренько закэнселят (с этим сейчас строго), а \u001b[92mее\u001b[0m создателям предъявят судебные иски на много миллионов долларов за оскорбление д\n",
            "\n",
            "\n",
            "Сущность 16\n",
            "\t\t[[10337, 10361], [10385, 10388], [11450, 11453], [15237, 15239]]\n",
            "\t\t1. овых моделей: оказывается, им не чужда творческая жилка! По сути, при генерации \u001b[92mкаждого следующего слова\u001b[0m, такие модели выбирают его «случайным» образом, как бы кидая кубик. Но не абы к\n",
            "\t\t2. я жилка! По сути, при генерации каждого следующего слова, такие модели выбирают \u001b[92mего\u001b[0m «случайным» образом, как бы кидая кубик. Но не абы как — а так, чтобы вероятнос\n",
            "\t\t3. и наборами правил и исключений. Слова в предложениях не появляются из ниоткуда, \u001b[92mони\u001b[0m связаны друг с другом. Эти связи неплохо выучиваются человеком «в автоматическо\n",
            "\t\t4. енно это позволило сделать прорыв в нейросетевой обработке текстов (в том числе \u001b[92mих\u001b[0m генерации). Теперь модель не забывает: она переиспользует то, что уже было напи\n",
            "\n",
            "\n",
            "Сущность 17\n",
            "\t\t[[12135, 12141], [12143, 12150], [25333, 25340], [39585, 39588]]\n",
            "\t\t1. ующей части текста, описывающей ситуацию) — тем лучше она способна генерировать \u001b[92mответы\u001b[0m, которые мы хотим от нее услышать.ChatGPT показывает мастер-класс по вариативно\n",
            "\t\t2. сти текста, описывающей ситуацию) — тем лучше она способна генерировать ответы, \u001b[92mкоторые\u001b[0m мы хотим от нее услышать.ChatGPT показывает мастер-класс по вариативности: всег\n",
            "\t\t3. ачинает поражать всех своими успехами в решении совершенно незнакомых ей задач, \u001b[92mкоторые\u001b[0m она раньше никогда не встречала и специально их не изучала.Краткое резюме: GPT-\n",
            "\t\t4. не стала – но зато научилась подгонять свои ответы таким образом, чтобы люди от \u001b[92mних\u001b[0m дичайше кайфовали.Ноябрь 2022: ChatGPT, или маленькие секреты большого хайпаCha\n",
            "\n",
            "\n",
            "Сущность 18\n",
            "\t\t[[12651, 12656], [12999, 13002], [17203, 17227], [17626, 17631], [18771, 18776], [21360, 21366], [21440, 21442], [22722, 22732], [23929, 23934], [24405, 24414], [24433, 24435], [24654, 24657], [25218, 25227], [25275, 25281], [25323, 25325], [25341, 25344], [25416, 25421], [25443, 25446], [25460, 25464], [25625, 25631], [26676, 26681], [26727, 26730], [26820, 26831], [26896, 26898], [26952, 26966], [27159, 27166], [27393, 27399], [27535, 27538], [27617, 27624], [27844, 27849], [28196, 28201], [28222, 28226], [28826, 28829], [29390, 29396], [29696, 29699], [29975, 29984], [30001, 30003], [30327, 30330], [30349, 30353], [30435, 30441], [30481, 30484], [30636, 30642], [30655, 30657], [30682, 30684], [30931, 30937], [31010, 31013], [31085, 31091], [31708, 31714], [33061, 33067], [34010, 34015], [34176, 34182], [35770, 35775], [37953, 37960], [38084, 38094], [38172, 38174], [38344, 38359], [38653, 38659], [39090, 39096], [39216, 39223], [39544, 39548], [39732, 39737], [39962, 39965], [40067, 40070], [40171, 40178], [41583, 41590], [42336, 42343], [42961, 42967], [43012, 43033]]\n",
            "\t\t1. ать следующее слово в зависимости от поданного «на вход» исходного текста.2018: \u001b[92mGPT-1\u001b[0m трансформирует языковые моделиДавайте уже переходить от всяких дремучих T9 к бо\n",
            "\t\t2. ности радовать людей своими ответами, нам придется сначала вернуться к истокам. \u001b[92mGPT\u001b[0m расшифровывается как Generative Pre‑trained Transformer, или «трансформер, обуч\n",
            "\t\t3. следующее за ними слово».А теперь давайте еще вспомним, что обкатанная на GPT-1 \u001b[92mтехнология Трансформеров\u001b[0m оказалась на редкость удачной в плане масштабирования: она умеет работать с бол\n",
            "\t\t4. я пилить здоровенные языковые модели!»В общем, было решено радикально прокачать \u001b[92mGPT-2\u001b[0m по двум ключевым направлениям: набор тренировочных данных (датасет) и размер мо\n",
            "\t\t5. о 5,5 мегабайт. Так вот: это в 7300 раз меньше, чем объем тренировочной выборки \u001b[92mGPT-2\u001b[0m... С учетом того, что люди в среднем читают по странице в минуту, даже если вы \n",
            "\t\t6. ложное уравнение зашито внутрь модели (чем больше в нем параметров) — тем лучше \u001b[92mмодель\u001b[0m предсказывает вероятности, и тем более правдоподобным будет генерируемый ей тек\n",
            "\t\t7. модель предсказывает вероятности, и тем более правдоподобным будет генерируемый \u001b[92mей\u001b[0m текст. И у этой самой большой на тот момент модели GPT-2 тексты внезапно стали \n",
            "\t\t8. ея не является оригинальной», – так один из кожаных мешков в жюри оценил работу \u001b[92mнейросетки\u001b[0m GPT-2.Переход количества в качество (почти по Марксу)Вообще, вот эта идея о том\n",
            "\t\t9.  примере вытекает из контекста и ее, извините, кровожадных действий.Способна ли \u001b[92mGPT-2\u001b[0m действительно понять этот мем и оценить его абсурдную красоту? Сейчас узнаем...\n",
            "\t\t10.  большую базу таких задачек (на пару тысяч примеров) с ответами, прогнать через \u001b[92mнейросеть\u001b[0m — и натренировать ее на поиск правильного ответа». И со старыми моделями (с мен\n",
            "\t\t11. (на пару тысяч примеров) с ответами, прогнать через нейросеть — и натренировать \u001b[92mее\u001b[0m на поиск правильного ответа». И со старыми моделями (с меньшим числом параметро\n",
            "\t\t12. о до примерно 60% успеха. А вот GPT-2 никто специально таким трюкам не учил; но \u001b[92mона\u001b[0m взяла, и сама неожиданно и уверенно превзошла своих «специализированных» предше\n",
            "\t\t13. а модели еще в два раза до 700 млн параметров — происходит качественный скачок, \u001b[92mнейросеть\u001b[0m внезапно «прозревает» и начинает поражать всех своими успехами в решении соверш\n",
            "\t\t14. т качественный скачок, нейросеть внезапно «прозревает» и начинает поражать всех \u001b[92mсвоими\u001b[0m успехами в решении совершенно незнакомых ей задач, которые она раньше никогда н\n",
            "\t\t15. евает» и начинает поражать всех своими успехами в решении совершенно незнакомых \u001b[92mей\u001b[0m задач, которые она раньше никогда не встречала и специально их не изучала.Кратк\n",
            "\t\t16. поражать всех своими успехами в решении совершенно незнакомых ей задач, которые \u001b[92mона\u001b[0m раньше никогда не встречала и специально их не изучала.Краткое резюме: GPT-2 вы\n",
            "\t\t17. орые она раньше никогда не встречала и специально их не изучала.Краткое резюме: \u001b[92mGPT-2\u001b[0m вышла в 2019 году, и она превосходила свою предшественницу и по объему трениров\n",
            "\t\t18. встречала и специально их не изучала.Краткое резюме: GPT-2 вышла в 2019 году, и \u001b[92mона\u001b[0m превосходила свою предшественницу и по объему тренировочных текстовых данных, и\n",
            "\t\t19. ально их не изучала.Краткое резюме: GPT-2 вышла в 2019 году, и она превосходила \u001b[92mсвою\u001b[0m предшественницу и по объему тренировочных текстовых данных, и по размеру самой \n",
            "\t\t20. одели (числу параметров) в 10 раз. Такой количественный рост привел к тому, что \u001b[92mмодель\u001b[0m неожиданно самообучилась качественно новым навыкам: от сочинения длинных эссе с\n",
            "\t\t21. толиев Вассерманов, чтобы они читали буквально нон‑стоп по 50 лет подряд каждый.\u001b[92mGPT-3\u001b[0m может и быть умнее Онотолея, но осмелится ли она сказать ему это в лицо?..  Сра\n",
            "\t\t22. стоп по 50 лет подряд каждый.GPT-3 может и быть умнее Онотолея, но осмелится ли \u001b[92mона\u001b[0m сказать ему это в лицо?..  Сразу бросается в глаза интересный нюанс: в отличие \n",
            "\t\t23. му это в лицо?..  Сразу бросается в глаза интересный нюанс: в отличие от GPT-2, \u001b[92mсама модель\u001b[0m теперь имеет размер больше (700 Гб), чем весь массив текста для ее обучения (42\n",
            "\t\t24. -2, сама модель теперь имеет размер больше (700 Гб), чем весь массив текста для \u001b[92mее\u001b[0m обучения (420 Гб). Получается как будто бы парадокс: наш «нейромозг» в данном с\n",
            "\t\t25.  весь массив текста для ее обучения (420 Гб). Получается как будто бы парадокс: \u001b[92mнаш «нейромозг\u001b[0m» в данном случае в процессе изучения сырых данных генерирует информацию о разны\n",
            "\t\t26. которая превышает по объему исходную информацию.Такое обобщение («осмысление»?) \u001b[92mмоделью\u001b[0m позволяет еще лучше прежнего делать экстраполяцию — то есть, показывать хорошие\n",
            "\t\t27. тречались очень редко или не встречались вовсе. Теперь уже точно не нужно учить \u001b[92mмодель\u001b[0m решать конкретную задачу — вместо этого достаточно описать словами проблему, да\n",
            "\t\t28. ать словами проблему, дать несколько примеров, и GPT-3 схватит на лету, чего от \u001b[92mнее\u001b[0m хотят!И тут в очередной раз оказалось, что «универсальный Халк» в виде GPT-3 (к\n",
            "\t\t29. е хотят!И тут в очередной раз оказалось, что «универсальный Халк» в виде GPT-3 (\u001b[92mкоторую\u001b[0m никто никаким «узким» задачам не обучал) с легкостью кладет на лопатки многие с\n",
            "\t\t30. перевод текстов с французского или немецкого на английский сразу начал даваться \u001b[92mGPT-3\u001b[0m легче и лучше, чем любым другим специально заточенным под это нейросетям. Как?!\n",
            "\t\t31. утся способности к переводу?Но это еще цветочки — еще более удивительно то, что \u001b[92mGPT-3\u001b[0m смогла научить сама себя... математике! На графике ниже (источник: оригинальная\n",
            "\t\t32. у?Но это еще цветочки — еще более удивительно то, что GPT-3 смогла научить сама \u001b[92mсебя\u001b[0m... математике! На графике ниже (источник: оригинальная статья) показана точност\n",
            "\t\t33. имеровЕще раз, вдумайтесь: языковую модель обучали продолжать тексты словами, а \u001b[92mона\u001b[0m при этом как‑то смогла сама разобраться в том, что если ей печатают «378 + 789 \n",
            "\t\t34. будто бы не меняется ничего, а затем — р‑раз! Происходит качественный скачок, и \u001b[92mGPT-3 \u001b[0mначинает «понимать», как решать ту или иную задачу. Как, что, почему это работае\n",
            "\t\t35. е как раз наглядно показывает, как с увеличением количества параметров модели в \u001b[92mней\u001b[0m «прорастают» новые способности, которые никто туда специально не закладывал:Кст\n",
            "\t\t36.  прямо как человек. Заставляет задуматься, правда: а какие новые скиллы обретет \u001b[92mнейросеть\u001b[0m, если увеличить ее объем еще раз в сто? Ну там, до десятков триллионов параметр\n",
            "\t\t37. ляет задуматься, правда: а какие новые скиллы обретет нейросеть, если увеличить \u001b[92mее\u001b[0m объем еще раз в сто? Ну там, до десятков триллионов параметров, например...Пром\n",
            "\t\t38.  сути, процесс выглядит так: мы подаем на вход модели некий текст с запросом, а \u001b[92mона\u001b[0m к нему дописывает свое продолжение. Если это продолжение (генерация) совпадает \n",
            "\t\t39. т так: мы подаем на вход модели некий текст с запросом, а она к нему дописывает \u001b[92mсвое\u001b[0m продолжение. Если это продолжение (генерация) совпадает с нашими ожиданиями — т\n",
            "\t\t40. родолжение. Если это продолжение (генерация) совпадает с нашими ожиданиями — то \u001b[92mмодель\u001b[0m, получается, решила поставленную перед ней задачу.Тот текст, что мы подаем на в\n",
            "\t\t41. овпадает с нашими ожиданиями — то модель, получается, решила поставленную перед \u001b[92mней\u001b[0m задачу.Тот текст, что мы подаем на вход, называется prompt (промпт, или «запрос\n",
            "\t\t42.  «запрос/затравка» по‑русски). Чем точнее он описывает, что мы хотим, тем лучше \u001b[92mмодель\u001b[0m поймет, что ей нужно делать. А если мы ей еще и примеров отсыпем с десяток — то\n",
            "\t\t43. по‑русски). Чем точнее он описывает, что мы хотим, тем лучше модель поймет, что \u001b[92mей\u001b[0m нужно делать. А если мы ей еще и примеров отсыпем с десяток — то вообще шик! Пр\n",
            "\t\t44. писывает, что мы хотим, тем лучше модель поймет, что ей нужно делать. А если мы \u001b[92mей\u001b[0m еще и примеров отсыпем с десяток — то вообще шик! Пример детального запроса для\n",
            "\t\t45. примера желаемого поведения, после чего пишется новое слово или предложение – а \u001b[92mмодель\u001b[0m следом сгенерирует корректный перевод (ну, это самый простейший пример, она мож\n",
            "\t\t46.  модель следом сгенерирует корректный перевод (ну, это самый простейший пример, \u001b[92mона\u001b[0m может и посложнее, конечно)Без описания цели и без примеров в промпте, модель т\n",
            "\t\t47. мер, она может и посложнее, конечно)Без описания цели и без примеров в промпте, \u001b[92mмодель\u001b[0m тоже обычно понимает проблему, но предлагает не такие хорошие решения (с точки \n",
            "\t\t48. авление всего одной фразы перед ответом на вопрос существенно улучшает качество \u001b[92mмодели\u001b[0m. И эта магическая фраза — «пожалуйста» «let»s think step by step» (давай подума\n",
            "\t\t49. я корректным ответом на исходный вопрос. Отдельно отмечу: мы никак не дообучали \u001b[92mмодель\u001b[0m после того, как она ответила неправильно — это абсолютно та же самая модель. Мы\n",
            "\t\t50. лось всего ничего.Краткое резюме: GPT-3 образца 2020 года была в 100 раз больше \u001b[92mсвоей\u001b[0m предшественницы по количеству параметров, и в 10 раз – по объему тренировочных \n",
            "\t\t51. екстовых данных. И снова рост количества привел к внезапному скачку в качестве: \u001b[92mмодель\u001b[0m научилась переводу с других языков, арифметике, базовому программированию, поша\n",
            "\t\t52. человек.Отчасти отсутствие таких способностей «по умолчанию» связано с тем, что \u001b[92mGPT-3\u001b[0m обучена просто предсказывать следующее слово в гигантском наборе текстов из Инт\n",
            "\t\t53. ».Короче, InstructGPT (также известная как GPT-3.5) – это как раз и есть GPT-3, \u001b[92mкоторую\u001b[0m дообучили с помощью фидбека на максимизацию оценки живого человека. Буквально –\n",
            "\t\t54.  оценки живого человека. Буквально – куча людей сидели и оценивали кучу ответов \u001b[92mнейросетки\u001b[0m на предмет того, насколько они соответствуют их ожиданиям с учетом выданного ей\n",
            "\t\t55. ки на предмет того, насколько они соответствуют их ожиданиям с учетом выданного \u001b[92mей\u001b[0m запроса. Ну, на самом деле, всё было не совсем так просто (инструкции для члено\n",
            "\t\t56. мясного жюри» занимали 26 страниц убористым почерком) – но суть именно такая. А \u001b[92mязыковая модель\u001b[0m, получается, училась решать еще одну дополнительную задачу – «как мне поменять \n",
            "\t\t57. зи разбирается в этом материале).Причем с точки зрения общего процесса обучения \u001b[92mмодели\u001b[0m, этот финальный этап «дообучения на живых людях» занимает не более 1%. Но именн\n",
            "\t\t58. разных авторов, и так далее. Но только с помощью обратной связи от других людей \u001b[92mмодель\u001b[0m научилась пользоваться этими знаниями именно таким образом, который мы (люди) с\n",
            "\t\t59. менно таким образом, который мы (люди) считаем «правильным». В каком-то смысле, \u001b[92mGPT-3.5\u001b[0m – это модель, «воспитанная обществом».Краткое резюме: GPT-3.5 (также известная \n",
            "\t\t60. одель формально вроде как больше и умнее не стала – но зато научилась подгонять \u001b[92mсвои\u001b[0m ответы таким образом, чтобы люди от них дичайше кайфовали.Ноябрь 2022: ChatGPT,\n",
            "\t\t61. ольшого хайпаChatGPT вышла в ноябре 2022 года — примерно через 10 месяцев после \u001b[92mсвоей\u001b[0m предшественницы, InstructGPT/GPT-3.5 — и мгновенно прогремела на весь мир. Каже\n",
            "\t\t62. дъезда обсуждают только одно — что там нового сказала эта ваша «ЧатЖПТ», и кого \u001b[92mона\u001b[0m по самым свежим прогнозам вот‑вот оставит без работы.При этом с технической точ\n",
            "\t\t63. озам вот‑вот оставит без работы.При этом с технической точки зрения, кажется, у \u001b[92mнее\u001b[0m нет каких‑то особо мощных отличий от InstructGPT (к сожалению, научной статьи с\n",
            "\t\t64. ощных отличий от InstructGPT (к сожалению, научной статьи с детальным описанием \u001b[92mChatGPT\u001b[0m команда OpenAI пока так и не опубликовала — так что мы тут можем только гадать)\n",
            "\t\t65. о есть, сделать это заведомо могли только нёрды‑айтишники, а не обычные люди. А \u001b[92mChatGPT\u001b[0m усадили в привычный интерфейс «диалогового окна», прямо как в знакомых всем мес\n",
            "\t\t66.  никому не интересны, если к ним не прилагается простой и понятный интерфейс. И \u001b[92mChatGPT\u001b[0m в этом смысле совершил прорыв, выведя технологию в массы за счет обычного диало\n",
            "\t\t67. а с OpenAI сделку по инвестированию в них десятка миллиардов долларов, инженеры \u001b[92mGoogle\u001b[0m забили тревогу и сели думать, как им спасти свой поисковый сервис от конкуренци\n",
            "\t\t68. иллиардов долларов, инженеры Google забили тревогу и сели думать, как им спасти \u001b[92mсвой поисковый сервис\u001b[0m от конкуренции с нейросетью, а китайцы в срочном порядке анонсировали скорый ре\n",
            "\n",
            "\n",
            "Сущность 19\n",
            "\t\t[[13259, 13268], [13550, 13562], [31850, 31856]]\n",
            "\t\t1. вателями Google в далеком 2017 году (про «далекий» мы не оговорились: по меркам \u001b[92mиндустрии\u001b[0m, прошедшие с тех пор шесть лет — это целая вечность).Именно изобретение Трансфо\n",
            "\t\t2. тки изображений, звука или видео — начали его активно адаптировать и применять. \u001b[92mИндустрия ИИ\u001b[0m буквально получила мощную встряску: перешла от так называемой «зимы ИИ» к бурно\n",
            "\t\t3. p by step» (давай подумаем шаг за шагом). Внезапно оказалось, что это побуждает \u001b[92mмодель\u001b[0m рассуждать последовательно, делать выводы на основе собственных суждений, и при\n",
            "\n",
            "\n",
            "Сущность 20\n",
            "\t\t[[14656, 14662], [14743, 14746], [34705, 34709], [34717, 34723], [34771, 34773], [36759, 36760], [36772, 36775], [38426, 38429], [38439, 38443]]\n",
            "\t\t1. ые данные по принципу «один за другим», то есть последовательно. Поэтому, когда \u001b[92mмодель\u001b[0m работала с текстом длиной в одну страницу, то уже к середине третьего параграфа\n",
            "\t\t2. работала с текстом длиной в одну страницу, то уже к середине третьего параграфа \u001b[92mона\u001b[0m забывала, что было в самом начале (прямо как люди с утра, до того как они «бахн\n",
            "\t\t3. икации между людьми считаются сами собой разумеющимися, что ли. Например, когда \u001b[92mМаша\u001b[0m просит своего мужа: «Вась, сходи выбрось мусор» — то вряд ли ей придет в голову\n",
            "\t\t4.  людьми считаются сами собой разумеющимися, что ли. Например, когда Маша просит \u001b[92mсвоего\u001b[0m мужа: «Вась, сходи выбрось мусор» — то вряд ли ей придет в голову прибавить к э\n",
            "\t\t5. пример, когда Маша просит своего мужа: «Вась, сходи выбрось мусор» — то вряд ли \u001b[92mей\u001b[0m придет в голову прибавить к этому промпту «(только не из окна, плз!)». Ведь Вас\n",
            "\t\t6. обидность модель в пределе будет отвечать на совершенно любой промпт «извините, \u001b[92mя\u001b[0m боюсь, что мой ответ может кого‑то оскорбить в Интернете».Получается, создание \n",
            "\t\t7. ель в пределе будет отвечать на совершенно любой промпт «извините, я боюсь, что \u001b[92mмой\u001b[0m ответ может кого‑то оскорбить в Интернете».Получается, создание ИИ, выравненног\n",
            "\t\t8. ыковая модель, получается, училась решать еще одну дополнительную задачу – «как \u001b[92mмне\u001b[0m поменять свой сгенерированный ответ таким образом, чтобы он получил наибольшую \n",
            "\t\t9. , получается, училась решать еще одну дополнительную задачу – «как мне поменять \u001b[92mсвой\u001b[0m сгенерированный ответ таким образом, чтобы он получил наибольшую оценку от чело\n",
            "\n",
            "\n",
            "Сущность 21\n",
            "\t\t[[15833, 15835], [15956, 15958]]\n",
            "\t\t1. делей.2019: GPT-2, или как запихнуть в языковую модель семь тысяч ШекспировЕсли \u001b[92mвы\u001b[0m хотите научить нейросетку для распознавания изображений отличать маленьких милы\n",
            "\t\t2. ния изображений отличать маленьких милых чихуабелей от маффинов с черничкой, то \u001b[92mвы\u001b[0m не можете просто сказать ей «вот ссылка на гигантский архив со 100 500 фотограф\n",
            "\n",
            "\n",
            "Сущность 22\n",
            "\t\t[[16335, 16360], [32813, 32815]]\n",
            "\t\t1. ой.Игра «чихуабель или булка», уровень сложности – «Бог»А знаете, чем прекрасно \u001b[92mобучение языковых моделей\u001b[0m? Тем, что им можно «скармливать» совершенно любые текстовые данные, и эти самые\n",
            "\t\t2.  75 = 375 ударов.И снова текст выделенный жирным — это ответ модели. Видно, что \u001b[92mон\u001b[0m стал длиннее, решение задачи получилось прямо как у школьника — в три действия.\n",
            "\n",
            "\n",
            "Сущность 23\n",
            "\t\t[[16821, 16836], [16887, 16890]]\n",
            "\t\t1. сли подумать, то это логично: мы же хотим научить языковую модель предсказывать \u001b[92mследующее слово\u001b[0m на основе информации о словах, которые идут перед ним? Ну дак совершенно любой \n",
            "\t\t2. предсказывать следующее слово на основе информации о словах, которые идут перед \u001b[92mним\u001b[0m? Ну дак совершенно любой текст, написанный человеком когда‑либо, — это и есть у\n",
            "\n",
            "\n",
            "Сущность 24\n",
            "\t\t[[17197, 17202], [25460, 25480]]\n",
            "\t\t1. ий => следующее за ними слово».А теперь давайте еще вспомним, что обкатанная на \u001b[92mGPT-1\u001b[0m технология Трансформеров оказалась на редкость удачной в плане масштабирования:\n",
            "\t\t2. ально их не изучала.Краткое резюме: GPT-2 вышла в 2019 году, и она превосходила \u001b[92mсвою предшественницу\u001b[0m и по объему тренировочных текстовых данных, и по размеру самой модели (числу па\n",
            "\n",
            "\n",
            "Сущность 25\n",
            "\t\t[[17491, 17497], [18004, 18010], [41079, 41085]]\n",
            "\t\t1. внее своих предшественников. Вы думаете о том же, о чем и я? Ну вот и ученые из \u001b[92mOpenAI\u001b[0m в 2019 году сделали такой же вывод: «Пришло время пилить здоровенные языковые м\n",
            "\t\t2. дилось извращаться согласно их собственной степени испорченности. Вот ребята из \u001b[92mOpenAI\u001b[0m и решили поступить остроумно: они пошли на самый популярный англоязычный онлайн\n",
            "\t\t3. GPT-3.5 еще в начале 2022-го? При том, что Сэм Альтман (исполнительный директор \u001b[92mOpenAI\u001b[0m) честно признался, что исследователи сами удивились такому бурному успеху ChatG\n",
            "\n",
            "\n",
            "Сущность 26\n",
            "\t\t[[17994, 18010], [18041, 18044]]\n",
            "\t\t1. о ИИ приходилось извращаться согласно их собственной степени испорченности. Вот \u001b[92mребята из OpenAI\u001b[0m и решили поступить остроумно: они пошли на самый популярный англоязычный онлайн\n",
            "\t\t2. енной степени испорченности. Вот ребята из OpenAI и решили поступить остроумно: \u001b[92mони\u001b[0m пошли на самый популярный англоязычный онлайн‑форум Reddit и тупо выкачали все \n",
            "\n",
            "\n",
            "Сущность 27\n",
            "\t\t[[18229, 18241], [18284, 18287]]\n",
            "\t\t1. ений, имевших более трех лайков (я сейчас не шучу — научный подход, ну!). Всего \u001b[92mтаких ссылок\u001b[0m вышло порядка 8 миллионов, а скачанные из них тексты весили в совокупности 40 г\n",
            "\t\t2. чный подход, ну!). Всего таких ссылок вышло порядка 8 миллионов, а скачанные из \u001b[92mних\u001b[0m тексты весили в совокупности 40 гигабайт.Много это или мало? Давайте прикинем: \n",
            "\n",
            "\n",
            "Сущность 28\n",
            "\t\t[[18409, 18412], [18622, 18656]]\n",
            "\t\t1. Много это или мало? Давайте прикинем: собрание сочинений Уильяма Шекспира (всех \u001b[92mего\u001b[0m пьес, сонетов и стихов) состоит из 850'000 слов. В среднем на одной странице кн\n",
            "\t\t2.  2800 страниц чудесного, временами устаревшего английского текста за авторством \u001b[92mвеличайшего англоязычного писателя\u001b[0m займет в памяти компьютера примерно 5,5 мегабайт. Так вот: это в 7300 раз меньш\n",
            "\n",
            "\n",
            "Сущность 29\n",
            "\t\t[[19000, 19018], [19020, 19027]]\n",
            "\t\t1.  — вам потребуется почти 40 лет, чтобы догнать GPT-2 по эрудиции!Весь Шекспир – \u001b[92m13 увесистых томов\u001b[0m, которые занимают целую полку. Если вы прочитаете примерно вот столько книг сем\n",
            "\t\t2. очти 40 лет, чтобы догнать GPT-2 по эрудиции!Весь Шекспир – 13 увесистых томов, \u001b[92mкоторые\u001b[0m занимают целую полку. Если вы прочитаете примерно вот столько книг семь тысяч р\n",
            "\n",
            "\n",
            "Сущность 30\n",
            "\t\t[[19228, 19250], [19466, 19472], [19633, 19639], [20491, 20497], [20832, 20838], [22846, 22852], [22855, 22858], [23882, 23884], [28684, 28690], [30216, 30222], [32427, 32439], [32794, 32800], [37622, 37628]]\n",
            "\t\t1. как GPT-2 (но это не точно!)Но одного объема тренировочных данных для получения \u001b[92mкрутой языковой модели\u001b[0m недостаточно: ведь даже если посадить пятилетнего ребенка перечитывать всё собр\n",
            "\t\t2. изике Фейнмана впридачу, то вряд ли он от этого станет сильно умнее. Так и тут: \u001b[92mмодель\u001b[0m еще и сама по себе должна быть достаточно сложной и объемной, чтобы полноценно \n",
            "\t\t3. проглотить» и «переварить» такой объем информации. А как измерить эту сложность \u001b[92mмодели\u001b[0m, в чем она выражается?Почему в мире языковых моделей больше ценятся именно моде\n",
            "\t\t4. ньше, чем суммарный размер текстового массива данных, на котором мы тренировали \u001b[92mмодель\u001b[0m (помните, который мы собирали по ссылкам с Reddit, на 40 Гб); с другой — модели\n",
            "\t\t5. тры (их еще называют «веса», или «коэффициенты») получаются во время тренировки \u001b[92mмодели\u001b[0m, затем сохраняются, и больше не меняются. То есть, при использовании модели в э\n",
            "\t\t6. во (почти по Марксу)Вообще, вот эта идея о том, что по мере наращивания размера \u001b[92mмодели\u001b[0m у нее внезапно открываются качественно новые свойства (например, писать связные\n",
            "\t\t7.  по Марксу)Вообще, вот эта идея о том, что по мере наращивания размера модели у \u001b[92mнее\u001b[0m внезапно открываются качественно новые свойства (например, писать связные эссе \n",
            "\t\t8. е). Вывод о ее «голодности» в данном конкретном примере вытекает из контекста и \u001b[92mее\u001b[0m, извините, кровожадных действий.Способна ли GPT-2 действительно понять этот мем\n",
            "\t\t9. онтали – количество параметров в модели (в миллиардах), по вертикали – качество \u001b[92mмодели\u001b[0m, выраженное в проценте верно решенных математических примеровЕще раз, вдумайтес\n",
            "\t\t10. сделаем небольшое отступление в сторону и обсудим, а что это вообще означает — «\u001b[92mмодель\u001b[0m умеет решать задачи»? По сути, процесс выглядит так: мы подаем на вход модели н\n",
            "\t\t11. – сколько честно нанесенных ударов «украла» у него языковая модель?Однако та же \u001b[92mсамая модель\u001b[0m может ответить вот так:Вопрос: В среднем боксер Иван наносит 25 ударов в минуту\n",
            "\t\t12. ов Иван наносит 5 * 75 = 375 ударов.И снова текст выделенный жирным — это ответ \u001b[92mмодели\u001b[0m. Видно, что он стал длиннее, решение задачи получилось прямо как у школьника — \n",
            "\t\t13. опросов нет)...В итоге исследователи не придумали ничего лучше, чем просто дать \u001b[92mмодели\u001b[0m очень много обратной связи. В каком-то смысле, человеческие детеныши ведь именн\n",
            "\n",
            "\n",
            "Сущность 31\n",
            "\t\t[[19619, 19639], [19647, 19650]]\n",
            "\t\t1. ы полноценно «проглотить» и «переварить» такой объем информации. А как измерить \u001b[92mэту сложность модели\u001b[0m, в чем она выражается?Почему в мире языковых моделей больше ценятся именно моде\n",
            "\t\t2. «переварить» такой объем информации. А как измерить эту сложность модели, в чем \u001b[92mона\u001b[0m выражается?Почему в мире языковых моделей больше ценятся именно модели «Plus Si\n",
            "\n",
            "\n",
            "Сущность 32\n",
            "\t\t[[20438, 20463], [26340, 26342]]\n",
            "\t\t1.  он займет 6 гигабайт! С одной стороны, это сильно меньше, чем суммарный размер \u001b[92mтекстового массива данных\u001b[0m, на котором мы тренировали модель (помните, который мы собирали по ссылкам с Re\n",
            "\t\t2. айт.Набор данных для обучения GPT-3 тоже прокачали, хоть и не столь радикально: \u001b[92mон\u001b[0m увеличился примерно в 10 раз до 420 гигабайт — туда запихнули кучу книг, Википе\n",
            "\n",
            "\n",
            "Сущность 33\n",
            "\t\t[[20476, 20478], [44986, 44993]]\n",
            "\t\t1. , это сильно меньше, чем суммарный размер текстового массива данных, на котором \u001b[92mмы\u001b[0m тренировали модель (помните, который мы собирали по ссылкам с Reddit, на 40 Гб)\n",
            "\t\t2. . Если вы не хотите его пропустить — то приглашаем вас подписаться на ТГ‑каналы \u001b[92mавторов\u001b[0m: Сиолошная Игоря Котенкова (для тех, кто хочет шарить за технологии) и Rational\n",
            "\n",
            "\n",
            "Сущность 34\n",
            "\t\t[[21119, 21122], [21221, 21223]]\n",
            "\t\t1. ения (числовые коэффициенты  при иксах) при этом остаются неизменны.Думаю, если \u001b[92mвам\u001b[0m для каждого слова в разговоре пришлось бы решать по уравнению на полтора миллиа\n",
            "\t\t2. в разговоре пришлось бы решать по уравнению на полтора миллиарда параметров, то \u001b[92mвы\u001b[0m бы тоже стояли с примерно таким же лицом лицаЧем более сложное уравнение зашито\n",
            "\n",
            "\n",
            "Сущность 35\n",
            "\t\t[[22420, 22431], [22470, 22473], [30294, 30300], [32838, 32844], [39360, 39362], [42642, 42644], [43869, 43880], [44431, 44437], [44772, 44782], [45387, 45398]]\n",
            "\t\t1. соответствующего конкурса — и те не заметили никакого подвоха. Ну, окей, оценки \u001b[92mэтой работе\u001b[0m поставили не сильно высокие и в финал она не прошла — но и «что за чушь вы нам \n",
            "\t\t2. ого подвоха. Ну, окей, оценки этой работе поставили не сильно высокие и в финал \u001b[92mона\u001b[0m не прошла — но и «что за чушь вы нам отправили, постыдились бы!!» тоже никто не\n",
            "\t\t3.  «модель умеет решать задачи»? По сути, процесс выглядит так: мы подаем на вход \u001b[92mмодели\u001b[0m некий текст с запросом, а она к нему дописывает свое продолжение. Если это прод\n",
            "\t\t4. текст выделенный жирным — это ответ модели. Видно, что он стал длиннее, решение \u001b[92mзадачи\u001b[0m получилось прямо как у школьника — в три действия. Четко, последовательно — ров\n",
            "\t\t5. T-3.5 (также известная как InstructGPT) появилась в начале 2022 года, и главной \u001b[92mее\u001b[0m фишкой стало дополнительное дообучение на основе обратной связи от живых людей.\n",
            "\t\t6. рекорды по скорости привлечения новых пользователей: отметку в 1 миллион юзеров \u001b[92mон\u001b[0m достиг в первые пять дней после релиза, а за 100 миллионов перевалил всего за д\n",
            "\t\t7. под капотом этих самых нейросетей. Кстати, у Игоря Котенкова (одного из авторов \u001b[92mэтой статьи\u001b[0m) есть еще один лонгрид на Хабре под названием «ChatGPT как инструмент для поиск\n",
            "\t\t8. ть нам уточняющие вопросы в комментариях).На самом деле, в первоначальном плане \u001b[92mстатьи\u001b[0m у нас было гораздо больше пунктов: мы хотели подробнее обсудить и проблемы конт\n",
            "\t\t9.  вроде «можно ли считать, что нейросеть умеет мыслить, или всё же нет?».Если на \u001b[92mэту статью\u001b[0m будет много положительных отзывов, то все эти (на наш взгляд — супер‑захватываю\n",
            "\t\t10. ть здесь.GPT-4: Чему научилась новая нейросеть, и почему это немного жутковатоВ \u001b[92mэтой статье\u001b[0m мы разберем новые удивительные способности последней языковой модели из семейст\n",
            "\n",
            "\n",
            "Сущность 36\n",
            "\t\t[[23293, 23297], [23335, 23339], [23360, 23363]]\n",
            "\t\t1. ие текста (хоть человеком, хоть нейросетью). Например, сравните два утверждения:\u001b[92mРыба\u001b[0m заглотила приманку. Она была вкусной.Рыба заглотила приманку. Она была голодной\n",
            "\t\t2. ). Например, сравните два утверждения:Рыба заглотила приманку. Она была вкусной.\u001b[92mРыба\u001b[0m заглотила приманку. Она была голодной. К какому объекту относится местоимение «\n",
            "\t\t3.  утверждения:Рыба заглотила приманку. Она была вкусной.Рыба заглотила приманку. \u001b[92mОна\u001b[0m была голодной. К какому объекту относится местоимение «она» в первом примере — \n",
            "\n",
            "\n",
            "Сущность 37\n",
            "\t\t[[23308, 23316], [23318, 23321]]\n",
            "\t\t1.  человеком, хоть нейросетью). Например, сравните два утверждения:Рыба заглотила \u001b[92mприманку\u001b[0m. Она была вкусной.Рыба заглотила приманку. Она была голодной. К какому объекту \n",
            "\t\t2. , хоть нейросетью). Например, сравните два утверждения:Рыба заглотила приманку. \u001b[92mОна\u001b[0m была вкусной.Рыба заглотила приманку. Она была голодной. К какому объекту относ\n",
            "\n",
            "\n",
            "Сущность 38\n",
            "\t\t[[23956, 23964], [23975, 23978]]\n",
            "\t\t1. ста и ее, извините, кровожадных действий.Способна ли GPT-2 действительно понять \u001b[92mэтот мем\u001b[0m и оценить его абсурдную красоту? Сейчас узнаем...Люди решают такие задачи прави\n",
            "\t\t2.  кровожадных действий.Способна ли GPT-2 действительно понять этот мем и оценить \u001b[92mего\u001b[0m абсурдную красоту? Сейчас узнаем...Люди решают такие задачи правильно примерно \n",
            "\n",
            "\n",
            "Сущность 39\n",
            "\t\t[[24866, 24873], [24922, 24924]]\n",
            "\t\t1. правильно в 70% случаев.Это и есть тот самый переход количества в качество, про \u001b[92mкоторый\u001b[0m нам когда‑то твердил старина Карл Маркс. Причем он происходит совершенно нелине\n",
            "\t\t2. ичества в качество, про который нам когда‑то твердил старина Карл Маркс. Причем \u001b[92mон\u001b[0m происходит совершенно нелинейно: например, при росте количества параметров в тр\n",
            "\n",
            "\n",
            "Сущность 40\n",
            "\t\t[[25916, 25921], [26007, 26009]]\n",
            "\t\t1. ли Невероятного ХалкаПоигравшись немного с располневшей (и от этого поумневшей) \u001b[92mGPT-2\u001b[0m, ребята из OpenAI подумали: «А почему бы не взять ту же самую модель, и не увел\n",
            "\t\t2. та из OpenAI подумали: «А почему бы не взять ту же самую модель, и не увеличить \u001b[92mее\u001b[0m еще раз эдак в 100?» В общем, вышедшая в 2020 году следующая номерная версия, G\n",
            "\n",
            "\n",
            "Сущность 41\n",
            "\t\t[[26593, 26614], [26622, 26625], [43117, 43123]]\n",
            "\t\t1. й объем информации уже точно нереально — ну, разве что, если посадить с десяток \u001b[92mАнатолиев Вассерманов\u001b[0m, чтобы они читали буквально нон‑стоп по 50 лет подряд каждый.GPT-3 может и быть\n",
            "\t\t2. нереально — ну, разве что, если посадить с десяток Анатолиев Вассерманов, чтобы \u001b[92mони\u001b[0m читали буквально нон‑стоп по 50 лет подряд каждый.GPT-3 может и быть умнее Онот\n",
            "\t\t3. конкуренции с нейросетью, а китайцы в срочном порядке анонсировали скорый релиз \u001b[92mсвоего\u001b[0m собственного чат‑бота. Но это всё, если честно, уже совсем другая история — сле\n",
            "\n",
            "\n",
            "Сущность 42\n",
            "\t\t[[26701, 26709], [26739, 26742]]\n",
            "\t\t1.  они читали буквально нон‑стоп по 50 лет подряд каждый.GPT-3 может и быть умнее \u001b[92mОнотолея\u001b[0m, но осмелится ли она сказать ему это в лицо?..  Сразу бросается в глаза интерес\n",
            "\t\t2. ет подряд каждый.GPT-3 может и быть умнее Онотолея, но осмелится ли она сказать \u001b[92mему\u001b[0m это в лицо?..  Сразу бросается в глаза интересный нюанс: в отличие от GPT-2, са\n",
            "\n",
            "\n",
            "Сущность 43\n",
            "\t\t[[26813, 26818], [40108, 40119]]\n",
            "\t\t1. азать ему это в лицо?..  Сразу бросается в глаза интересный нюанс: в отличие от \u001b[92mGPT-2\u001b[0m, сама модель теперь имеет размер больше (700 Гб), чем весь массив текста для ее\n",
            "\t\t2. с технической точки зрения, кажется, у нее нет каких‑то особо мощных отличий от \u001b[92mInstructGPT\u001b[0m (к сожалению, научной статьи с детальным описанием ChatGPT команда OpenAI пока \n",
            "\n",
            "\n",
            "Сущность 44\n",
            "\t\t[[27004, 27016], [27074, 27077]]\n",
            "\t\t1. ется как будто бы парадокс: наш «нейромозг» в данном случае в процессе изучения \u001b[92mсырых данных\u001b[0m генерирует информацию о разных взаимозависимостях внутри них, которая превышает\n",
            "\t\t2.  изучения сырых данных генерирует информацию о разных взаимозависимостях внутри \u001b[92mних\u001b[0m, которая превышает по объему исходную информацию.Такое обобщение («осмысление»?\n",
            "\n",
            "\n",
            "Сущность 45\n",
            "\t\t[[29713, 29730], [29732, 29739], [37295, 37297]]\n",
            "\t\t1. о показывает, как с увеличением количества параметров модели в ней «прорастают» \u001b[92mновые способности\u001b[0m, которые никто туда специально не закладывал:Кстати, задачу про «голодных рыбов\n",
            "\t\t2.  увеличением количества параметров модели в ней «прорастают» новые способности, \u001b[92mкоторые\u001b[0m никто туда специально не закладывал:Кстати, задачу про «голодных рыбов», которо\n",
            "\t\t3. ом, что подобных спорных ситуаций – огромная куча, и как-то четко формализовать \u001b[92mих\u001b[0m просто не представляется возможным. Да что там, люди и сами между собой не могу\n",
            "\n",
            "\n",
            "Сущность 46\n",
            "\t\t[[30301, 30323], [30333, 30337]]\n",
            "\t\t1. ь умеет решать задачи»? По сути, процесс выглядит так: мы подаем на вход модели \u001b[92mнекий текст с запросом\u001b[0m, а она к нему дописывает свое продолжение. Если это продолжение (генерация) сов\n",
            "\t\t2.  процесс выглядит так: мы подаем на вход модели некий текст с запросом, а она к \u001b[92mнему\u001b[0m дописывает свое продолжение. Если это продолжение (генерация) совпадает с нашим\n",
            "\n",
            "\n",
            "Сущность 47\n",
            "\t\t[[30492, 30501], [30598, 30600]]\n",
            "\t\t1. нашими ожиданиями — то модель, получается, решила поставленную перед ней задачу.\u001b[92mТот текст\u001b[0m, что мы подаем на вход, называется prompt (промпт, или «запрос/затравка» по‑рус\n",
            "\t\t2. а вход, называется prompt (промпт, или «запрос/затравка» по‑русски). Чем точнее \u001b[92mон\u001b[0m описывает, что мы хотим, тем лучше модель поймет, что ей нужно делать. А если м\n",
            "\n",
            "\n",
            "Сущность 48\n",
            "\t\t[[32068, 32079], [32157, 32159], [32304, 32317], [32325, 32327], [32393, 32397], [32481, 32492], [32570, 32572], [32630, 32634], [32668, 32672], [32717, 32721]]\n",
            "\t\t1. ой фразы.Как это работает? Давайте на примере детской задачки:Вопрос: В среднем \u001b[92mбоксер Иван\u001b[0m наносит 25 ударов в минуту. Бой длится 5 раундов по 3 минуты. Сколько ударов он\n",
            "\t\t2. ан наносит 25 ударов в минуту. Бой длится 5 раундов по 3 минуты. Сколько ударов \u001b[92mон\u001b[0m нанес?Ответ: 255Текст, выделенный жирным – это ответ, сгенерированный языковой \n",
            "\t\t3. анный языковой моделью. Легко проверить, что он – ну, немного неправильный.Лицо \u001b[92mбоксера Ивана\u001b[0m, когда он пытается посчитать – сколько честно нанесенных ударов «украла» у него\n",
            "\t\t4. ю. Легко проверить, что он – ну, немного неправильный.Лицо боксера Ивана, когда \u001b[92mон\u001b[0m пытается посчитать – сколько честно нанесенных ударов «украла» у него языковая \n",
            "\t\t5. вана, когда он пытается посчитать – сколько честно нанесенных ударов «украла» у \u001b[92mнего\u001b[0m языковая модель?Однако та же самая модель может ответить вот так:Вопрос: В сред\n",
            "\t\t6. ковая модель?Однако та же самая модель может ответить вот так:Вопрос: В среднем \u001b[92mбоксер Иван\u001b[0m наносит 25 ударов в минуту. Бой длится 5 раундов по 3 минуты. Сколько ударов он\n",
            "\t\t7. ан наносит 25 ударов в минуту. Бой длится 5 раундов по 3 минуты. Сколько ударов \u001b[92mон\u001b[0m нанес?Ответ: Давай подумаем шаг за шагом. За одну минуту Иван наносит 25 ударов\n",
            "\t\t8. уты. Сколько ударов он нанес?Ответ: Давай подумаем шаг за шагом. За одну минуту \u001b[92mИван\u001b[0m наносит 25 ударов. За три минуты Иван наносит 3 * 25 = 75 ударов. За пять раунд\n",
            "\t\t9. вай подумаем шаг за шагом. За одну минуту Иван наносит 25 ударов. За три минуты \u001b[92mИван\u001b[0m наносит 3 * 25 = 75 ударов. За пять раундов Иван наносит 5 * 75 = 375 ударов.И \n",
            "\t\t10. носит 25 ударов. За три минуты Иван наносит 3 * 25 = 75 ударов. За пять раундов \u001b[92mИван\u001b[0m наносит 5 * 75 = 375 ударов.И снова текст выделенный жирным — это ответ модели.\n",
            "\n",
            "\n",
            "Сущность 49\n",
            "\t\t[[34467, 34475], [34498, 34500]]\n",
            "\t\t1. азмеров языковых моделей само по себе еще не означает, что они будут отвечать на\u001b[92m запросы\u001b[0m именно так, как хочет их пользователь. Ведь часто мы, когда формулируем какой‑т\n",
            "\t\t2. о себе еще не означает, что они будут отвечать на запросы именно так, как хочет \u001b[92mих\u001b[0m пользователь. Ведь часто мы, когда формулируем какой‑то запрос, подразумеваем о\n",
            "\n",
            "\n",
            "Сущность 50\n",
            "\t\t[[34717, 34728], [34850, 34854]]\n",
            "\t\t1.  людьми считаются сами собой разумеющимися, что ли. Например, когда Маша просит \u001b[92mсвоего мужа\u001b[0m: «Вась, сходи выбрось мусор» — то вряд ли ей придет в голову прибавить к этому \n",
            "\t\t2.  ей придет в голову прибавить к этому промпту «(только не из окна, плз!)». Ведь \u001b[92mВася\u001b[0m это понимает и без уточнений — а всё потому, что их намерения и установки непло\n",
            "\n",
            "\n",
            "Сущность 51\n",
            "\t\t[[35852, 35861], [35867, 35877]]\n",
            "\t\t1. T-3 обучена просто предсказывать следующее слово в гигантском наборе текстов из \u001b[92mИнтернета\u001b[0m — а в Интернете, как и на заборе, много всякого разного написано (и не всегда п\n",
            "\t\t2. сто предсказывать следующее слово в гигантском наборе текстов из Интернета — а в\u001b[92m Интернете\u001b[0m, как и на заборе, много всякого разного написано (и не всегда полезного). При э\n",
            "\n",
            "\n",
            "Сущность 52\n",
            "\t\t[[38439, 38465], [38487, 38489]]\n",
            "\t\t1. , получается, училась решать еще одну дополнительную задачу – «как мне поменять \u001b[92mсвой сгенерированный ответ\u001b[0m таким образом, чтобы он получил наибольшую оценку от человека?» (подробнее проц\n",
            "\t\t2. ьную задачу – «как мне поменять свой сгенерированный ответ таким образом, чтобы \u001b[92mон\u001b[0m получил наибольшую оценку от человека?» (подробнее процесс обучения по обратной\n",
            "\n",
            "\n",
            "Сущность 53\n",
            "\t\t[[41869, 41871], [41902, 41905], [42000, 42005], [42028, 42030]]\n",
            "\t\t1. ю, скринить их и делиться в соцсетях. Choo‑choo, all aboard the hype train!Если \u001b[92mвы\u001b[0m заставили робота сочинить для вас объяснение квантовой физики в форме рэп-телег\n",
            "\t\t2. тях. Choo‑choo, all aboard the hype train!Если вы заставили робота сочинить для \u001b[92mвас\u001b[0m объяснение квантовой физики в форме рэп-телеги от Снуп Дога – то, признайтесь, \n",
            "\t\t3. нтовой физики в форме рэп-телеги от Снуп Дога – то, признайтесь, это окажется в \u001b[92mвашем\u001b[0m Твиттере быстрее, чем вы успеете моргнутьКак и в любом технологическом стартапе\n",
            "\t\t4. леги от Снуп Дога – то, признайтесь, это окажется в вашем Твиттере быстрее, чем \u001b[92mвы\u001b[0m успеете моргнутьКак и в любом технологическом стартапе, здесь оказалась важна н\n",
            "\n",
            "\n",
            "Сущность 54\n",
            "\t\t[[42247, 42250], [42285, 42288]]\n",
            "\t\t1. ла завернута. У вас может быть самая лучшая модель или самый умный чат‑бот — но \u001b[92mони\u001b[0m будут никому не интересны, если к ним не прилагается простой и понятный интерфе\n",
            "\t\t2. учшая модель или самый умный чат‑бот — но они будут никому не интересны, если к \u001b[92mним\u001b[0m не прилагается простой и понятный интерфейс. И ChatGPT в этом смысле совершил п\n",
            "\n",
            "\n",
            "Сущность 55\n",
            "\t\t[[42952, 42967], [43012, 43016]]\n",
            "\t\t1.  заключила с OpenAI сделку по инвестированию в них десятка миллиардов долларов, \u001b[92mинженеры Google\u001b[0m забили тревогу и сели думать, как им спасти свой поисковый сервис от конкуренци\n",
            "\t\t2. иллиардов долларов, инженеры Google забили тревогу и сели думать, как им спасти \u001b[92mсвой\u001b[0m поисковый сервис от конкуренции с нейросетью, а китайцы в срочном порядке анонс\n",
            "\n",
            "\n",
            "Сущность 56\n",
            "\t\t[[44088, 44112], [44114, 44121]]\n",
            "\t\t1. ашинного обучения разбираются еще более подробно.Для вашего удобства мы сделали \u001b[92mнебольшой сводный постер\u001b[0m, который наглядно иллюстрирует основные вехи истории эволюции языковых моделей.\n",
            "\t\t2. тся еще более подробно.Для вашего удобства мы сделали небольшой сводный постер, \u001b[92mкоторый\u001b[0m наглядно иллюстрирует основные вехи истории эволюции языковых моделей. Если как\n",
            "\n",
            "\n",
            "Сущность 57\n",
            "\t\t[[44886, 44906], [44926, 44929]]\n",
            "\t\t1. ых отзывов, то все эти (на наш взгляд — супер‑захватывающие!) темы мы разберем в\u001b[92m следующем материале\u001b[0m. Если вы не хотите его пропустить — то приглашаем вас подписаться на ТГ‑каналы \n",
            "\t\t2. супер‑захватывающие!) темы мы разберем в следующем материале. Если вы не хотите \u001b[92mего\u001b[0m пропустить — то приглашаем вас подписаться на ТГ‑каналы авторов: Сиолошная Игор\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_highlited(\"./kristinas_result/text_542718.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8u93rrLauI6",
        "outputId": "2d94a55f-1af5-4591-9e5c-50a7904f9257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Обзор современных инструментов дата-аналитика / Habr\n",
            "\n",
            "\n",
            "              16  February  2021 at 18:16  Обзор современных инструментов дата-аналитика Data Mining *Data visualization *Machine learning *Artificial Intelligence       \n",
            "\n",
            "\n",
            "Сразу уточню, что видов аналитиков очень много, так как анализировать можно все что угодно. Это и веб-аналитики, и классические data scientists, и бизнес-аналитики, и финансовые аналитики, а также продуктовые, системные и UX аналитики. Причина такого разнообразия, по-видимому, в том, что в ряде крупных компаний над созданием одной платформы или продукта одновременно могут работать десятки, а то и сотни программистов и аналитиков. В таких условиях происходит сильное сужение специализации.\n",
            "\n",
            "\n",
            "ВСЕ ПЕРЕЧИСЛЕННЫЕ ВИДЫ АНАЛИТИКОВ используют СВОИ специфические наборы инструментов. Поэтому сосредоточусь только непосредственно на сфере анализа данных вне контекста происхождения этих самых данных. Таким образом мы исключаем из обзора системы веб-аналитики, CRM, ERP, системы складского учета, управления логистикой и документооборотом.\n",
            "\n",
            "1. Языки программирования\n",
            "\n",
            "Не будем касаться исключительных, уникальных или редких случаев. Рассмотрим все только самое популярное. И конечно же, в первую очередь, это язык python.\n",
            "\n",
            "Python\n",
            "\n",
            "\n",
            "Python служит главным инструментом в руках data scientists, не имеет строгой типизации и предназначен для быстрой разработки прототипов или написания коротких сценариев или скриптов. Люди разбирающиеся в программировании и computer science ЕГО часто критикуют за то, что АЛГОРИТМЫ написанные на чистом python оказываются не оптимальными в отношении СВОЕЙ производительности и требованиям к памяти.\n",
            "\n",
            "\n",
            "Но тем не менее у ДАННОГО ЯЗЫКА ПРОГРАММИРОВАНИЯ есть много ПЛЮСОВ. Среди НИХ Я бы отметил то, что PYTHON преподают уже практически везде, в связи с чем сравнительно легко найти аналитика знающего python. Второе преимущество — это библиотеки для работы с данными и машинного обучения, имеющие удобный интерфейс. Например, на основе библиотеки sklearn легко собирать конвейеры предварительной обработки данных и построения моделей. Все алгоритмы и настройки машинного обучения инкапсулированы внутри классов и объектов, что делает код очень простым.\n",
            "\n",
            "R\n",
            "\n",
            "\n",
            "До недавнего времени основным конкурентом PYTHON был язык R. Пожелания к знанию R и сейчас изредка встречаются в описаниях вакансий по крайней мере в разделе «преимущества». До середины 2018-го года Я и сам программировал на R. И при попытке автоматизировать часть СВОЕЙ работы по машинному обучению чуть не изобрел велосипед, пытаясь на R создать конвейеры подготовки данных и обучения моделей. Чуть позже узнал, что такие конвейеры уже давно существуют в библиотеке sklearn и называются pipeline.\n",
            "\n",
            "C++, C#\n",
            "\n",
            "\n",
            "Если существующих библиотек на PYTHON недостаточно и требуется реализовать новый алгоритм с высокой производительностью, к вашим услугам компилируемый и статически типизированный язык C++ или похожий на него язык C#.\n",
            "\n",
            "MatLab\n",
            "\n",
            "\n",
            "ЯЗЫК MATLAB встроен в одноименный пакет программ и интерактивную среду инженерных расчетов. Правда предназначен данный язык в большей степени для решения технических задач, а не для выполнения финансового или бизнес-анализа. Например, МНЕ посчастливилось применять MatLab дважды: в процессе исследования сигналов акустической эмиссии в конструкциях, а также при обработке человеческой речи.\n",
            "\n",
            "\n",
            "Существует ряд библиотек машинного обучения с API для других языков программирования, таких как Java, JavaScript, Scala и т.д. Но останавливаться на них не буду поскольку цель статьи немного иная.\n",
            "\n",
            "\n",
            "Прошу немного потерпеть. Обо всем вы узнаете в следующих разделах.\n",
            "\n",
            "2. AutoML и визуальные конструкторы\n",
            "\n",
            "AutoML согласно своей основной идее резко упрощает задачу исследователя и сводит несколько шагов по изучению и подготовке данных, конструированию признаков, выбору и сравнению алгоритма машинного обучения и настройке гиперпараметров к одному единственному шагу. И этот шаг заключается в выборе и настройке ОДНОГО БОЛЬШОГО ЯЩИКА ПОД НАЗВАНИЕМ AUTOML. Результатом запуска алгоритма AutoML является сконструированный и соответствующим образом настроенный и обученный PIPELINE. Остается только брать «СЫРЫЕ» ДАННЫЕ, подсовывать ИХ в PIPELINE и ждать на выходе результат в виде прогнозов.\n",
            "\n",
            "\n",
            "ЯЩИК под названием «AutoML» выглядит либо как библиотека машинного обучения, либо как веб-сервис куда заливаются данные.\n",
            "\n",
            "\n",
            "Если это библиотека, то она отличается от sklearn тем, что наш привычный код в 20-30 строк сжимается до 5 строк. Известный пример такой библиотеки H2O.\n",
            "\n",
            "\n",
            "Другой пример — БИБЛИОТЕКА MLBOX. Про НЕЕ в интернете можно найти истории, о том как применение MLBOX позволило попасть в топовые 5% на соревнованиях kaggle.\n",
            "\n",
            "\n",
            "Теперь несколько слов об облачных сервисах AutoML. Во первых, СВОИ технические решения спешат представить ВСЕ ОСНОВНЫЕ ЦИФРОВЫЕ ГИГАНТЫ. Вот некоторые из НИХ: Google AutoML Tables, Azure Machine Learning (Microsoft), SageMaker Autopilot (Amazon). Перечисленные сервисы должны быть интересны в первую очередь тем компаниям, которые разрабатывают аналитические системы на облачных платформах. Очень удобно, когда и инфраструктуру данных, и вычислительные ресурсы, и готовые алгоритмы машинного обучения предоставляет один и тот же провайдер. Интеграция получается поистине бесшовной.\n",
            "\n",
            "\n",
            "Помимо цифровых гигантов на рынке AutoML появляются и игроки поменьше. Например, непосредственно в настоящий момент в компании Bell Integrator идет активная работа над платформой neuton.ai.\n",
            "\n",
            "\n",
            "В этом же разделе стоит вспомнить про системы машинного обучения, занимающие промежуточные позиции между непосредственным программированием на R и Python и полностью упакованным в коробку AutoML. Это так называемые конструкторы workflow. Два типичных примера: конструктор машинного обучения Azure от MICROSOFT и платформа SberDS Сбербанка.\n",
            "\n",
            "\n",
            "Конструктор представляет собой набор кубиков, из которых можно собрать весь конвейер машинного обучения, включая финальную проверку работоспособности модели. Это несомненно красивое решение для людей с визуальным типом мышления, которым удобно представлять процесс машинного обучения и тестирования моделей в виде схем.\n",
            "\n",
            "3. Инструменты BI\n",
            "\n",
            "Здесь бы Я хотел рассмотреть несколько BI решений в области аналитики: Power BI, Tableau, Qlik Sense, QlikView и Excel.\n",
            "\n",
            "Power BI\n",
            "\n",
            "\n",
            "Power BI — это набор аналитических инструментов от MICROSOFT, которые доступны в виде десктопных приложений и облачных сервисов. Существуют корпоративные решения, работающие на закрытой it-инфраструктуре КОМПАНИИ. Работа в Power BI Desktop или Power BI Services не требует навыков программирования. Предусмотрена возможность онлайн-интеграции с внешними источниками данных, а также загрузка данных в формате csv.\n",
            "\n",
            "\n",
            "Power BI способен решать задачи машинного обучения посредством AutoML, то есть для построения модели классификации или регрессии писать программный код как на питоне не придется. Кроме стандартных задач анализа табличных данных в функционал встроены технологии анализа тональности, извлечения ключевых фраз, распознавания языка и добавления тегов к изображению.\n",
            "\n",
            "Tableau\n",
            "\n",
            "\n",
            "Tableau также представляет собой целое семейство онлайн и десктопных приложений, как и Power BI. Данные приложения имеют простой визуальный интерфейс и позволяют работать методом перетаскивания drag-and-drop. Красивые графики строятся буквально за несколько кликов. Также ДАННЫЕ можно анализировать в табличном виде и применять к НИМ различные фильтры.\n",
            "\n",
            "\n",
            "TABLEAU позволяет решать и задачи машинного обучения, такие как регрессия, прогнозирование временных рядов, кластерный анализ. А главное, TABLEAU способен интегрироваться с внешними скриптами на R и Python. Получается легко расширяемый инструмент.\n",
            "\n",
            "Qlik Sence и QlikView\n",
            "\n",
            "\n",
            "Qlik Sence и QLIKVIEW по позиционированию и интерфейсу отличаются между собой, но по сути и по алгоритмам решения задач построены на одном движке. QLIKVIEW — корпоративная платформа, которой управляют it-специалисты, Qlik Sence — инструмент для личного использования без необходимости обращаться за помощью в тех. поддержку.\n",
            "\n",
            "\n",
            "При первом же знакомстве бросается в глаза «красота» и легкость визуализации. Это тот самый инструмент, если надо построить приятный глазу дашборд для руководства. С МОЕЙ точки зрения особенно зрелищным выглядит возможность менять масштаб при анализе географических карт и кластеров на двухмерных графиках. Вспоминаются кадры из фильмов, где на фото со спутников пытаются разглядеть номер автомобиля или выделить человека из толпы на площади.\n",
            "\n",
            "\n",
            "Еще одна интересная опция — наличие мобильного приложения для выполнения анализа со смартфона. Так и представляется топ-менеджер сети ритейла, спешащий на очередной рейс в аэропорту и получивший неожиданное сообщение в мессенджере со ссылкой на дашборд.\n",
            "\n",
            "Qlik Sence интегрируется с Python, а следовательно и с машинным обучением.\n",
            "\n",
            "Excel\n",
            "\n",
            "\n",
            "Вы МЕНЯ простите, но Я не мог пройти мимо EXCEL. Сколько не смейся, но любой инструмент по своему хорош. Например, в EXCEL прекрасно строятся сводные таблицы и графики, буквально в несколько кликов. В сочетании с удобным табличным процессором и работой с форматом csv вполне себе хороший инструмент.\n",
            "\n",
            "4. Изюминка на торте. Автоматическая генерация кода на основе AI\n",
            "\n",
            "Как-то раз при знакомстве в сети МНЕ задали вопрос «ТЫ программируешь на python?». И когда Я ответил «Да», продолжение было совершенно неожиданным.\n",
            "\n",
            "\n",
            "«А ТЫ знаешь про это… » и далее шла ссылка на ролик в Youtube \n",
            "https://www.youtube.com/watch?v=fZSFNUT6iY8&t=4s&ab_channel=FazilBabu.\n",
            "\n",
            "\n",
            "Речь идет о генеративной текстовой модели от OpenAI, обученной на репозитории GitHub. На конкретных примерах показана способность МОДЕЛИ генерировать код на PYTHON на основании заголовка функции и ее краткого описания.\n",
            "\n",
            "\n",
            "А что будет, если ТАКУЮ МОДЕЛЬ удастся хорошо обучить на скриптах data scientists? Это вопрос для размышлений…    Tags: аналитикdata sciencebusiness intelligencedata miningmachine learningмашинное обучениедата-аналитиканализ данных Hubs: Data MiningData visualizationMachine learningArtificial Intelligence          \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Inlnie semantic tags"
      ],
      "metadata": {
        "id": "OcK4anC_yC8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_func(obj):\n",
        "    return obj[\"location\"][\"start\"]"
      ],
      "metadata": {
        "id": "nCsYrt0qzAas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./rucoco/kristina/kristinas_dataset.json\", mode=\"r\", encoding=\"utf8\") as kristinas_dataset_file:\n",
        "    dataset_list = json.load(kristinas_dataset_file, strict=False)\n",
        "dataset = {}\n",
        "for data_element in dataset_list:\n",
        "    dataset[data_element[\"data_row\"][\"external_id\"]] = data_element[\"projects\"][\"clsovprgd0a3x07zq8x8hfvm1\"][\"labels\"][0][\"annotations\"][\"objects\"]"
      ],
      "metadata": {
        "id": "ujNIF-MJ0ywu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "\n",
        "def is_emoji(s):\n",
        "    return s in UNICODE_EMOJI\n",
        "\n",
        "entries = [entry for entry in os.scandir(\"./rucoco/kristina/kristinas_texts/texts\") if entry.name.endswith(\".txt\")]\n",
        "i = 0\n",
        "for entry in tqdm(entries, leave=True):\n",
        "    dataset[entry.name].sort(key=sort_func)\n",
        "    offset = 0\n",
        "    with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        text = f.read().replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\").replace(\"\\r\", \"\\\\r\").replace(\"🐺\", \"🐺🐺\")\n",
        "        for obj in dataset[entry.name]:\n",
        "            start = obj[\"location\"][\"start\"]\n",
        "            end = obj[\"location\"][\"end\"]\n",
        "            text = text[:start + offset] + \"[\" + obj[\"value\"] + \" \" + text[start + offset:end + offset + 1] + \"]\" + text[end + offset + 1:]\n",
        "            label_len = len(obj[\"value\"])\n",
        "            offset += label_len + 3\n",
        "\n",
        "        text = text.replace(\"\\\\n\", \"\\n\").replace(\"\\\\t\", \"\\t\").replace(\"\\\\r\", \"\\r\").replace(\"🐺🐺\", \"🐺\")\n",
        "        with open(os.path.join(\"./rucoco/kristina/kristinas_texts/labeled_texts\", entry.name), mode=\"w\", encoding=\"utf8\") as labeled_f:\n",
        "            labeled_f.write(text)\n",
        "    i += 1\n",
        "    print(\"Files: \", i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4eAT7niyAJD",
        "outputId": "a6c7b071-220a-411c-8ab0-fb04fd936adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 1222.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files:  1\n",
            "Files:  2\n",
            "Files:  3\n",
            "Files:  4\n",
            "Files:  5\n",
            "Files:  6\n",
            "Files:  7\n",
            "Files:  8\n",
            "Files:  9\n",
            "Files:  10\n",
            "Files:  11\n",
            "Files:  12\n",
            "Files:  13\n",
            "Files:  14\n",
            "Files:  15\n",
            "Files:  16\n",
            "Files:  17\n",
            "Files:  18\n",
            "Files:  19\n",
            "Files:  20\n",
            "Files:  21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split large texts"
      ],
      "metadata": {
        "id": "OMel-J7R36eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "w0YeMhq3-hJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = load_tokenizer(model.hparams[\"encoder_model_name\"])"
      ],
      "metadata": {
        "id": "qRNhSNSd-6AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokens_number(text: str):\n",
        "    return len(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "id": "hK2lYFNGxidz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text: str, file_name: str, out_dir: str):\n",
        "    if get_tokens_number(text) <= max_text_length:\n",
        "        with open(os.path.join(out_dir, file_name), mode=\"w\", encoding=\"utf8\") as f:\n",
        "            f.write(text)\n",
        "        return\n",
        "\n",
        "    start = 0\n",
        "    end = 0\n",
        "    texts = []\n",
        "    while end < len(text):\n",
        "        new_end = text.find('\\n', end + 1)\n",
        "        if new_end == -1:\n",
        "            new_end = len(text)\n",
        "        if get_tokens_number(text[start:new_end]) > max_text_length:\n",
        "            texts.append(text[start:end])\n",
        "            start = end + 1\n",
        "        end = new_end\n",
        "    texts.append(text[start:end])\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        with open(os.path.join(out_dir,  os.path.splitext(os.path.basename(file_name))[0] + \"_\" + str(i) + \".txt\"), mode=\"w\", encoding=\"utf8\") as f:\n",
        "               f.write(texts[i])"
      ],
      "metadata": {
        "id": "-vv8DxBD6ive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entries = [entry for entry in os.scandir(\"./rucoco/kristina/kristinas_texts/texts\") if entry.name.endswith(\".txt\")]\n",
        "\n",
        "out_dir = \"./rucoco/kristina/kristinas_texts/splitted_texts\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    i = 0\n",
        "    for entry in tqdm(entries, leave=True):\n",
        "        i += 1\n",
        "        with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "            text = f.read()\n",
        "            split_text(text, entry.name, out_dir)\n",
        "\n",
        "    print(\"Files: \", i)"
      ],
      "metadata": {
        "id": "NPpzvmz93_Jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7e9121-aee3-4513-8c3d-9c6352d4e1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:01<00:00, 20.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files:  21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entries = [entry for entry in os.scandir(\"./rucoco/kristina/kristinas_texts/texts\") if entry.name.endswith(\".txt\")]\n",
        "\n",
        "\n",
        "i = 0\n",
        "for entry in entries:\n",
        "    i += 1\n",
        "    with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        text = f.read()\n",
        "        print(\"Tokens number = \" + str(get_tokens_number(text)))\n",
        "\n",
        "\n",
        "print(\"Files: \", i)"
      ],
      "metadata": {
        "id": "CzDLzntNCSd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120d6479-f379-4198-a034-211c7044f4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens number = 2438\n",
            "Tokens number = 7648\n",
            "Tokens number = 4096\n",
            "Tokens number = 4358\n",
            "Tokens number = 4591\n",
            "Tokens number = 4575\n",
            "Tokens number = 14044\n",
            "Tokens number = 4613\n",
            "Tokens number = 8824\n",
            "Tokens number = 3285\n",
            "Tokens number = 2597\n",
            "Tokens number = 12238\n",
            "Tokens number = 2845\n",
            "Tokens number = 9961\n",
            "Tokens number = 3583\n",
            "Tokens number = 3452\n",
            "Tokens number = 1900\n",
            "Tokens number = 12544\n",
            "Tokens number = 3567\n",
            "Tokens number = 3316\n",
            "Tokens number = 676\n",
            "Files:  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict using data with semantics"
      ],
      "metadata": {
        "id": "n1UxDsGcrFRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare semantics dataset"
      ],
      "metadata": {
        "id": "ym9HmrSp4lOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "CrmxI0h5_-H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = load_tokenizer(model.hparams[\"encoder_model_name\"])"
      ],
      "metadata": {
        "id": "u70k6VsZdw4k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "30fad76c-7d51-49a0-edf9-1164c0f8e83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m load_tokenizer(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mhparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_model_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./rucoco/kristina/kristinas_dataset.json\", mode=\"r\", encoding=\"utf8\") as kristinas_dataset_file:\n",
        "    dataset_list = json.load(kristinas_dataset_file, strict=False)\n",
        "dataset0 = {}\n",
        "for data_element in dataset_list:\n",
        "    dataset0[data_element[\"data_row\"][\"external_id\"]] = data_element[\"projects\"][\"clsovprgd0a3x07zq8x8hfvm1\"][\"labels\"][0][\"annotations\"][\"objects\"]"
      ],
      "metadata": {
        "id": "H_JSf1lfCnZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_func(obj):\n",
        "    return obj[\"location\"][\"start\"]"
      ],
      "metadata": {
        "id": "zKDrsnWqDGnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entries = [entry for entry in os.scandir(\"./rucoco/kristina/kristinas_texts/texts\") if entry.name.endswith(\".txt\")]\n",
        "i = 0\n",
        "for entry in tqdm(entries, leave=True):\n",
        "    print(entry.name)\n",
        "    dataset0[entry.name].sort(key=sort_func)\n",
        "    with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "        text = f.read()\n",
        "        for obj in dataset0[entry.name]:\n",
        "            start = obj[\"location\"][\"start\"]\n",
        "            print(\"start before shifting: \", obj[\"location\"][\"start\"])\n",
        "            offset = text[:start].count(\"\\n\") + text[:start].count(\"\\t\") + text[:start].count(\"\\r\") + text[:start].count(\"🐺\")\n",
        "            print(offset)\n",
        "            obj[\"location\"][\"start\"] -= offset\n",
        "            obj[\"location\"][\"end\"] -= offset - 1\n",
        "            print(\"start: \", obj[\"location\"][\"start\"])\n",
        "            print(text[obj[\"location\"][\"start\"]:obj[\"location\"][\"end\"]])\n",
        "            print(\"===\")\n",
        "        print(\"======\")\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "7Tg_BYXCrD9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7bac30-630e-4adf-9fe0-96b6e09e03ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 386.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_542718.txt\n",
            "start before shifting:  0\n",
            "0\n",
            "start:  0\n",
            "\n",
            "\n",
            "Обзор с\n",
            "===\n",
            "start before shifting:  42\n",
            "2\n",
            "start:  40\n",
            "алитика \n",
            "===\n",
            "start before shifting:  47\n",
            "2\n",
            "start:  45\n",
            "ка / Ha\n",
            "===\n",
            "start before shifting:  51\n",
            "2\n",
            "start:  49\n",
            " Habr\n",
            "\n",
            "\n",
            "  \n",
            "===\n",
            "start before shifting:  63\n",
            "5\n",
            "start:  58\n",
            "  \n",
            "===\n",
            "start before shifting:  85\n",
            "5\n",
            "start:  80\n",
            "ar\n",
            "===\n",
            "start before shifting:  144\n",
            "5\n",
            "start:  139\n",
            "лити\n",
            "===\n",
            "start before shifting:  179\n",
            "5\n",
            "start:  174\n",
            "ion *Machine lear\n",
            "===\n",
            "start before shifting:  181\n",
            "5\n",
            "start:  176\n",
            "n *Mac\n",
            "===\n",
            "start before shifting:  191\n",
            "5\n",
            "start:  186\n",
            " learning *Ar\n",
            "===\n",
            "start before shifting:  197\n",
            "5\n",
            "start:  192\n",
            "ing *Artificial Intellig\n",
            "===\n",
            "start before shifting:  223\n",
            "5\n",
            "start:  218\n",
            "ce       \n",
            "\n",
            "\n",
            "Сразу\n",
            "===\n",
            "start before shifting:  230\n",
            "8\n",
            "start:  222\n",
            "  \n",
            "===\n",
            "start before shifting:  244\n",
            "8\n",
            "start:  236\n",
            "уточню, что видов \n",
            "===\n",
            "start before shifting:  250\n",
            "8\n",
            "start:  242\n",
            ", что \n",
            "===\n",
            "start before shifting:  250\n",
            "8\n",
            "start:  242\n",
            ", что видов\n",
            "===\n",
            "start before shifting:  277\n",
            "8\n",
            "start:  269\n",
            "ь много\n",
            "===\n",
            "start before shifting:  286\n",
            "8\n",
            "start:  278\n",
            "так как анализирова\n",
            "===\n",
            "start before shifting:  328\n",
            "8\n",
            "start:  320\n",
            ". Это \n",
            "===\n",
            "start before shifting:  343\n",
            "8\n",
            "start:  335\n",
            "ли\n",
            "===\n",
            "start before shifting:  357\n",
            "8\n",
            "start:  349\n",
            "сически\n",
            "===\n",
            "start before shifting:  381\n",
            "8\n",
            "start:  373\n",
            ", и би\n",
            "===\n",
            "start before shifting:  405\n",
            "8\n",
            "start:  397\n",
            "фина\n",
            "===\n",
            "start before shifting:  415\n",
            "8\n",
            "start:  407\n",
            " аналитик\n",
            "===\n",
            "start before shifting:  456\n",
            "8\n",
            "start:  448\n",
            "е и UX\n",
            "===\n",
            "start before shifting:  473\n",
            "8\n",
            "start:  465\n",
            " Причина\n",
            "===\n",
            "start before shifting:  473\n",
            "8\n",
            "start:  465\n",
            " Причин\n",
            "===\n",
            "start before shifting:  478\n",
            "8\n",
            "start:  470\n",
            "ина так\n",
            "===\n",
            "start before shifting:  480\n",
            "8\n",
            "start:  472\n",
            "а такого разно\n",
            "===\n",
            "start before shifting:  495\n",
            "8\n",
            "start:  487\n",
            "бразия, по-видимому, в \n",
            "===\n",
            "start before shifting:  502\n",
            "8\n",
            "start:  494\n",
            " по-\n",
            "===\n",
            "start before shifting:  507\n",
            "8\n",
            "start:  499\n",
            "иди\n",
            "===\n",
            "start before shifting:  519\n",
            "8\n",
            "start:  511\n",
            "ом, что в \n",
            "===\n",
            "start before shifting:  531\n",
            "8\n",
            "start:  523\n",
            "де крупных компаний \n",
            "===\n",
            "start before shifting:  546\n",
            "8\n",
            "start:  538\n",
            "аний на\n",
            "===\n",
            "start before shifting:  552\n",
            "8\n",
            "start:  544\n",
            "ад созд\n",
            "===\n",
            "start before shifting:  574\n",
            "8\n",
            "start:  566\n",
            "тформы \n",
            "===\n",
            "start before shifting:  618\n",
            "8\n",
            "start:  610\n",
            "ать десятки, а то и сотни\n",
            "===\n",
            "start before shifting:  676\n",
            "8\n",
            "start:  668\n",
            "ких условиях происхо\n",
            "===\n",
            "start before shifting:  695\n",
            "8\n",
            "start:  687\n",
            "одит сильное сужение спец\n",
            "===\n",
            "start before shifting:  698\n",
            "8\n",
            "start:  690\n",
            "т си\n",
            "===\n",
            "start before shifting:  718\n",
            "8\n",
            "start:  710\n",
            "ециализации.\n",
            "\n",
            "\n",
            "Все п\n",
            "===\n",
            "start before shifting:  723\n",
            "9\n",
            "start:  714\n",
            "лиз\n",
            "===\n",
            "start before shifting:  730\n",
            "11\n",
            "start:  719\n",
            "ии.\n",
            "\n",
            "\n",
            "В\n",
            "===\n",
            "start before shifting:  740\n",
            "11\n",
            "start:  729\n",
            "перечисленные вид\n",
            "===\n",
            "start before shifting:  747\n",
            "11\n",
            "start:  736\n",
            "ленные \n",
            "===\n",
            "start before shifting:  775\n",
            "11\n",
            "start:  764\n",
            "ьзуют св\n",
            "===\n",
            "start before shifting:  776\n",
            "11\n",
            "start:  765\n",
            "зуют свои\n",
            "===\n",
            "start before shifting:  786\n",
            "11\n",
            "start:  775\n",
            "специфические наборы инструме\n",
            "===\n",
            "start before shifting:  788\n",
            "11\n",
            "start:  777\n",
            "ецифичес\n",
            "===\n",
            "start before shifting:  875\n",
            "11\n",
            "start:  864\n",
            "анализа д\n",
            "===\n",
            "start before shifting:  906\n",
            "11\n",
            "start:  895\n",
            "оисхожде\n",
            "===\n",
            "start before shifting:  932\n",
            "11\n",
            "start:  921\n",
            "ных. Та\n",
            "===\n",
            "start before shifting:  982\n",
            "11\n",
            "start:  971\n",
            "веб-аналитики,\n",
            "===\n",
            "start before shifting:  1004\n",
            "11\n",
            "start:  993\n",
            "P, системы складского учета, у\n",
            "===\n",
            "start before shifting:  1007\n",
            "11\n",
            "start:  996\n",
            "системы\n",
            "===\n",
            "start before shifting:  1024\n",
            "11\n",
            "start:  1013\n",
            "о учета, управле\n",
            "===\n",
            "start before shifting:  1037\n",
            "11\n",
            "start:  1026\n",
            "вления \n",
            "===\n",
            "start before shifting:  1070\n",
            "13\n",
            "start:  1057\n",
            "оротом.\n",
            "===\n",
            "start before shifting:  1074\n",
            "13\n",
            "start:  1061\n",
            "ом.\n",
            "\n",
            "1. Яз\n",
            "===\n",
            "start before shifting:  1143\n",
            "15\n",
            "start:  1128\n",
            "никальны\n",
            "===\n",
            "start before shifting:  1146\n",
            "15\n",
            "start:  1131\n",
            "альных \n",
            "===\n",
            "start before shifting:  1160\n",
            "15\n",
            "start:  1145\n",
            "ких случаев. Рассмо\n",
            "===\n",
            "start before shifting:  1207\n",
            "15\n",
            "start:  1192\n",
            "рное. И ко\n",
            "===\n",
            "start before shifting:  1218\n",
            "15\n",
            "start:  1203\n",
            "ечно же, в первую очередь, это я\n",
            "===\n",
            "start before shifting:  1231\n",
            "15\n",
            "start:  1216\n",
            "рвую \n",
            "===\n",
            "start before shifting:  1233\n",
            "15\n",
            "start:  1218\n",
            "ую\n",
            "===\n",
            "start before shifting:  1237\n",
            "15\n",
            "start:  1222\n",
            "чередь,\n",
            "===\n",
            "start before shifting:  1237\n",
            "15\n",
            "start:  1222\n",
            "чередь, это\n",
            "===\n",
            "start before shifting:  1237\n",
            "15\n",
            "start:  1222\n",
            "чередь,\n",
            "===\n",
            "start before shifting:  1245\n",
            "15\n",
            "start:  1230\n",
            "это язы\n",
            "===\n",
            "start before shifting:  1249\n",
            "17\n",
            "start:  1232\n",
            "о язык\n",
            "===\n",
            "start before shifting:  1251\n",
            "17\n",
            "start:  1234\n",
            "язык python.\n",
            "\n",
            "Pyth\n",
            "===\n",
            "start before shifting:  1257\n",
            "20\n",
            "start:  1237\n",
            "к pytho\n",
            "===\n",
            "start before shifting:  1278\n",
            "20\n",
            "start:  1258\n",
            "ython с\n",
            "===\n",
            "start before shifting:  1281\n",
            "20\n",
            "start:  1261\n",
            "on служи\n",
            "===\n",
            "start before shifting:  1318\n",
            "20\n",
            "start:  1298\n",
            "х data sc\n",
            "===\n",
            "start before shifting:  1333\n",
            "20\n",
            "start:  1313\n",
            "ts\n",
            "===\n",
            "start before shifting:  1337\n",
            "20\n",
            "start:  1317\n",
            "не имее\n",
            "===\n",
            "start before shifting:  1378\n",
            "20\n",
            "start:  1358\n",
            " для б\n",
            "===\n",
            "start before shifting:  1387\n",
            "20\n",
            "start:  1367\n",
            "рой разраб\n",
            "===\n",
            "start before shifting:  1389\n",
            "20\n",
            "start:  1369\n",
            "й разработк\n",
            "===\n",
            "start before shifting:  1402\n",
            "20\n",
            "start:  1382\n",
            "прототипо\n",
            "===\n",
            "start before shifting:  1403\n",
            "20\n",
            "start:  1383\n",
            "рототип\n",
            "===\n",
            "start before shifting:  1409\n",
            "20\n",
            "start:  1389\n",
            "пов или\n",
            "===\n",
            "start before shifting:  1416\n",
            "20\n",
            "start:  1396\n",
            " написания\n",
            "===\n",
            "start before shifting:  1416\n",
            "20\n",
            "start:  1396\n",
            " написания \n",
            "===\n",
            "start before shifting:  1429\n",
            "20\n",
            "start:  1409\n",
            "ротких сц\n",
            "===\n",
            "start before shifting:  1439\n",
            "20\n",
            "start:  1419\n",
            "нариев \n",
            "===\n",
            "start before shifting:  1461\n",
            "20\n",
            "start:  1441\n",
            "юди разбирающиеся\n",
            "===\n",
            "start before shifting:  1480\n",
            "20\n",
            "start:  1460\n",
            " программировании\n",
            "===\n",
            "start before shifting:  1559\n",
            "20\n",
            "start:  1539\n",
            "аписанн\n",
            "===\n",
            "start before shifting:  1563\n",
            "20\n",
            "start:  1543\n",
            "анные на \n",
            "===\n",
            "start before shifting:  1633\n",
            "20\n",
            "start:  1613\n",
            "роизводител\n",
            "===\n",
            "start before shifting:  1756\n",
            "23\n",
            "start:  1733\n",
            "х я бы \n",
            "===\n",
            "start before shifting:  1838\n",
            "23\n",
            "start:  1815\n",
            "ительно л\n",
            "===\n",
            "start before shifting:  1848\n",
            "23\n",
            "start:  1825\n",
            "гко найт\n",
            "===\n",
            "start before shifting:  1854\n",
            "23\n",
            "start:  1831\n",
            "йти ана\n",
            "===\n",
            "start before shifting:  1857\n",
            "23\n",
            "start:  1834\n",
            " аналитика \n",
            "===\n",
            "start before shifting:  1869\n",
            "23\n",
            "start:  1846\n",
            "нающего p\n",
            "===\n",
            "start before shifting:  1880\n",
            "23\n",
            "start:  1857\n",
            "hon. В\n",
            "===\n",
            "start before shifting:  1890\n",
            "23\n",
            "start:  1867\n",
            "е преимущ\n",
            "===\n",
            "start before shifting:  1922\n",
            "23\n",
            "start:  1899\n",
            "для работы с данным\n",
            "===\n",
            "start before shifting:  2000\n",
            "23\n",
            "start:  1977\n",
            ", на осн\n",
            "===\n",
            "start before shifting:  2044\n",
            "23\n",
            "start:  2021\n",
            "ь конвейе\n",
            "===\n",
            "start before shifting:  2082\n",
            "23\n",
            "start:  2059\n",
            "данных и построения\n",
            "===\n",
            "start before shifting:  2114\n",
            "23\n",
            "start:  2091\n",
            " алгоритмы и настро\n",
            "===\n",
            "start before shifting:  2204\n",
            "23\n",
            "start:  2181\n",
            "ел\n",
            "===\n",
            "======\n",
            "text_737046.txt\n",
            "start before shifting:  27\n",
            "2\n",
            "start:  25\n",
            "н на Air\n",
            "===\n",
            "start before shifting:  30\n",
            "2\n",
            "start:  28\n",
            "а Airflo\n",
            "===\n",
            "start before shifting:  50\n",
            "2\n",
            "start:  48\n",
            " туториа\n",
            "===\n",
            "start before shifting:  51\n",
            "2\n",
            "start:  49\n",
            "туториал / Habr\n",
            "\n",
            "\n",
            "         \n",
            "===\n",
            "start before shifting:  57\n",
            "2\n",
            "start:  55\n",
            "ал / Hab\n",
            "===\n",
            "start before shifting:  63\n",
            "2\n",
            "start:  61\n",
            "abr\n",
            "\n",
            "\n",
            "  \n",
            "===\n",
            "start before shifting:  80\n",
            "5\n",
            "start:  75\n",
            "       Пишем первый ML-пайплайн на Airflow: подробный тутори\n",
            "===\n",
            "start before shifting:  82\n",
            "5\n",
            "start:  77\n",
            "     Пиш\n",
            "===\n",
            "start before shifting:  83\n",
            "5\n",
            "start:  78\n",
            "    Пише\n",
            "===\n",
            "start before shifting:  88\n",
            "5\n",
            "start:  83\n",
            "ишем пер\n",
            "===\n",
            "start before shifting:  102\n",
            "5\n",
            "start:  97\n",
            "-пайплайн на Ai\n",
            "===\n",
            "start before shifting:  102\n",
            "5\n",
            "start:  97\n",
            "-пайплайн на Airflow: подробный туториал\n",
            "===\n",
            "start before shifting:  102\n",
            "5\n",
            "start:  97\n",
            "-пайплай\n",
            "===\n",
            "start before shifting:  104\n",
            "5\n",
            "start:  99\n",
            "айплайн на Air\n",
            "===\n",
            "start before shifting:  110\n",
            "5\n",
            "start:  105\n",
            "н на Air\n",
            "===\n",
            "start before shifting:  110\n",
            "5\n",
            "start:  105\n",
            "н на Air\n",
            "===\n",
            "start before shifting:  111\n",
            "5\n",
            "start:  106\n",
            " на Airflow: по\n",
            "===\n",
            "start before shifting:  116\n",
            "5\n",
            "start:  111\n",
            "irflow: подробный туториал \n",
            "===\n",
            "start before shifting:  119\n",
            "5\n",
            "start:  114\n",
            "low: подробный туториал  \n",
            "===\n",
            "start before shifting:  120\n",
            "5\n",
            "start:  115\n",
            "ow: подр\n",
            "===\n",
            "start before shifting:  120\n",
            "5\n",
            "start:  115\n",
            "ow: подр\n",
            "===\n",
            "start before shifting:  124\n",
            "5\n",
            "start:  119\n",
            "подробный туториал\n",
            "===\n",
            "start before shifting:  143\n",
            "5\n",
            "start:  138\n",
            " Reading t\n",
            "===\n",
            "start before shifting:  154\n",
            "6\n",
            "start:  148\n",
            "ime  \n",
            "    13 min\n",
            "  \n",
            "===\n",
            "start before shifting:  155\n",
            "6\n",
            "start:  149\n",
            "me  \n",
            "   \n",
            "===\n",
            "start before shifting:  155\n",
            "6\n",
            "start:  149\n",
            "me  \n",
            "    1\n",
            "===\n",
            "start before shifting:  163\n",
            "6\n",
            "start:  157\n",
            " 13 min\n",
            "\n",
            "===\n",
            "start before shifting:  166\n",
            "7\n",
            "start:  159\n",
            "3 min\n",
            "  \n",
            "===\n",
            "start before shifting:  170\n",
            "7\n",
            "start:  163\n",
            "n\n",
            "   Vie\n",
            "===\n",
            "start before shifting:  175\n",
            "7\n",
            "start:  168\n",
            "Views  4\n",
            "===\n",
            "start before shifting:  177\n",
            "7\n",
            "start:  170\n",
            "ews  4.2\n",
            "===\n",
            "start before shifting:  179\n",
            "7\n",
            "start:  172\n",
            "s  4.2K\n",
            "===\n",
            "start before shifting:  187\n",
            "7\n",
            "start:  180\n",
            "Python *Machine learning *Natural Language Proces\n",
            "===\n",
            "start before shifting:  190\n",
            "7\n",
            "start:  183\n",
            "hon *Mac\n",
            "===\n",
            "start before shifting:  191\n",
            "7\n",
            "start:  184\n",
            "on *Machine learnin\n",
            "===\n",
            "start before shifting:  200\n",
            "7\n",
            "start:  193\n",
            "ne learn\n",
            "===\n",
            "start before shifting:  205\n",
            "7\n",
            "start:  198\n",
            "arning *Natural\n",
            "===\n",
            "start before shifting:  210\n",
            "7\n",
            "start:  203\n",
            "g *Natur\n",
            "===\n",
            "start before shifting:  223\n",
            "7\n",
            "start:  216\n",
            "nguage P\n",
            "===\n",
            "start before shifting:  236\n",
            "7\n",
            "start:  229\n",
            "sing * \n",
            "    Tutoria\n",
            "===\n",
            "start before shifting:  243\n",
            "8\n",
            "start:  235\n",
            " \n",
            "    Tutorial\n",
            "\n",
            "===\n",
            "start before shifting:  248\n",
            "8\n",
            "start:  240\n",
            " Tutoria\n",
            "===\n",
            "start before shifting:  436\n",
            "9\n",
            "start:  427\n",
            "Airflow.\n",
            "===\n",
            "start before shifting:  508\n",
            "9\n",
            "start:  499\n",
            "чения. В\n",
            "===\n",
            "start before shifting:  627\n",
            "9\n",
            "start:  618\n",
            "(zero-sh\n",
            "===\n",
            "start before shifting:  635\n",
            "9\n",
            "start:  626\n",
            "ot classific\n",
            "===\n",
            "start before shifting:  2229\n",
            "9\n",
            "start:  2220\n",
            "й обрабо\n",
            "===\n",
            "start before shifting:  2333\n",
            "9\n",
            "start:  2324\n",
            " не треб\n",
            "===\n",
            "start before shifting:  2363\n",
            "9\n",
            "start:  2354\n",
            "имизации\n",
            "===\n",
            "start before shifting:  2425\n",
            "9\n",
            "start:  2416\n",
            "к: предсказ\n",
            "===\n",
            "start before shifting:  2436\n",
            "9\n",
            "start:  2427\n",
            "ания имеют запа\n",
            "===\n",
            "start before shifting:  2989\n",
            "9\n",
            "start:  2980\n",
            "йплайна. Это ст\n",
            "===\n",
            "start before shifting:  3271\n",
            "9\n",
            "start:  3262\n",
            "исимостями.Task\n",
            "===\n",
            "start before shifting:  3386\n",
            "9\n",
            "start:  3377\n",
            " должны быт\n",
            "===\n",
            "start before shifting:  3627\n",
            "9\n",
            "start:  3618\n",
            "дача в п\n",
            "===\n",
            "start before shifting:  3789\n",
            "9\n",
            "start:  3780\n",
            "е о структ\n",
            "===\n",
            "start before shifting:  3800\n",
            "9\n",
            "start:  3791\n",
            "ре п\n",
            "===\n",
            "start before shifting:  3889\n",
            "9\n",
            "start:  3880\n",
            "server: у\n",
            "===\n",
            "start before shifting:  4022\n",
            "9\n",
            "start:  4013\n",
            "просматривать ста\n",
            "===\n",
            "start before shifting:  4066\n",
            "9\n",
            "start:  4057\n",
            "рять логи, а также управлять пай\n",
            "===\n",
            "start before shifting:  4298\n",
            "9\n",
            "start:  4289\n",
            "ответст\n",
            "===\n",
            "start before shifting:  5213\n",
            "9\n",
            "start:  5204\n",
            "ерах. Дл\n",
            "===\n",
            "======\n",
            "text_737018.txt\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "Slov\n",
            "===\n",
            "start before shifting:  10\n",
            "2\n",
            "start:  8\n",
            "и русский жестовый язы\n",
            "===\n",
            "start before shifting:  13\n",
            "2\n",
            "start:  11\n",
            "усский жесто\n",
            "===\n",
            "start before shifting:  27\n",
            "2\n",
            "start:  25\n",
            "й яз\n",
            "===\n",
            "start before shifting:  30\n",
            "2\n",
            "start:  28\n",
            "зык / Habr\n",
            "\n",
            "\n",
            "               Slovo и рус\n",
            "===\n",
            "start before shifting:  37\n",
            "2\n",
            "start:  35\n",
            "abr\n",
            "\n",
            "\n",
            "               \n",
            "===\n",
            "start before shifting:  44\n",
            "5\n",
            "start:  39\n",
            "\n",
            "\n",
            "               Slovo и \n",
            "===\n",
            "start before shifting:  56\n",
            "5\n",
            "start:  51\n",
            "     S\n",
            "===\n",
            "start before shifting:  59\n",
            "5\n",
            "start:  54\n",
            "  Slovo и русский ж\n",
            "===\n",
            "start before shifting:  64\n",
            "5\n",
            "start:  59\n",
            "vo и русский жестовый \n",
            "===\n",
            "start before shifting:  70\n",
            "5\n",
            "start:  65\n",
            "усск\n",
            "===\n",
            "start before shifting:  79\n",
            "5\n",
            "start:  74\n",
            "стовый язык \n",
            "===\n",
            "start before shifting:  81\n",
            "5\n",
            "start:  76\n",
            "овый\n",
            "===\n",
            "start before shifting:  92\n",
            "5\n",
            "start:  87\n",
            "evel of difficulty  \n",
            "    Medium\n",
            "  \n",
            "===\n",
            "start before shifting:  105\n",
            "5\n",
            "start:  100\n",
            "culty  \n",
            " \n",
            "===\n",
            "start before shifting:  458\n",
            "9\n",
            "start:  449\n",
            "ивер\n",
            "===\n",
            "start before shifting:  938\n",
            "9\n",
            "start:  929\n",
            "аспознавание жестового языка. Часть д\n",
            "===\n",
            "start before shifting:  2168\n",
            "9\n",
            "start:  2159\n",
            " обр\n",
            "===\n",
            "start before shifting:  2398\n",
            "9\n",
            "start:  2389\n",
            "ельно\n",
            "===\n",
            "start before shifting:  2876\n",
            "9\n",
            "start:  2867\n",
            "твенных\n",
            "===\n",
            "start before shifting:  2949\n",
            "9\n",
            "start:  2940\n",
            "ания. Подобные и некоторые дру\n",
            "===\n",
            "start before shifting:  3156\n",
            "9\n",
            "start:  3147\n",
            "языке с\n",
            "===\n",
            "start before shifting:  3223\n",
            "9\n",
            "start:  3214\n",
            "бучения\n",
            "===\n",
            "start before shifting:  3558\n",
            "9\n",
            "start:  3549\n",
            "вита ж\n",
            "===\n",
            "start before shifting:  4379\n",
            "9\n",
            "start:  4370\n",
            "ждое\n",
            "===\n",
            "start before shifting:  5170\n",
            "9\n",
            "start:  5161\n",
            "выборк\n",
            "===\n",
            "start before shifting:  5451\n",
            "9\n",
            "start:  5442\n",
            "ду о\n",
            "===\n",
            "start before shifting:  5510\n",
            "9\n",
            "start:  5501\n",
            "е по юзерам, н\n",
            "===\n",
            "start before shifting:  5577\n",
            "9\n",
            "start:  5568\n",
            "орка была макси\n",
            "===\n",
            "start before shifting:  6520\n",
            "9\n",
            "start:  6511\n",
            " пер\n",
            "===\n",
            "start before shifting:  6970\n",
            "9\n",
            "start:  6961\n",
            "етчи\n",
            "===\n",
            "start before shifting:  7132\n",
            "9\n",
            "start:  7123\n",
            "ории\n",
            "===\n",
            "start before shifting:  7495\n",
            "9\n",
            "start:  7486\n",
            "учас\n",
            "===\n",
            "start before shifting:  7816\n",
            "9\n",
            "start:  7807\n",
            "был \n",
            "===\n",
            "start before shifting:  8068\n",
            "9\n",
            "start:  8059\n",
            "нтерес \n",
            "===\n",
            "start before shifting:  8139\n",
            "9\n",
            "start:  8130\n",
            "рошл\n",
            "===\n",
            "start before shifting:  10437\n",
            "9\n",
            "start:  10428\n",
            "ик д\n",
            "===\n",
            "start before shifting:  10984\n",
            "9\n",
            "start:  10975\n",
            "оверяли ка\n",
            "===\n",
            "start before shifting:  11076\n",
            "9\n",
            "start:  11067\n",
            "если процент пра\n",
            "===\n",
            "start before shifting:  11889\n",
            "9\n",
            "start:  11880\n",
            "представлен примерны\n",
            "===\n",
            "start before shifting:  11956\n",
            "9\n",
            "start:  11947\n",
            "от N = 3 \n",
            "===\n",
            "start before shifting:  11987\n",
            "9\n",
            "start:  11978\n",
            " на группы начало \n",
            "===\n",
            "start before shifting:  12229\n",
            "9\n",
            "start:  12220\n",
            "удалось агр\n",
            "===\n",
            "start before shifting:  12242\n",
            "9\n",
            "start:  12233\n",
            "ировать то\n",
            "===\n",
            "start before shifting:  12351\n",
            "9\n",
            "start:  12342\n",
            "е размечены \n",
            "===\n",
            "start before shifting:  12384\n",
            "9\n",
            "start:  12375\n",
            " повысить к\n",
            "===\n",
            "start before shifting:  12411\n",
            "9\n",
            "start:  12402\n",
            "вания жестово\n",
            "===\n",
            "start before shifting:  12435\n",
            "9\n",
            "start:  12426\n",
            "утем добав\n",
            "===\n",
            "start before shifting:  13140\n",
            "9\n",
            "start:  13131\n",
            "ы обучили ряд \n",
            "===\n",
            "start before shifting:  13219\n",
            "9\n",
            "start:  13210\n",
            " подходе с V\n",
            "===\n",
            "start before shifting:  13233\n",
            "9\n",
            "start:  13224\n",
            "ual Transfo\n",
            "===\n",
            "start before shifting:  13256\n",
            "9\n",
            "start:  13247\n",
            "арительно\n",
            "===\n",
            "start before shifting:  13386\n",
            "9\n",
            "start:  13377\n",
            "емени\n",
            "===\n",
            "start before shifting:  13393\n",
            "9\n",
            "start:  13384\n",
            "в идеале\n",
            "===\n",
            "start before shifting:  13686\n",
            "9\n",
            "start:  13677\n",
            " базе ResNet3D-50 и две тяжелые модели \n",
            "===\n",
            "start before shifting:  14190\n",
            "9\n",
            "start:  14181\n",
            "етром децимации от 1 до 4 (в случае d = \n",
            "===\n",
            "start before shifting:  14231\n",
            "9\n",
            "start:  14222\n",
            " видео не меняется). Эксперименты с d > 4 также\n",
            "===\n",
            "start before shifting:  14279\n",
            "9\n",
            "start:  14270\n",
            "показывали очень плохие метрики\n",
            "===\n",
            "start before shifting:  14326\n",
            "9\n",
            "start:  14317\n",
            "ускалось очень много к\n",
            "===\n",
            "start before shifting:  14406\n",
            "9\n",
            "start:  14397\n",
            "ке какой-либо\n",
            "===\n",
            "start before shifting:  14570\n",
            "9\n",
            "start:  14561\n",
            "0 и Swin-la\n",
            "===\n",
            "start before shifting:  14662\n",
            "9\n",
            "start:  14653\n",
            "смотреть в нашей статье.В реп\n",
            "===\n",
            "start before shifting:  14692\n",
            "9\n",
            "start:  14683\n",
            "зитории вы найдете код\n",
            "===\n",
            "start before shifting:  14797\n",
            "9\n",
            "start:  14788\n",
            "енса д\n",
            "===\n",
            "start before shifting:  15182\n",
            "9\n",
            "start:  15173\n",
            " диа\n",
            "===\n",
            "======\n",
            "text_756964.txt\n",
            "start before shifting:  62\n",
            "2\n",
            "start:  60\n",
            " новый тест Тью\n",
            "===\n",
            "start before shifting:  67\n",
            "2\n",
            "start:  65\n",
            "й тест Тьюринг\n",
            "===\n",
            "start before shifting:  68\n",
            "2\n",
            "start:  66\n",
            " тест Ть\n",
            "===\n",
            "start before shifting:  76\n",
            "2\n",
            "start:  74\n",
            "юринга\n",
            "===\n",
            "start before shifting:  126\n",
            "5\n",
            "start:  121\n",
            "поху искусственног\n",
            "===\n",
            "start before shifting:  170\n",
            "5\n",
            "start:  165\n",
            "овый тест Тьюр\n",
            "===\n",
            "start before shifting:  185\n",
            "5\n",
            "start:  180\n",
            "нга Level of d\n",
            "===\n",
            "start before shifting:  202\n",
            "5\n",
            "start:  197\n",
            "iculty  \n",
            "    \n",
            "===\n",
            "start before shifting:  211\n",
            "6\n",
            "start:  205\n",
            "\n",
            "   \n",
            "===\n",
            "start before shifting:  252\n",
            "9\n",
            "start:  243\n",
            "\n",
            "   Views\n",
            "===\n",
            "start before shifting:  273\n",
            "9\n",
            "start:  264\n",
            "ng r\n",
            "===\n",
            "start before shifting:  288\n",
            "9\n",
            "start:  279\n",
            " science Artificial Inte\n",
            "===\n",
            "start before shifting:  289\n",
            "9\n",
            "start:  280\n",
            "science Artificial Intelligence\n",
            "===\n",
            "start before shifting:  330\n",
            "12\n",
            "start:  318\n",
            "Opin\n",
            "===\n",
            "start before shifting:  350\n",
            "13\n",
            "start:  337\n",
            "nslation\n",
            " \n",
            "===\n",
            "start before shifting:  365\n",
            "14\n",
            "start:  351\n",
            "\n",
            "   \n",
            "===\n",
            "start before shifting:  365\n",
            "14\n",
            "start:  351\n",
            "\n",
            "   \n",
            "===\n",
            "start before shifting:  365\n",
            "14\n",
            "start:  351\n",
            "\n",
            "   \n",
            "===\n",
            "start before shifting:  371\n",
            "14\n",
            "start:  357\n",
            "     \n",
            "===\n",
            "start before shifting:  378\n",
            "14\n",
            "start:  364\n",
            "    Original author:\n",
            "  \n",
            "===\n",
            "start before shifting:  379\n",
            "14\n",
            "start:  365\n",
            "   Original au\n",
            "===\n",
            "start before shifting:  394\n",
            "15\n",
            "start:  379\n",
            "thor:\n",
            "  \n",
            "===\n",
            "start before shifting:  418\n",
            "16\n",
            "start:  402\n",
            "     \n",
            "===\n",
            "start before shifting:  507\n",
            "17\n",
            "start:  490\n",
            " принял \n",
            "===\n",
            "start before shifting:  546\n",
            "17\n",
            "start:  529\n",
            "ятия\n",
            "===\n",
            "start before shifting:  669\n",
            "17\n",
            "start:  652\n",
            "огим\n",
            "===\n",
            "start before shifting:  746\n",
            "17\n",
            "start:  729\n",
            " раб\n",
            "===\n",
            "start before shifting:  1086\n",
            "17\n",
            "start:  1069\n",
            "И называю\n",
            "===\n",
            "start before shifting:  1349\n",
            "17\n",
            "start:  1332\n",
            "ватель, пожав п\n",
            "===\n",
            "start before shifting:  1456\n",
            "17\n",
            "start:  1439\n",
            "ть себя \n",
            "===\n",
            "start before shifting:  1482\n",
            "17\n",
            "start:  1465\n",
            "о с того\n",
            "===\n",
            "start before shifting:  1829\n",
            "17\n",
            "start:  1812\n",
            "йчас тест уже кажется немного \n",
            "===\n",
            "start before shifting:  2026\n",
            "17\n",
            "start:  2009\n",
            "ации, ос\n",
            "===\n",
            "start before shifting:  2208\n",
            "17\n",
            "start:  2191\n",
            "венн\n",
            "===\n",
            "start before shifting:  2854\n",
            "17\n",
            "start:  2837\n",
            "ии т\n",
            "===\n",
            "start before shifting:  2950\n",
            "17\n",
            "start:  2933\n",
            "моуб\n",
            "===\n",
            "start before shifting:  3034\n",
            "17\n",
            "start:  3017\n",
            "сните, ч\n",
            "===\n",
            "start before shifting:  3346\n",
            "17\n",
            "start:  3329\n",
            "искусств\n",
            "===\n",
            "start before shifting:  3870\n",
            "17\n",
            "start:  3853\n",
            "задачи п\n",
            "===\n",
            "start before shifting:  4302\n",
            "17\n",
            "start:  4285\n",
            "нитивно-\n",
            "===\n",
            "start before shifting:  5113\n",
            "17\n",
            "start:  5096\n",
            "нок \n",
            "===\n",
            "start before shifting:  5269\n",
            "17\n",
            "start:  5252\n",
            "Тьюр\n",
            "===\n",
            "start before shifting:  5381\n",
            "17\n",
            "start:  5364\n",
            "сцене п\n",
            "===\n",
            "start before shifting:  5414\n",
            "17\n",
            "start:  5397\n",
            " мирово\n",
            "===\n",
            "start before shifting:  5421\n",
            "17\n",
            "start:  5404\n",
            "е цуна\n",
            "===\n",
            "start before shifting:  5492\n",
            "17\n",
            "start:  5475\n",
            "убокого \n",
            "===\n",
            "start before shifting:  5537\n",
            "17\n",
            "start:  5520\n",
            "потенц\n",
            "===\n",
            "start before shifting:  5632\n",
            "17\n",
            "start:  5615\n",
            "та, та\n",
            "===\n",
            "start before shifting:  5642\n",
            "17\n",
            "start:  5625\n",
            "как я (а\n",
            "===\n",
            "start before shifting:  5793\n",
            "17\n",
            "start:  5776\n",
            " что опе\n",
            "===\n",
            "start before shifting:  6386\n",
            "17\n",
            "start:  6369\n",
            "монстрирует \n",
            "===\n",
            "======\n",
            "text_759210.txt\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "LLaM\n",
            "===\n",
            "start before shifting:  5\n",
            "2\n",
            "start:  3\n",
            "LaMa vs Gi\n",
            "===\n",
            "start before shifting:  11\n",
            "2\n",
            "start:  9\n",
            "s GigaCha\n",
            "===\n",
            "start before shifting:  23\n",
            "2\n",
            "start:  21\n",
            "может ли \n",
            "===\n",
            "start before shifting:  45\n",
            "2\n",
            "start:  43\n",
            "одель рабо\n",
            "===\n",
            "start before shifting:  50\n",
            "2\n",
            "start:  48\n",
            " работа\n",
            "===\n",
            "start before shifting:  59\n",
            "2\n",
            "start:  57\n",
            " лучше LLM с \n",
            "===\n",
            "start before shifting:  64\n",
            "2\n",
            "start:  62\n",
            "е LL\n",
            "===\n",
            "start before shifting:  80\n",
            "2\n",
            "start:  78\n",
            "параме\n",
            "===\n",
            "start before shifting:  83\n",
            "2\n",
            "start:  81\n",
            "аметрами? / Habr\n",
            "\n",
            "===\n",
            "start before shifting:  94\n",
            "2\n",
            "start:  92\n",
            " Habr\n",
            "\n",
            "\n",
            "         \n",
            "===\n",
            "start before shifting:  113\n",
            "5\n",
            "start:  108\n",
            "        LLa\n",
            "===\n",
            "start before shifting:  116\n",
            "5\n",
            "start:  111\n",
            "     L\n",
            "===\n",
            "start before shifting:  125\n",
            "5\n",
            "start:  120\n",
            "a vs Giga\n",
            "===\n",
            "start before shifting:  157\n",
            "5\n",
            "start:  152\n",
            "ная модел\n",
            "===\n",
            "start before shifting:  161\n",
            "5\n",
            "start:  156\n",
            "мод\n",
            "===\n",
            "start before shifting:  176\n",
            "5\n",
            "start:  171\n",
            " лучше \n",
            "===\n",
            "start before shifting:  178\n",
            "5\n",
            "start:  173\n",
            "учше\n",
            "===\n",
            "start before shifting:  192\n",
            "5\n",
            "start:  187\n",
            "млрд п\n",
            "===\n",
            "start before shifting:  195\n",
            "5\n",
            "start:  190\n",
            "д пар\n",
            "===\n",
            "start before shifting:  204\n",
            "5\n",
            "start:  199\n",
            "рами? \n",
            "===\n",
            "start before shifting:  213\n",
            "5\n",
            "start:  208\n",
            "ading\n",
            "===\n",
            "start before shifting:  219\n",
            "5\n",
            "start:  214\n",
            "time  \n",
            "    9 min\n",
            "   Views  6.4K \n",
            "===\n",
            "start before shifting:  237\n",
            "7\n",
            "start:  230\n",
            "\n",
            "   Views\n",
            "===\n",
            "start before shifting:  254\n",
            "7\n",
            "start:  247\n",
            "ТС corpor\n",
            "===\n",
            "start before shifting:  275\n",
            "7\n",
            "start:  268\n",
            " AI co\n",
            "===\n",
            "start before shifting:  287\n",
            "7\n",
            "start:  280\n",
            "e blog Machine le\n",
            "===\n",
            "start before shifting:  305\n",
            "7\n",
            "start:  298\n",
            "rning *Artificial Intell\n",
            "===\n",
            "start before shifting:  309\n",
            "7\n",
            "start:  302\n",
            "g *Artifi\n",
            "===\n",
            "start before shifting:  310\n",
            "7\n",
            "start:  303\n",
            " *Art\n",
            "===\n",
            "start before shifting:  323\n",
            "7\n",
            "start:  316\n",
            "Intellige\n",
            "===\n",
            "start before shifting:  329\n",
            "7\n",
            "start:  322\n",
            "igence Natural Language Proc\n",
            "===\n",
            "start before shifting:  354\n",
            "7\n",
            "start:  347\n",
            "rocess\n",
            "===\n",
            "start before shifting:  355\n",
            "7\n",
            "start:  348\n",
            "ocessi\n",
            "===\n",
            "start before shifting:  370\n",
            "7\n",
            "start:  363\n",
            " Всем при\n",
            "===\n",
            "start before shifting:  393\n",
            "7\n",
            "start:  386\n",
            "т Алан, я раз\n",
            "===\n",
            "start before shifting:  414\n",
            "7\n",
            "start:  407\n",
            "-исс\n",
            "===\n",
            "start before shifting:  421\n",
            "7\n",
            "start:  414\n",
            "овател\n",
            "===\n",
            "start before shifting:  424\n",
            "7\n",
            "start:  417\n",
            "тель в \n",
            "===\n",
            "start before shifting:  442\n",
            "7\n",
            "start:  435\n",
            "сейчас\n",
            "===\n",
            "start before shifting:  443\n",
            "7\n",
            "start:  436\n",
            "ейчас \n",
            "===\n",
            "start before shifting:  458\n",
            "7\n",
            "start:  451\n",
            "зуча\n",
            "===\n",
            "start before shifting:  475\n",
            "7\n",
            "start:  468\n",
            "руя их\n",
            "===\n",
            "start before shifting:  476\n",
            "7\n",
            "start:  469\n",
            "уя их воз\n",
            "===\n",
            "start before shifting:  515\n",
            "7\n",
            "start:  508\n",
            "Росси\n",
            "===\n",
            "start before shifting:  553\n",
            "7\n",
            "start:  546\n",
            "ыковых м\n",
            "===\n",
            "start before shifting:  574\n",
            "7\n",
            "start:  567\n",
            " числе Gi\n",
            "===\n",
            "start before shifting:  585\n",
            "7\n",
            "start:  578\n",
            "Chat и Yan\n",
            "===\n",
            "start before shifting:  600\n",
            "7\n",
            "start:  593\n",
            "T, кот\n",
            "===\n",
            "start before shifting:  627\n",
            "7\n",
            "start:  620\n",
            " текстовые задачи\n",
            "===\n",
            "start before shifting:  646\n",
            "7\n",
            "start:  639\n",
            "В этой статье показывается, что язык\n",
            "===\n",
            "start before shifting:  671\n",
            "7\n",
            "start:  664\n",
            "я, что языковая \n",
            "===\n",
            "start before shifting:  796\n",
            "7\n",
            "start:  789\n",
            " в некотор\n",
            "===\n",
            "start before shifting:  818\n",
            "7\n",
            "start:  811\n",
            " лучшую\n",
            "===\n",
            "start before shifting:  857\n",
            "7\n",
            "start:  850\n",
            " больших коммерче\n",
            "===\n",
            "start before shifting:  874\n",
            "7\n",
            "start:  867\n",
            "ских решений. На небольш\n",
            "===\n",
            "start before shifting:  877\n",
            "7\n",
            "start:  870\n",
            "х реш\n",
            "===\n",
            "start before shifting:  895\n",
            "7\n",
            "start:  888\n",
            "льшом количестве примеров мы\n",
            "===\n",
            "start before shifting:  922\n",
            "7\n",
            "start:  915\n",
            "ы пров\n",
            "===\n",
            "start before shifting:  923\n",
            "7\n",
            "start:  916\n",
            " про\n",
            "===\n",
            "start before shifting:  950\n",
            "7\n",
            "start:  943\n",
            "ей решать простые математ\n",
            "===\n",
            "start before shifting:  953\n",
            "7\n",
            "start:  946\n",
            "решать простые математические \n",
            "===\n",
            "start before shifting:  984\n",
            "7\n",
            "start:  977\n",
            "адачи, отвечать на вопрос по заданному кон\n",
            "===\n",
            "start before shifting:  991\n",
            "7\n",
            "start:  984\n",
            "отвечать\n",
            "===\n",
            "start before shifting:  1006\n",
            "7\n",
            "start:  999\n",
            "рос по\n",
            "===\n",
            "start before shifting:  1025\n",
            "7\n",
            "start:  1018\n",
            "нтексту, \n",
            "===\n",
            "start before shifting:  1043\n",
            "7\n",
            "start:  1036\n",
            " содержа\n",
            "===\n",
            "start before shifting:  1086\n",
            "7\n",
            "start:  1079\n",
            "овые инстр\n",
            "===\n",
            "start before shifting:  1240\n",
            "8\n",
            "start:  1232\n",
            " версия L\n",
            "===\n",
            "start before shifting:  1245\n",
            "8\n",
            "start:  1237\n",
            "ия LLaMa-7\n",
            "===\n",
            "start before shifting:  1276\n",
            "8\n",
            "start:  1268\n",
            "на набор\n",
            "===\n",
            "start before shifting:  1285\n",
            "8\n",
            "start:  1277\n",
            " данных IlyaGusev/ru_turb\n",
            "===\n",
            "start before shifting:  1331\n",
            "8\n",
            "start:  1323\n",
            "примера\n",
            "===\n",
            "start before shifting:  1349\n",
            "8\n",
            "start:  1341\n",
            " магазине\n",
            "===\n",
            "start before shifting:  1371\n",
            "8\n",
            "start:  1363\n",
            "сть сл\n",
            "===\n",
            "start before shifting:  1569\n",
            "8\n",
            "start:  1561\n",
            "равится ru\n",
            "===\n",
            "start before shifting:  1607\n",
            "8\n",
            "start:  1599\n",
            "quad. У G\n",
            "===\n",
            "start before shifting:  1655\n",
            "8\n",
            "start:  1647\n",
            "терфейс G\n",
            "===\n",
            "======\n",
            "text_747488.txt\n",
            "start before shifting:  21\n",
            "2\n",
            "start:  19\n",
            "И убивает стары\n",
            "===\n",
            "start before shifting:  29\n",
            "2\n",
            "start:  27\n",
            "т старый и\n",
            "===\n",
            "start before shifting:  32\n",
            "2\n",
            "start:  30\n",
            "тарый интернет.\n",
            "===\n",
            "start before shifting:  37\n",
            "2\n",
            "start:  35\n",
            " интернет. Но новы\n",
            "===\n",
            "start before shifting:  68\n",
            "2\n",
            "start:  66\n",
            "ь хуже /\n",
            "===\n",
            "start before shifting:  79\n",
            "2\n",
            "start:  77\n",
            "br\n",
            "\n",
            "\n",
            "               На\n",
            "===\n",
            "start before shifting:  105\n",
            "5\n",
            "start:  100\n",
            "наших г\n",
            "===\n",
            "start before shifting:  110\n",
            "5\n",
            "start:  105\n",
            " глазах\n",
            "===\n",
            "start before shifting:  116\n",
            "5\n",
            "start:  111\n",
            "х ИИ у\n",
            "===\n",
            "start before shifting:  143\n",
            "5\n",
            "start:  138\n",
            "т. Но нов\n",
            "===\n",
            "start before shifting:  153\n",
            "5\n",
            "start:  148\n",
            "й обещае\n",
            "===\n",
            "start before shifting:  163\n",
            "5\n",
            "start:  158\n",
            "быть хуж\n",
            "===\n",
            "start before shifting:  167\n",
            "5\n",
            "start:  162\n",
            " хуже  R\n",
            "===\n",
            "start before shifting:  215\n",
            "7\n",
            "start:  208\n",
            " ГК I\n",
            "===\n",
            "start before shifting:  257\n",
            "7\n",
            "start:  250\n",
            " Intell\n",
            "===\n",
            "start before shifting:  268\n",
            "7\n",
            "start:  261\n",
            "ce The \n",
            "===\n",
            "start before shifting:  285\n",
            "7\n",
            "start:  278\n",
            "here I\n",
            "===\n",
            "start before shifting:  325\n",
            "8\n",
            "start:  317\n",
            "ели в Ин\n",
            "===\n",
            "start before shifting:  335\n",
            "8\n",
            "start:  327\n",
            "рнете в \n",
            "===\n",
            "start before shifting:  350\n",
            "8\n",
            "start:  342\n",
            "ий год, то могли зам\n",
            "===\n",
            "start before shifting:  384\n",
            "8\n",
            "start:  376\n",
            "быстро меняется. И\n",
            "===\n",
            "start before shifting:  389\n",
            "8\n",
            "start:  381\n",
            "о меня\n",
            "===\n",
            "start before shifting:  393\n",
            "8\n",
            "start:  385\n",
            "няется. И этот сн\n",
            "===\n",
            "start before shifting:  405\n",
            "8\n",
            "start:  397\n",
            "от снежный ком лети\n",
            "===\n",
            "start before shifting:  419\n",
            "8\n",
            "start:  411\n",
            " летит с \n",
            "===\n",
            "start before shifting:  428\n",
            "8\n",
            "start:  420\n",
            "горы с возрастающей скоростью. Goo\n",
            "===\n",
            "start before shifting:  442\n",
            "8\n",
            "start:  434\n",
            "ающей с\n",
            "===\n",
            "start before shifting:  446\n",
            "8\n",
            "start:  438\n",
            "й скорость\n",
            "===\n",
            "start before shifting:  450\n",
            "8\n",
            "start:  442\n",
            "оростью. Google\n",
            "===\n",
            "start before shifting:  451\n",
            "8\n",
            "start:  443\n",
            "ростью.\n",
            "===\n",
            "start before shifting:  454\n",
            "8\n",
            "start:  446\n",
            "тью. \n",
            "===\n",
            "start before shifting:  494\n",
            "8\n",
            "start:  486\n",
            " 10 синих ссылок\n",
            "===\n",
            "start before shifting:  517\n",
            "8\n",
            "start:  509\n",
            "ив их в\n",
            "===\n",
            "start before shifting:  541\n",
            "8\n",
            "start:  533\n",
            "чатбо\n",
            "===\n",
            "start before shifting:  548\n",
            "8\n",
            "start:  540\n",
            " Bard). \n",
            "===\n",
            "start before shifting:  579\n",
            "8\n",
            "start:  571\n",
            "лением \n",
            "===\n",
            "start before shifting:  601\n",
            "8\n",
            "start:  593\n",
            "алочек.\n",
            "===\n",
            "start before shifting:  639\n",
            "8\n",
            "start:  631\n",
            ", котор\n",
            "===\n",
            "start before shifting:  643\n",
            "8\n",
            "start:  635\n",
            "торые сейчас д\n",
            "===\n",
            "start before shifting:  647\n",
            "8\n",
            "start:  639\n",
            "е сейчас д\n",
            "===\n",
            "start before shifting:  656\n",
            "8\n",
            "start:  648\n",
            "доминир\n",
            "===\n",
            "start before shifting:  658\n",
            "8\n",
            "start:  650\n",
            "минируют в спис\n",
            "===\n",
            "start before shifting:  684\n",
            "8\n",
            "start:  676\n",
            "еров, а\n",
            "===\n",
            "start before shifting:  785\n",
            "8\n",
            "start:  777\n",
            "пытывае\n",
            "===\n",
            "start before shifting:  789\n",
            "8\n",
            "start:  781\n",
            "вает TikTok.\n",
            "  \n",
            "===\n",
            "start before shifting:  820\n",
            "9\n",
            "start:  811\n",
            "нения з\n",
            "===\n",
            "start before shifting:  922\n",
            "9\n",
            "start:  913\n",
            "неделю».\n",
            "===\n",
            "start before shifting:  962\n",
            "9\n",
            "start:  953\n",
            "ия целых сотен с\n",
            "===\n",
            "start before shifting:  989\n",
            "9\n",
            "start:  980\n",
            " на кото\n",
            "===\n",
            "start before shifting:  998\n",
            "9\n",
            "start:  989\n",
            "ых, ничего не подозр\n",
            "===\n",
            "start before shifting:  1021\n",
            "9\n",
            "start:  1012\n",
            "я, через Go\n",
            "===\n",
            "start before shifting:  1043\n",
            "9\n",
            "start:  1034\n",
            "кламируются бре\n",
            "===\n",
            "start before shifting:  1054\n",
            "9\n",
            "start:  1045\n",
            " брен\n",
            "===\n",
            "start before shifting:  1125\n",
            "9\n",
            "start:  1116\n",
            "Чатботы цитирую\n",
            "===\n",
            "start before shifting:  1150\n",
            "9\n",
            "start:  1141\n",
            "га в как\n",
            "===\n",
            "start before shifting:  1154\n",
            "9\n",
            "start:  1145\n",
            " каком-то дезинформационном уроборо\n",
            "===\n",
            "start before shifting:  1184\n",
            "9\n",
            "start:  1175\n",
            "оборосе. \n",
            "===\n",
            "start before shifting:  1245\n",
            "9\n",
            "start:  1236\n",
            "ляции с\n",
            "===\n",
            "start before shifting:  1253\n",
            "9\n",
            "start:  1244\n",
            "общений рек\n",
            "===\n",
            "start before shifting:  1265\n",
            "9\n",
            "start:  1256\n",
            "утеро\n",
            "===\n",
            "start before shifting:  1272\n",
            "9\n",
            "start:  1263\n",
            "(чтобы создать\n",
            "===\n",
            "start before shifting:  1286\n",
            "9\n",
            "start:  1277\n",
            " пер\n",
            "===\n",
            "start before shifting:  1309\n",
            "9\n",
            "start:  1300\n",
            "общение \n",
            "===\n",
            "start before shifting:  1353\n",
            "9\n",
            "start:  1344\n",
            "ремени —\n",
            "===\n",
            "start before shifting:  1389\n",
            "9\n",
            "start:  1380\n",
            "ый спам!). Но и\n",
            "===\n",
            "start before shifting:  1415\n",
            "9\n",
            "start:  1406\n",
            " предел. \n",
            "===\n",
            "start before shifting:  1426\n",
            "9\n",
            "start:  1417\n",
            "apchat и I\n",
            "===\n",
            "start before shifting:  1444\n",
            "9\n",
            "start:  1435\n",
            " рассчитывают, что б\n",
            "===\n",
            "start before shifting:  1448\n",
            "9\n",
            "start:  1439\n",
            "считывают, что бот\n",
            "===\n",
            "start before shifting:  1451\n",
            "9\n",
            "start:  1442\n",
            "тывают, что бот\n",
            "===\n",
            "start before shifting:  1462\n",
            "9\n",
            "start:  1453\n",
            " боты с\n",
            "===\n",
            "start before shifting:  1469\n",
            "9\n",
            "start:  1460\n",
            "коро б\n",
            "===\n",
            "start before shifting:  1483\n",
            "9\n",
            "start:  1474\n",
            "говарива\n",
            "===\n",
            "start before shifting:  1490\n",
            "9\n",
            "start:  1481\n",
            "ать с вами\n",
            "===\n",
            "start before shifting:  1502\n",
            "9\n",
            "start:  1493\n",
            "когда это\n",
            "===\n",
            "start before shifting:  1512\n",
            "9\n",
            "start:  1503\n",
            "о не делают ваши \n",
            "===\n",
            "start before shifting:  1514\n",
            "9\n",
            "start:  1505\n",
            "не делают ваши \n",
            "===\n",
            "start before shifting:  1572\n",
            "9\n",
            "start:  1563\n",
            "стуют мо\n",
            "===\n",
            "start before shifting:  1574\n",
            "9\n",
            "start:  1565\n",
            "уют моды Stack \n",
            "===\n",
            "start before shifting:  1577\n",
            "9\n",
            "start:  1568\n",
            " моды \n",
            "===\n",
            "start before shifting:  1578\n",
            "9\n",
            "start:  1569\n",
            "моды Sta\n",
            "===\n",
            "start before shifting:  1700\n",
            "9\n",
            "start:  1691\n",
            "разрыва\n",
            "===\n",
            "start before shifting:  1701\n",
            "9\n",
            "start:  1692\n",
            "азрывает В\n",
            "===\n",
            "start before shifting:  1859\n",
            "10\n",
            "start:  1849\n",
            "выглядеть пои\n",
            "===\n",
            "start before shifting:  1923\n",
            "10\n",
            "start:  1913\n",
            "ти поль\n",
            "===\n",
            "======\n",
            "text_751972.txt\n",
            "start before shifting:  13\n",
            "2\n",
            "start:  11\n",
            "есконечно\n",
            "===\n",
            "start before shifting:  21\n",
            "2\n",
            "start:  19\n",
            "ое (лет\n",
            "===\n",
            "start before shifting:  27\n",
            "2\n",
            "start:  25\n",
            "то) RuGPT3.5\n",
            "===\n",
            "start before shifting:  28\n",
            "2\n",
            "start:  26\n",
            "о) RuGPT3.5: Генерация \n",
            "===\n",
            "start before shifting:  29\n",
            "2\n",
            "start:  27\n",
            ") RuGPT3.\n",
            "===\n",
            "start before shifting:  34\n",
            "2\n",
            "start:  32\n",
            "PT3.5: Генерация новеллы на ходу\n",
            "===\n",
            "start before shifting:  39\n",
            "2\n",
            "start:  37\n",
            ": Генерация новелл\n",
            "===\n",
            "start before shifting:  43\n",
            "2\n",
            "start:  41\n",
            "нерац\n",
            "===\n",
            "start before shifting:  47\n",
            "2\n",
            "start:  45\n",
            "ция новелл\n",
            "===\n",
            "start before shifting:  53\n",
            "2\n",
            "start:  51\n",
            "веллы н\n",
            "===\n",
            "start before shifting:  57\n",
            "2\n",
            "start:  55\n",
            "ы на ходу не\n",
            "===\n",
            "start before shifting:  68\n",
            "2\n",
            "start:  66\n",
            "ейросе\n",
            "===\n",
            "start before shifting:  71\n",
            "2\n",
            "start:  69\n",
            "осетью / Habr\n",
            "\n",
            "\n",
            "             \n",
            "===\n",
            "start before shifting:  72\n",
            "2\n",
            "start:  70\n",
            "сетью / H\n",
            "===\n",
            "start before shifting:  75\n",
            "2\n",
            "start:  73\n",
            "ью / \n",
            "===\n",
            "start before shifting:  127\n",
            "5\n",
            "start:  122\n",
            "ето) RuGP\n",
            "===\n",
            "start before shifting:  128\n",
            "5\n",
            "start:  123\n",
            "то) R\n",
            "===\n",
            "start before shifting:  137\n",
            "5\n",
            "start:  132\n",
            "3.5: Генерация нов\n",
            "===\n",
            "start before shifting:  175\n",
            "5\n",
            "start:  170\n",
            "тью Leve\n",
            "===\n",
            "start before shifting:  176\n",
            "5\n",
            "start:  171\n",
            "ью L\n",
            "===\n",
            "start before shifting:  195\n",
            "5\n",
            "start:  190\n",
            "lty  \n",
            "    \n",
            "===\n",
            "start before shifting:  197\n",
            "6\n",
            "start:  191\n",
            "ty  \n",
            "  \n",
            "===\n",
            "start before shifting:  205\n",
            "6\n",
            "start:  199\n",
            " Medium\n",
            "   R\n",
            "===\n",
            "start before shifting:  239\n",
            "9\n",
            "start:  230\n",
            "4 min\n",
            "   Views  17K Pr\n",
            "===\n",
            "start before shifting:  244\n",
            "9\n",
            "start:  235\n",
            "\n",
            "   Views\n",
            "===\n",
            "start before shifting:  244\n",
            "9\n",
            "start:  235\n",
            "\n",
            "   Views  17K Pr\n",
            "===\n",
            "start before shifting:  262\n",
            "9\n",
            "start:  253\n",
            "gramming \n",
            "===\n",
            "start before shifting:  265\n",
            "9\n",
            "start:  256\n",
            "mming *\n",
            "===\n",
            "start before shifting:  274\n",
            "9\n",
            "start:  265\n",
            "chine\n",
            "===\n",
            "start before shifting:  280\n",
            "9\n",
            "start:  271\n",
            "learn\n",
            "===\n",
            "start before shifting:  281\n",
            "9\n",
            "start:  272\n",
            "earning *Artificial Inte\n",
            "===\n",
            "start before shifting:  294\n",
            "9\n",
            "start:  285\n",
            "ficial \n",
            "===\n",
            "start before shifting:  308\n",
            "9\n",
            "start:  299\n",
            "gence\n",
            "===\n",
            "start before shifting:  314\n",
            "9\n",
            "start:  305\n",
            "Games and game consoles\n",
            "===\n",
            "start before shifting:  320\n",
            "9\n",
            "start:  311\n",
            "and gam\n",
            "===\n",
            "start before shifting:  329\n",
            "9\n",
            "start:  320\n",
            "consoles Natural Language Pr\n",
            "===\n",
            "start before shifting:  338\n",
            "9\n",
            "start:  329\n",
            "Natur\n",
            "===\n",
            "start before shifting:  358\n",
            "9\n",
            "start:  349\n",
            "cessing \n",
            "===\n",
            "start before shifting:  367\n",
            "10\n",
            "start:  357\n",
            "* \n",
            "  \n",
            "===\n",
            "start before shifting:  392\n",
            "11\n",
            "start:  381\n",
            "Что э\n",
            "===\n",
            "start before shifting:  400\n",
            "11\n",
            "start:  389\n",
            "за мирова\n",
            "===\n",
            "start before shifting:  405\n",
            "11\n",
            "start:  394\n",
            "ровая линия\n",
            "===\n",
            "start before shifting:  406\n",
            "11\n",
            "start:  395\n",
            "овая линия?Я уж было п\n",
            "===\n",
            "start before shifting:  413\n",
            "11\n",
            "start:  402\n",
            "ния?Я у\n",
            "===\n",
            "start before shifting:  437\n",
            "11\n",
            "start:  426\n",
            "то эпох\n",
            "===\n",
            "start before shifting:  456\n",
            "11\n",
            "start:  445\n",
            "трансфо\n",
            "===\n",
            "start before shifting:  458\n",
            "11\n",
            "start:  447\n",
            "ансфор\n",
            "===\n",
            "start before shifting:  469\n",
            "11\n",
            "start:  458\n",
            "х нейрос\n",
            "===\n",
            "start before shifting:  484\n",
            "11\n",
            "start:  473\n",
            "ла, остав\n",
            "===\n",
            "start before shifting:  494\n",
            "11\n",
            "start:  483\n",
            "в пос\n",
            "===\n",
            "start before shifting:  524\n",
            "11\n",
            "start:  513\n",
            "е (мож\n",
            "===\n",
            "start before shifting:  531\n",
            "11\n",
            "start:  520\n",
            "о пер\n",
            "===\n",
            "start before shifting:  538\n",
            "11\n",
            "start:  527\n",
            "читать на \n",
            "===\n",
            "start before shifting:  546\n",
            "11\n",
            "start:  535\n",
            "а пальцах), однако пару н\n",
            "===\n",
            "start before shifting:  549\n",
            "11\n",
            "start:  538\n",
            "альцах), \n",
            "===\n",
            "start before shifting:  555\n",
            "11\n",
            "start:  544\n",
            "), о\n",
            "===\n",
            "start before shifting:  559\n",
            "11\n",
            "start:  548\n",
            "днако п\n",
            "===\n",
            "start before shifting:  563\n",
            "11\n",
            "start:  552\n",
            "о пару недель назад \n",
            "===\n",
            "start before shifting:  572\n",
            "11\n",
            "start:  561\n",
            "дель наза\n",
            "===\n",
            "start before shifting:  584\n",
            "11\n",
            "start:  573\n",
            "uGPT3.\n",
            "===\n",
            "start before shifting:  592\n",
            "11\n",
            "start:  581\n",
            "от Сбера \n",
            "===\n",
            "start before shifting:  622\n",
            "11\n",
            "start:  611\n",
            "уп и,\n",
            "===\n",
            "start before shifting:  659\n",
            "11\n",
            "start:  648\n",
            "ых моделей дл\n",
            "===\n",
            "start before shifting:  664\n",
            "11\n",
            "start:  653\n",
            "делей д\n",
            "===\n",
            "start before shifting:  668\n",
            "11\n",
            "start:  657\n",
            "й для рус\n",
            "===\n",
            "start before shifting:  670\n",
            "11\n",
            "start:  659\n",
            "для \n",
            "===\n",
            "start before shifting:  704\n",
            "11\n",
            "start:  693\n",
            " удачн\n",
            "===\n",
            "start before shifting:  711\n",
            "11\n",
            "start:  700\n",
            "м шан\n",
            "===\n",
            "start before shifting:  722\n",
            "11\n",
            "start:  711\n",
            "я реа\n",
            "===\n",
            "start before shifting:  765\n",
            "12\n",
            "start:  753\n",
            "ние\n",
            "        З\n",
            "===\n",
            "start before shifting:  781\n",
            "12\n",
            "start:  769\n",
            "омство с моделью\n",
            "===\n",
            "start before shifting:  784\n",
            "12\n",
            "start:  772\n",
            "тво с мо\n",
            "===\n",
            "======\n",
            "text_758406.txt\n",
            "start before shifting:  31\n",
            "2\n",
            "start:  29\n",
            "ейросети C\n",
            "===\n",
            "start before shifting:  38\n",
            "2\n",
            "start:  36\n",
            "и ChatGP\n",
            "===\n",
            "start before shifting:  40\n",
            "2\n",
            "start:  38\n",
            "ChatGPT / Hab\n",
            "===\n",
            "start before shifting:  58\n",
            "5\n",
            "start:  53\n",
            "\n",
            "\n",
            "            \n",
            "===\n",
            "start before shifting:  78\n",
            "5\n",
            "start:  73\n",
            "еревел книгу с помощью нейросети Chat\n",
            "===\n",
            "start before shifting:  106\n",
            "5\n",
            "start:  101\n",
            "сети Cha\n",
            "===\n",
            "start before shifting:  117\n",
            "5\n",
            "start:  112\n",
            "T Level of \n",
            "===\n",
            "start before shifting:  249\n",
            "9\n",
            "start:  240\n",
            "Learning langu\n",
            "===\n",
            "start before shifting:  269\n",
            "10\n",
            "start:  259\n",
            "  \n",
            "    From sandbox\n",
            "    \n",
            "===\n",
            "start before shifting:  412\n",
            "11\n",
            "start:  401\n",
            "Упоминан\n",
            "===\n",
            "start before shifting:  1186\n",
            "11\n",
            "start:  1175\n",
            "подготов\n",
            "===\n",
            "start before shifting:  1278\n",
            "11\n",
            "start:  1267\n",
            "еловеком и \n",
            "===\n",
            "start before shifting:  1292\n",
            "11\n",
            "start:  1281\n",
            "усственны\n",
            "===\n",
            "start before shifting:  1631\n",
            "11\n",
            "start:  1620\n",
            "дение Ко\n",
            "===\n",
            "start before shifting:  2337\n",
            "11\n",
            "start:  2326\n",
            "в, с кот\n",
            "===\n",
            "start before shifting:  2751\n",
            "11\n",
            "start:  2740\n",
            "хударову\n",
            "===\n",
            "start before shifting:  2768\n",
            "11\n",
            "start:  2757\n",
            "оцесс преобразования речевого произвед\n",
            "===\n",
            "start before shifting:  3041\n",
            "11\n",
            "start:  3030\n",
            "айте пог\n",
            "===\n",
            "start before shifting:  3245\n",
            "11\n",
            "start:  3234\n",
            "усской\n",
            "===\n",
            "start before shifting:  3720\n",
            "11\n",
            "start:  3709\n",
            "итывает \n",
            "===\n",
            "start before shifting:  4103\n",
            "11\n",
            "start:  4092\n",
            "а над кото\n",
            "===\n",
            "start before shifting:  4138\n",
            "11\n",
            "start:  4127\n",
            "щью нейросети (ChatGPT). За т\n",
            "===\n",
            "start before shifting:  4320\n",
            "11\n",
            "start:  4309\n",
            "время от вр\n",
            "===\n",
            "start before shifting:  4565\n",
            "11\n",
            "start:  4554\n",
            "вной травмой колена в\n",
            "===\n",
            "start before shifting:  4715\n",
            "11\n",
            "start:  4704\n",
            " путь реабилит\n",
            "===\n",
            "start before shifting:  5063\n",
            "11\n",
            "start:  5052\n",
            "ржится п\n",
            "===\n",
            "start before shifting:  5920\n",
            "11\n",
            "start:  5909\n",
            " 100% точный перевод, так как в не\n",
            "===\n",
            "start before shifting:  6005\n",
            "11\n",
            "start:  5994\n",
            "еточнос\n",
            "===\n",
            "start before shifting:  6329\n",
            "11\n",
            "start:  6318\n",
            "азом переда\n",
            "===\n",
            "start before shifting:  6355\n",
            "11\n",
            "start:  6344\n",
            "льное выражение и\n",
            "===\n",
            "start before shifting:  6403\n",
            "11\n",
            "start:  6392\n",
            "ика заклю\n",
            "===\n",
            "start before shifting:  6587\n",
            "11\n",
            "start:  6576\n",
            "тог, можно сказать, что я использовал нейросеть для того, чтобы об\n",
            "===\n",
            "start before shifting:  6713\n",
            "11\n",
            "start:  6702\n",
            "средоточит\n",
            "===\n",
            "start before shifting:  7080\n",
            "11\n",
            "start:  7069\n",
            "ольшой о\n",
            "===\n",
            "start before shifting:  7342\n",
            "11\n",
            "start:  7331\n",
            "о передавать\n",
            "===\n",
            "start before shifting:  7364\n",
            "11\n",
            "start:  7353\n",
            " предложений, тон и стиль автора. Это позволяет сохранить ори\n",
            "===\n",
            "start before shifting:  7640\n",
            "11\n",
            "start:  7629\n",
            "очно подбирать соответствующие слова \n",
            "===\n",
            "start before shifting:  8484\n",
            "11\n",
            "start:  8473\n",
            "меет реша\n",
            "===\n",
            "start before shifting:  8517\n",
            "11\n",
            "start:  8506\n",
            " и тот же термин будет переведен по\n",
            "===\n",
            "start before shifting:  9067\n",
            "11\n",
            "start:  9056\n",
            " по слож\n",
            "===\n",
            "start before shifting:  9077\n",
            "11\n",
            "start:  9066\n",
            "сти задачей с\n",
            "===\n",
            "start before shifting:  9123\n",
            "11\n",
            "start:  9112\n",
            "ейросеть\n",
            "===\n",
            "start before shifting:  9171\n",
            "11\n",
            "start:  9160\n",
            "нов. Гово\n",
            "===\n",
            "start before shifting:  9229\n",
            "11\n",
            "start:  9218\n",
            "века, нейросе\n",
            "===\n",
            "start before shifting:  9262\n",
            "11\n",
            "start:  9251\n",
            " между связкой и сухо\n",
            "===\n",
            "start before shifting:  9288\n",
            "11\n",
            "start:  9277\n",
            "м, ягодично\n",
            "===\n",
            "start before shifting:  9301\n",
            "11\n",
            "start:  9290\n",
            "мышцей и му\n",
            "===\n",
            "start before shifting:  9521\n",
            "11\n",
            "start:  9510\n",
            "о перепроверить его, по\n",
            "===\n",
            "start before shifting:  9545\n",
            "11\n",
            "start:  9534\n",
            "ьзуясь д\n",
            "===\n",
            "start before shifting:  10409\n",
            "11\n",
            "start:  10398\n",
            "d Hip Air\n",
            "===\n",
            "start before shifting:  10727\n",
            "11\n",
            "start:  10716\n",
            " атлетов н\n",
            "===\n",
            "start before shifting:  15041\n",
            "11\n",
            "start:  15030\n",
            "pain \n",
            "===\n",
            "start before shifting:  15047\n",
            "11\n",
            "start:  15036\n",
            "hrough a neur\n",
            "===\n",
            "start before shifting:  15061\n",
            "11\n",
            "start:  15050\n",
            "logic overreactio\n",
            "===\n",
            "start before shifting:  16046\n",
            "11\n",
            "start:  16035\n",
            " плане того, что на текущий мо\n",
            "===\n",
            "start before shifting:  17021\n",
            "11\n",
            "start:  17010\n",
            "екта, я пришел к \n",
            "===\n",
            "start before shifting:  17147\n",
            "11\n",
            "start:  17136\n",
            "ючевое\n",
            "===\n",
            "start before shifting:  17165\n",
            "11\n",
            "start:  17154\n",
            "я достижения наил\n",
            "===\n",
            "start before shifting:  17256\n",
            "11\n",
            "start:  17245\n",
            "искусств\n",
            "===\n",
            "start before shifting:  17284\n",
            "11\n",
            "start:  17273\n",
            "процесс\n",
            "===\n",
            "start before shifting:  17284\n",
            "11\n",
            "start:  17273\n",
            "процессе перевод\n",
            "===\n",
            "start before shifting:  17304\n",
            "11\n",
            "start:  17293\n",
            "ециали\n",
            "===\n",
            "start before shifting:  17332\n",
            "11\n",
            "start:  17321\n",
            "лючает\n",
            "===\n",
            "start before shifting:  17389\n",
            "11\n",
            "start:  17378\n",
            "е спос\n",
            "===\n",
            "start before shifting:  17419\n",
            "11\n",
            "start:  17408\n",
            "е в сово\n",
            "===\n",
            "start before shifting:  17463\n",
            "11\n",
            "start:  17452\n",
            "во и точн\n",
            "===\n",
            "start before shifting:  17551\n",
            "11\n",
            "start:  17540\n",
            "кого знания т\n",
            "===\n",
            "start before shifting:  17588\n",
            "11\n",
            "start:  17577\n",
            "вых нюансов, \n",
            "===\n",
            "======\n",
            "text_418701.txt\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "Изуча\n",
            "===\n",
            "start before shifting:  8\n",
            "2\n",
            "start:  6\n",
            "аем си\n",
            "===\n",
            "start before shifting:  9\n",
            "2\n",
            "start:  7\n",
            "ем синтаксическ\n",
            "===\n",
            "start before shifting:  9\n",
            "2\n",
            "start:  7\n",
            "ем синтакс\n",
            "===\n",
            "start before shifting:  10\n",
            "2\n",
            "start:  8\n",
            "м синтаксические парсер\n",
            "===\n",
            "start before shifting:  18\n",
            "2\n",
            "start:  16\n",
            "сические парс\n",
            "===\n",
            "start before shifting:  20\n",
            "2\n",
            "start:  18\n",
            "ческие пар\n",
            "===\n",
            "start before shifting:  37\n",
            "2\n",
            "start:  35\n",
            "я русского язык\n",
            "===\n",
            "start before shifting:  39\n",
            "2\n",
            "start:  37\n",
            "русског\n",
            "===\n",
            "start before shifting:  41\n",
            "2\n",
            "start:  39\n",
            "сского язы\n",
            "===\n",
            "start before shifting:  42\n",
            "2\n",
            "start:  40\n",
            "ского язы\n",
            "===\n",
            "start before shifting:  58\n",
            "2\n",
            "start:  56\n",
            "br\n",
            "\n",
            "\n",
            "     \n",
            "===\n",
            "start before shifting:  76\n",
            "5\n",
            "start:  71\n",
            "     9  Au\n",
            "===\n",
            "start before shifting:  77\n",
            "5\n",
            "start:  72\n",
            "    9  \n",
            "===\n",
            "start before shifting:  85\n",
            "5\n",
            "start:  80\n",
            "ugust  201\n",
            "===\n",
            "start before shifting:  87\n",
            "5\n",
            "start:  82\n",
            "ust  2018 \n",
            "===\n",
            "start before shifting:  87\n",
            "5\n",
            "start:  82\n",
            "ust  20\n",
            "===\n",
            "start before shifting:  90\n",
            "5\n",
            "start:  85\n",
            "  2018 at 09:00  И\n",
            "===\n",
            "start before shifting:  101\n",
            "5\n",
            "start:  96\n",
            "9:00  Изуча\n",
            "===\n",
            "start before shifting:  105\n",
            "5\n",
            "start:  100\n",
            "  Из\n",
            "===\n",
            "start before shifting:  110\n",
            "5\n",
            "start:  105\n",
            "чаем синтаксические пар\n",
            "===\n",
            "start before shifting:  110\n",
            "5\n",
            "start:  105\n",
            "чаем синтаксические парсеры\n",
            "===\n",
            "start before shifting:  114\n",
            "5\n",
            "start:  109\n",
            " синтак\n",
            "===\n",
            "start before shifting:  118\n",
            "5\n",
            "start:  113\n",
            "такс\n",
            "===\n",
            "start before shifting:  122\n",
            "5\n",
            "start:  117\n",
            "ические\n",
            "===\n",
            "start before shifting:  124\n",
            "5\n",
            "start:  119\n",
            "еские парсе\n",
            "===\n",
            "start before shifting:  129\n",
            "5\n",
            "start:  124\n",
            " парсеры д\n",
            "===\n",
            "start before shifting:  129\n",
            "5\n",
            "start:  124\n",
            " парсеры для ру\n",
            "===\n",
            "start before shifting:  131\n",
            "5\n",
            "start:  126\n",
            "арсеры\n",
            "===\n",
            "start before shifting:  137\n",
            "5\n",
            "start:  132\n",
            " для русского я\n",
            "===\n",
            "start before shifting:  152\n",
            "5\n",
            "start:  147\n",
            "зыка \n",
            "===\n",
            "start before shifting:  156\n",
            "5\n",
            "start:  151\n",
            " Сбер cor\n",
            "===\n",
            "start before shifting:  162\n",
            "5\n",
            "start:  157\n",
            "corporate \n",
            "===\n",
            "start before shifting:  183\n",
            "5\n",
            "start:  178\n",
            "mming *Machine lea\n",
            "===\n",
            "start before shifting:  185\n",
            "5\n",
            "start:  180\n",
            "ing *Machine lear\n",
            "===\n",
            "start before shifting:  189\n",
            "5\n",
            "start:  184\n",
            "*Machine le\n",
            "===\n",
            "start before shifting:  192\n",
            "5\n",
            "start:  187\n",
            "chine lear\n",
            "===\n",
            "start before shifting:  203\n",
            "5\n",
            "start:  198\n",
            "ing *Artificial Intellig\n",
            "===\n",
            "start before shifting:  207\n",
            "5\n",
            "start:  202\n",
            "*Artificial \n",
            "===\n",
            "start before shifting:  208\n",
            "5\n",
            "start:  203\n",
            "Artificial\n",
            "===\n",
            "start before shifting:  215\n",
            "5\n",
            "start:  210\n",
            "ial \n",
            "===\n",
            "start before shifting:  219\n",
            "5\n",
            "start:  214\n",
            "Intelligence       Привет\n",
            "===\n",
            "start before shifting:  220\n",
            "5\n",
            "start:  215\n",
            "ntelligence       Привет!\n",
            "===\n",
            "start before shifting:  220\n",
            "5\n",
            "start:  215\n",
            "ntelligence  \n",
            "===\n",
            "start before shifting:  229\n",
            "5\n",
            "start:  224\n",
            "ce       П\n",
            "===\n",
            "start before shifting:  244\n",
            "5\n",
            "start:  239\n",
            "! Меня зовут Де\n",
            "===\n",
            "start before shifting:  244\n",
            "5\n",
            "start:  239\n",
            "! Меня \n",
            "===\n",
            "start before shifting:  280\n",
            "5\n",
            "start:  275\n",
            "аю в Сберб\n",
            "===\n",
            "start before shifting:  296\n",
            "5\n",
            "start:  291\n",
            " занимаюс\n",
            "===\n",
            "start before shifting:  296\n",
            "5\n",
            "start:  291\n",
            " занима\n",
            "===\n",
            "start before shifting:  298\n",
            "5\n",
            "start:  293\n",
            "анимаюсь п\n",
            "===\n",
            "start before shifting:  300\n",
            "5\n",
            "start:  295\n",
            "имаюсь \n",
            "===\n",
            "start before shifting:  303\n",
            "5\n",
            "start:  298\n",
            "юсь проблема\n",
            "===\n",
            "start before shifting:  306\n",
            "5\n",
            "start:  301\n",
            " проблема\n",
            "===\n",
            "start before shifting:  317\n",
            "5\n",
            "start:  312\n",
            " обработки естественного \n",
            "===\n",
            "start before shifting:  319\n",
            "5\n",
            "start:  314\n",
            "бработки ес\n",
            "===\n",
            "start before shifting:  324\n",
            "5\n",
            "start:  319\n",
            "тки естест\n",
            "===\n",
            "start before shifting:  337\n",
            "5\n",
            "start:  332\n",
            "ного языка (NLP). Однаж\n",
            "===\n",
            "start before shifting:  351\n",
            "5\n",
            "start:  346\n",
            "P). Однажды нам\n",
            "===\n",
            "start before shifting:  366\n",
            "5\n",
            "start:  361\n",
            " понадобилось выбрать синтак\n",
            "===\n",
            "start before shifting:  370\n",
            "5\n",
            "start:  365\n",
            "адобилось \n",
            "===\n",
            "start before shifting:  386\n",
            "5\n",
            "start:  381\n",
            "ь синтаксич\n",
            "===\n",
            "start before shifting:  389\n",
            "5\n",
            "start:  384\n",
            "интаксичес\n",
            "===\n",
            "start before shifting:  391\n",
            "5\n",
            "start:  386\n",
            "таксиче\n",
            "===\n",
            "start before shifting:  399\n",
            "5\n",
            "start:  394\n",
            "кий парсер д\n",
            "===\n",
            "start before shifting:  401\n",
            "5\n",
            "start:  396\n",
            "й парсер дл\n",
            "===\n",
            "start before shifting:  403\n",
            "5\n",
            "start:  398\n",
            "парсер для работы с русским я\n",
            "===\n",
            "start before shifting:  415\n",
            "5\n",
            "start:  410\n",
            "аботы с\n",
            "===\n",
            "start before shifting:  433\n",
            "5\n",
            "start:  428\n",
            "ыком. Для этого мы углу\n",
            "===\n",
            "start before shifting:  438\n",
            "5\n",
            "start:  433\n",
            " Для этого мы уг\n",
            "===\n",
            "start before shifting:  452\n",
            "5\n",
            "start:  447\n",
            "углу\n",
            "===\n",
            "start before shifting:  452\n",
            "5\n",
            "start:  447\n",
            "углубились в\n",
            "===\n",
            "start before shifting:  465\n",
            "5\n",
            "start:  460\n",
            "дебри морфоло\n",
            "===\n",
            "start before shifting:  466\n",
            "5\n",
            "start:  461\n",
            "ебри морфол\n",
            "===\n",
            "start before shifting:  468\n",
            "5\n",
            "start:  463\n",
            "ри морфоло\n",
            "===\n",
            "start before shifting:  468\n",
            "5\n",
            "start:  463\n",
            "ри морфологии и\n",
            "===\n",
            "start before shifting:  479\n",
            "5\n",
            "start:  474\n",
            "ии и токениз\n",
            "===\n",
            "start before shifting:  479\n",
            "5\n",
            "start:  474\n",
            "ии и токенизации, протести\n",
            "===\n",
            "start before shifting:  499\n",
            "5\n",
            "start:  494\n",
            "отестировали разны\n",
            "===\n",
            "start before shifting:  507\n",
            "5\n",
            "start:  502\n",
            "вали разн\n",
            "===\n",
            "start before shifting:  510\n",
            "5\n",
            "start:  505\n",
            "и разные вариан\n",
            "===\n",
            "start before shifting:  523\n",
            "5\n",
            "start:  518\n",
            "анты и оценили их приме\n",
            "===\n",
            "start before shifting:  532\n",
            "5\n",
            "start:  527\n",
            "енили их применение. Дел\n",
            "===\n",
            "start before shifting:  546\n",
            "5\n",
            "start:  541\n",
            "нение. Делимся опытом в этом пос\n",
            "===\n",
            "start before shifting:  586\n",
            "9\n",
            "start:  577\n",
            "\n",
            "\n",
            "\n",
            "Подг\n",
            "===\n",
            "start before shifting:  591\n",
            "9\n",
            "start:  582\n",
            "дготовка к отбо\n",
            "===\n",
            "start before shifting:  595\n",
            "9\n",
            "start:  586\n",
            "овка к \n",
            "===\n",
            "start before shifting:  605\n",
            "11\n",
            "start:  594\n",
            "тбору \n",
            "===\n",
            "start before shifting:  611\n",
            "11\n",
            "start:  600\n",
            "\n",
            "\n",
            "Начнём с основ: как вс\n",
            "===\n",
            "start before shifting:  619\n",
            "11\n",
            "start:  608\n",
            " с осно\n",
            "===\n",
            "start before shifting:  637\n",
            "11\n",
            "start:  626\n",
            "работает? Мы берем текст,\n",
            "===\n",
            "start before shifting:  639\n",
            "11\n",
            "start:  628\n",
            "ботает? М\n",
            "===\n",
            "start before shifting:  647\n",
            "11\n",
            "start:  636\n",
            "Мы бере\n",
            "===\n",
            "start before shifting:  654\n",
            "11\n",
            "start:  643\n",
            "м текст, прово\n",
            "===\n",
            "start before shifting:  660\n",
            "11\n",
            "start:  649\n",
            "т, пров\n",
            "===\n",
            "start before shifting:  670\n",
            "11\n",
            "start:  659\n",
            "м токенизаци\n",
            "===\n",
            "start before shifting:  684\n",
            "11\n",
            "start:  673\n",
            "и получаем некоторый масс\n",
            "===\n",
            "start before shifting:  695\n",
            "11\n",
            "start:  684\n",
            "некоторый \n",
            "===\n",
            "start before shifting:  703\n",
            "11\n",
            "start:  692\n",
            "й масси\n",
            "===\n",
            "start before shifting:  714\n",
            "11\n",
            "start:  703\n",
            "евдосло\n",
            "===\n",
            "start before shifting:  716\n",
            "11\n",
            "start:  705\n",
            "дослов-\n",
            "===\n",
            "start before shifting:  720\n",
            "11\n",
            "start:  709\n",
            "ов-токено\n",
            "===\n",
            "start before shifting:  729\n",
            "11\n",
            "start:  718\n",
            "в. Этапы д\n",
            "===\n",
            "start before shifting:  735\n",
            "11\n",
            "start:  724\n",
            "пы даль\n",
            "===\n",
            "start before shifting:  740\n",
            "11\n",
            "start:  729\n",
            "льнейше\n",
            "===\n",
            "start before shifting:  744\n",
            "11\n",
            "start:  733\n",
            "йшего а\n",
            "===\n",
            "start before shifting:  751\n",
            "11\n",
            "start:  740\n",
            "нализа укла\n",
            "===\n",
            "start before shifting:  753\n",
            "11\n",
            "start:  742\n",
            "лиза уклад\n",
            "===\n",
            "start before shifting:  753\n",
            "11\n",
            "start:  742\n",
            "лиза уклады\n",
            "===\n",
            "start before shifting:  762\n",
            "11\n",
            "start:  751\n",
            "дываютс\n",
            "===\n",
            "start before shifting:  769\n",
            "11\n",
            "start:  758\n",
            "я в пирамиду:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Начин\n",
            "===\n",
            "start before shifting:  769\n",
            "11\n",
            "start:  758\n",
            "я в пир\n",
            "===\n",
            "start before shifting:  786\n",
            "16\n",
            "start:  770\n",
            ":\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Начинается все с мо\n",
            "===\n",
            "start before shifting:  793\n",
            "16\n",
            "start:  777\n",
            "ачинается в\n",
            "===\n",
            "start before shifting:  815\n",
            "16\n",
            "start:  799\n",
            "огии — с \n",
            "===\n",
            "start before shifting:  816\n",
            "16\n",
            "start:  800\n",
            "гии — с\n",
            "===\n",
            "start before shifting:  816\n",
            "16\n",
            "start:  800\n",
            "гии — с\n",
            "===\n",
            "start before shifting:  822\n",
            "16\n",
            "start:  806\n",
            "с анал\n",
            "===\n",
            "start before shifting:  825\n",
            "16\n",
            "start:  809\n",
            "нализа фор\n",
            "===\n",
            "start before shifting:  834\n",
            "16\n",
            "start:  818\n",
            "рмы слова и его грамматич\n",
            "===\n",
            "start before shifting:  838\n",
            "16\n",
            "start:  822\n",
            "слова и его \n",
            "===\n",
            "start before shifting:  855\n",
            "16\n",
            "start:  839\n",
            "атических к\n",
            "===\n",
            "start before shifting:  869\n",
            "16\n",
            "start:  853\n",
            "горий (ро\n",
            "===\n",
            "start before shifting:  877\n",
            "16\n",
            "start:  861\n",
            "од, падеж \n",
            "===\n",
            "start before shifting:  883\n",
            "16\n",
            "start:  867\n",
            "деж и т.п.)\n",
            "===\n",
            "start before shifting:  886\n",
            "16\n",
            "start:  870\n",
            " и т.п.). На\n",
            "===\n",
            "start before shifting:  886\n",
            "16\n",
            "start:  870\n",
            " и т.п.).\n",
            "===\n",
            "start before shifting:  899\n",
            "16\n",
            "start:  883\n",
            "морфологии баз\n",
            "===\n",
            "start before shifting:  905\n",
            "16\n",
            "start:  889\n",
            "огии базир\n",
            "===\n",
            "start before shifting:  912\n",
            "16\n",
            "start:  896\n",
            "зиру\n",
            "===\n",
            "start before shifting:  913\n",
            "16\n",
            "start:  897\n",
            "ируется синтакс\n",
            "===\n",
            "start before shifting:  926\n",
            "16\n",
            "start:  910\n",
            "ксис — вза\n",
            "===\n",
            "start before shifting:  938\n",
            "16\n",
            "start:  922\n",
            "оотношения\n",
            "===\n",
            "start before shifting:  948\n",
            "16\n",
            "start:  932\n",
            " за рам\n",
            "===\n",
            "start before shifting:  951\n",
            "16\n",
            "start:  935\n",
            " рамками од\n",
            "===\n",
            "start before shifting:  979\n",
            "16\n",
            "start:  963\n",
            " словами. Синта\n",
            "===\n",
            "start before shifting:  990\n",
            "16\n",
            "start:  974\n",
            "интаксиче\n",
            "===\n",
            "start before shifting:  999\n",
            "16\n",
            "start:  983\n",
            "ские па\n",
            "===\n",
            "start before shifting:  1018\n",
            "16\n",
            "start:  1002\n",
            "орых пойде\n",
            "===\n",
            "start before shifting:  1022\n",
            "16\n",
            "start:  1006\n",
            " пойдет\n",
            "===\n",
            "start before shifting:  1032\n",
            "16\n",
            "start:  1016\n",
            "чь, ан\n",
            "===\n",
            "start before shifting:  1037\n",
            "16\n",
            "start:  1021\n",
            "нализируют \n",
            "===\n",
            "start before shifting:  1041\n",
            "16\n",
            "start:  1025\n",
            "зируют т\n",
            "===\n",
            "start before shifting:  1049\n",
            "16\n",
            "start:  1033\n",
            "екст и выдают структуру\n",
            "===\n",
            "start before shifting:  1060\n",
            "16\n",
            "start:  1044\n",
            "ют структу\n",
            "===\n",
            "start before shifting:  1061\n",
            "16\n",
            "start:  1045\n",
            "т струк\n",
            "===\n",
            "start before shifting:  1080\n",
            "16\n",
            "start:  1064\n",
            "остей с\n",
            "===\n",
            "start before shifting:  1091\n",
            "18\n",
            "start:  1073\n",
            "в друг от друга.\n",
            "\n",
            "Грамма\n",
            "===\n",
            "start before shifting:  1092\n",
            "18\n",
            "start:  1074\n",
            " друг от \n",
            "===\n",
            "start before shifting:  1102\n",
            "18\n",
            "start:  1084\n",
            "руга.\n",
            "\n",
            "Гра\n",
            "===\n",
            "start before shifting:  1110\n",
            "18\n",
            "start:  1092\n",
            "раммати\n",
            "===\n",
            "start before shifting:  1117\n",
            "18\n",
            "start:  1099\n",
            "ка зависимостей и грамматика непосредстве\n",
            "===\n",
            "start before shifting:  1141\n",
            "18\n",
            "start:  1123\n",
            "тика непо\n",
            "===\n",
            "start before shifting:  1168\n",
            "20\n",
            "start:  1148\n",
            "тавляющ\n",
            "===\n",
            "start before shifting:  1176\n",
            "20\n",
            "start:  1156\n",
            "х\n",
            "\n",
            "Есть \n",
            "===\n",
            "start before shifting:  1185\n",
            "20\n",
            "start:  1165\n",
            "ва основны\n",
            "===\n",
            "start before shifting:  1187\n",
            "20\n",
            "start:  1167\n",
            " основных подхода к синт\n",
            "===\n",
            "start before shifting:  1202\n",
            "20\n",
            "start:  1182\n",
            "да к си\n",
            "===\n",
            "start before shifting:  1240\n",
            "20\n",
            "start:  1220\n",
            "в лингвист\n",
            "===\n",
            "start before shifting:  1245\n",
            "20\n",
            "start:  1225\n",
            "гвистич\n",
            "===\n",
            "start before shifting:  1268\n",
            "20\n",
            "start:  1248\n",
            "ествуют пр\n",
            "===\n",
            "start before shifting:  1271\n",
            "20\n",
            "start:  1251\n",
            "вуют пр\n",
            "===\n",
            "start before shifting:  1304\n",
            "25\n",
            "start:  1279\n",
            "\n",
            "В первой строк\n",
            "===\n",
            "start before shifting:  1312\n",
            "25\n",
            "start:  1287\n",
            "й строке п\n",
            "===\n",
            "start before shifting:  1325\n",
            "25\n",
            "start:  1300\n",
            "ложение разобрано в рам\n",
            "===\n",
            "start before shifting:  1327\n",
            "25\n",
            "start:  1302\n",
            "жение разобрано в рамках\n",
            "===\n",
            "start before shifting:  1337\n",
            "25\n",
            "start:  1312\n",
            "брано в рамках \n",
            "===\n",
            "start before shifting:  1342\n",
            "25\n",
            "start:  1317\n",
            " в рамк\n",
            "===\n",
            "start before shifting:  1351\n",
            "25\n",
            "start:  1326\n",
            " грамматик\n",
            "===\n",
            "start before shifting:  1357\n",
            "25\n",
            "start:  1332\n",
            "атики з\n",
            "===\n",
            "start before shifting:  1361\n",
            "25\n",
            "start:  1336\n",
            "и зависимостей. Эт\n",
            "===\n",
            "start before shifting:  1367\n",
            "25\n",
            "start:  1342\n",
            "симостей. \n",
            "===\n",
            "start before shifting:  1368\n",
            "25\n",
            "start:  1343\n",
            "имостей. \n",
            "===\n",
            "start before shifting:  1381\n",
            "25\n",
            "start:  1356\n",
            "у подходу\n",
            "===\n",
            "start before shifting:  1389\n",
            "25\n",
            "start:  1364\n",
            "у учат \n",
            "===\n",
            "start before shifting:  1406\n",
            "25\n",
            "start:  1381\n",
            "аждое слово\n",
            "===\n",
            "start before shifting:  1407\n",
            "25\n",
            "start:  1382\n",
            "ждое сл\n",
            "===\n",
            "start before shifting:  1418\n",
            "25\n",
            "start:  1393\n",
            "в предложении\n",
            "===\n",
            "start before shifting:  1430\n",
            "25\n",
            "start:  1405\n",
            "и как-то связано с другим\n",
            "===\n",
            "start before shifting:  1433\n",
            "25\n",
            "start:  1408\n",
            "ак-то связано с другими\n",
            "===\n",
            "start before shifting:  1436\n",
            "25\n",
            "start:  1411\n",
            "то связано \n",
            "===\n",
            "start before shifting:  1450\n",
            "25\n",
            "start:  1425\n",
            "ругими.\n",
            "===\n",
            "start before shifting:  1479\n",
            "25\n",
            "start:  1454\n",
            "т которого з\n",
            "===\n",
            "start before shifting:  1481\n",
            "25\n",
            "start:  1456\n",
            "которого зависит п\n",
            "===\n",
            "start before shifting:  1484\n",
            "25\n",
            "start:  1459\n",
            "орого зависит подлежаще\n",
            "===\n",
            "start before shifting:  1494\n",
            "25\n",
            "start:  1469\n",
            "сит подлежащ\n",
            "===\n",
            "start before shifting:  1497\n",
            "25\n",
            "start:  1472\n",
            " подлеж\n",
            "===\n",
            "start before shifting:  1503\n",
            "25\n",
            "start:  1478\n",
            "жащее «\n",
            "===\n",
            "start before shifting:  1511\n",
            "25\n",
            "start:  1486\n",
            "ама» (\n",
            "===\n",
            "start before shifting:  1518\n",
            "25\n",
            "start:  1493\n",
            "десь гр\n",
            "===\n",
            "start before shifting:  1574\n",
            "25\n",
            "start:  1549\n",
            " сказуемое зави\n",
            "===\n",
            "start before shifting:  1584\n",
            "25\n",
            "start:  1559\n",
            " зависи\n",
            "===\n",
            "start before shifting:  1616\n",
            "25\n",
            "start:  1591\n",
            "ежащ\n",
            "===\n",
            "start before shifting:  1673\n",
            "25\n",
            "start:  1648\n",
            "ть завис\n",
            "===\n",
            "start before shifting:  1707\n",
            "25\n",
            "start:  1682\n",
            "му». А у прямого дополне\n",
            "===\n",
            "start before shifting:  1735\n",
            "25\n",
            "start:  1710\n",
            "«раму» \n",
            "===\n",
            "start before shifting:  1773\n",
            "28\n",
            "start:  1745\n",
            "о второй строке разбор ид\n",
            "===\n",
            "start before shifting:  1790\n",
            "28\n",
            "start:  1762\n",
            "азбор идет в соответствии с грамматикой н\n",
            "===\n",
            "start before shifting:  1798\n",
            "28\n",
            "start:  1770\n",
            "ет в со\n",
            "===\n",
            "start before shifting:  1814\n",
            "28\n",
            "start:  1786\n",
            "и с гра\n",
            "===\n",
            "======\n",
            "text_753914.txt\n",
            "start before shifting:  10\n",
            "2\n",
            "start:  8\n",
            "а ChatGP\n",
            "===\n",
            "start before shifting:  35\n",
            "2\n",
            "start:  33\n",
            "ть для начина\n",
            "===\n",
            "start before shifting:  39\n",
            "2\n",
            "start:  37\n",
            "ля начинающих разработчиков / Habr\n",
            "\n",
            "\n",
            "    \n",
            "===\n",
            "start before shifting:  79\n",
            "5\n",
            "start:  74\n",
            "    \n",
            "===\n",
            "start before shifting:  88\n",
            "5\n",
            "start:  83\n",
            "       И снова Chat\n",
            "===\n",
            "start before shifting:  98\n",
            "5\n",
            "start:  93\n",
            "нова Cha\n",
            "===\n",
            "start before shifting:  108\n",
            "5\n",
            "start:  103\n",
            "PT: боль или радость для начинающих разр\n",
            "===\n",
            "start before shifting:  125\n",
            "5\n",
            "start:  120\n",
            "сть для \n",
            "===\n",
            "start before shifting:  133\n",
            "5\n",
            "start:  128\n",
            "начинающ\n",
            "===\n",
            "start before shifting:  149\n",
            "5\n",
            "start:  144\n",
            "ботчиков Level\n",
            "===\n",
            "start before shifting:  156\n",
            "5\n",
            "start:  151\n",
            "в Level of \n",
            "===\n",
            "start before shifting:  158\n",
            "5\n",
            "start:  153\n",
            "Level of difficulty  \n",
            "    Easy\n",
            "   \n",
            "===\n",
            "start before shifting:  159\n",
            "5\n",
            "start:  154\n",
            "evel of \n",
            "===\n",
            "start before shifting:  159\n",
            "5\n",
            "start:  154\n",
            "evel of difficu\n",
            "===\n",
            "start before shifting:  165\n",
            "5\n",
            "start:  160\n",
            "f difficulty  \n",
            "===\n",
            "start before shifting:  169\n",
            "5\n",
            "start:  164\n",
            "fficulty  \n",
            "    Easy\n",
            "   \n",
            "===\n",
            "start before shifting:  190\n",
            "7\n",
            "start:  183\n",
            "\n",
            "   Read\n",
            "===\n",
            "start before shifting:  231\n",
            "9\n",
            "start:  222\n",
            "2.9K Янд\n",
            "===\n",
            "start before shifting:  243\n",
            "9\n",
            "start:  234\n",
            "Практикум corporate\n",
            "===\n",
            "start before shifting:  291\n",
            "9\n",
            "start:  282\n",
            "n IT IT career \n",
            "===\n",
            "start before shifting:  292\n",
            "9\n",
            "start:  283\n",
            " IT IT c\n",
            "===\n",
            "start before shifting:  320\n",
            "9\n",
            "start:  311\n",
            "ellige\n",
            "===\n",
            "start before shifting:  324\n",
            "10\n",
            "start:  314\n",
            "igence  \n",
            "===\n",
            "start before shifting:  333\n",
            "10\n",
            "start:  323\n",
            "    Opinion\n",
            "        Что изменилось \n",
            "===\n",
            "start before shifting:  394\n",
            "11\n",
            "start:  383\n",
            "ИИ-технологий в прог\n",
            "===\n",
            "start before shifting:  418\n",
            "11\n",
            "start:  407\n",
            "ировании с поя\n",
            "===\n",
            "start before shifting:  703\n",
            "11\n",
            "start:  692\n",
            "ь нейрос\n",
            "===\n",
            "start before shifting:  724\n",
            "11\n",
            "start:  713\n",
            "ии кода.\n",
            "===\n",
            "start before shifting:  1016\n",
            "11\n",
            "start:  1005\n",
            "nerative\n",
            "===\n",
            "start before shifting:  1204\n",
            "11\n",
            "start:  1193\n",
            "на каж\n",
            "===\n",
            "start before shifting:  1471\n",
            "11\n",
            "start:  1460\n",
            "есть о\n",
            "===\n",
            "start before shifting:  1604\n",
            "11\n",
            "start:  1593\n",
            "ящее \n",
            "===\n",
            "start before shifting:  1889\n",
            "11\n",
            "start:  1878\n",
            "дит неск\n",
            "===\n",
            "start before shifting:  1897\n",
            "11\n",
            "start:  1886\n",
            "ольк\n",
            "===\n",
            "start before shifting:  1966\n",
            "11\n",
            "start:  1955\n",
            "о на входе ней\n",
            "===\n",
            "start before shifting:  1981\n",
            "11\n",
            "start:  1970\n",
            "онная сеть ген\n",
            "===\n",
            "start before shifting:  1996\n",
            "11\n",
            "start:  1985\n",
            "рирует случа\n",
            "===\n",
            "start before shifting:  2009\n",
            "11\n",
            "start:  1998\n",
            "ный шум и дальше пытается \n",
            "===\n",
            "start before shifting:  2057\n",
            "11\n",
            "start:  2046\n",
            "аиболее похожие части уж\n",
            "===\n",
            "start before shifting:  2168\n",
            "11\n",
            "start:  2157\n",
            "тся \n",
            "===\n",
            "start before shifting:  2723\n",
            "11\n",
            "start:  2712\n",
            "ки тольк\n",
            "===\n",
            "start before shifting:  3264\n",
            "11\n",
            "start:  3253\n",
            "сле дождя. Но мож\n",
            "===\n",
            "start before shifting:  3292\n",
            "11\n",
            "start:  3281\n",
            "ть то, что сейчас ес\n",
            "===\n",
            "start before shifting:  3702\n",
            "11\n",
            "start:  3691\n",
            "ько в само\n",
            "===\n",
            "start before shifting:  3906\n",
            "11\n",
            "start:  3895\n",
            "мажорной ве\n",
            "===\n",
            "start before shifting:  4343\n",
            "11\n",
            "start:  4332\n",
            "афики. Соо\n",
            "===\n",
            "start before shifting:  4364\n",
            "11\n",
            "start:  4353\n",
            ", база значительно расширилась. В\n",
            "===\n",
            "start before shifting:  4449\n",
            "11\n",
            "start:  4438\n",
            " количестве параметров\n",
            "===\n",
            "start before shifting:  4484\n",
            "11\n",
            "start:  4473\n",
            "они обучены. GPT-\n",
            "===\n",
            "start before shifting:  4525\n",
            "11\n",
            "start:  4514\n",
            " будущем м\n",
            "===\n",
            "start before shifting:  4969\n",
            "11\n",
            "start:  4958\n",
            "ще всего\n",
            "===\n",
            "start before shifting:  5330\n",
            "11\n",
            "start:  5319\n",
            "троенный в Notion,\n",
            "===\n",
            "start before shifting:  5357\n",
            "11\n",
            "start:  5346\n",
            "ет как помочь \n",
            "===\n",
            "start before shifting:  5380\n",
            "11\n",
            "start:  5369\n",
            "уже напи\n",
            "===\n",
            "start before shifting:  5839\n",
            "11\n",
            "start:  5828\n",
            "формате\n",
            "===\n",
            "start before shifting:  5851\n",
            "11\n",
            "start:  5840\n",
            "указанны\n",
            "===\n",
            "start before shifting:  5862\n",
            "11\n",
            "start:  5851\n",
            "пользов\n",
            "===\n",
            "start before shifting:  5871\n",
            "11\n",
            "start:  5860\n",
            "елем параметра\n",
            "===\n",
            "start before shifting:  5890\n",
            "11\n",
            "start:  5879\n",
            "а этом ч\n",
            "===\n",
            "start before shifting:  6154\n",
            "11\n",
            "start:  6143\n",
            "етов, ка\n",
            "===\n",
            "start before shifting:  6250\n",
            "11\n",
            "start:  6239\n",
            "arcwise.\n",
            "===\n",
            "start before shifting:  6262\n",
            "11\n",
            "start:  6251\n",
            "ai — помощник, \n",
            "===\n",
            "start before shifting:  6416\n",
            "11\n",
            "start:  6405\n",
            "нтов. Буде\n",
            "===\n",
            "start before shifting:  6426\n",
            "11\n",
            "start:  6415\n",
            "м честными, все проекты, \n",
            "===\n",
            "start before shifting:  6580\n",
            "11\n",
            "start:  6569\n",
            " основе на\n",
            "===\n",
            "start before shifting:  6824\n",
            "11\n",
            "start:  6813\n",
            "варианты\n",
            "===\n",
            "start before shifting:  7009\n",
            "11\n",
            "start:  6998\n",
            "очь с ре\n",
            "===\n",
            "start before shifting:  7112\n",
            "11\n",
            "start:  7101\n",
            "до прив\n",
            "===\n",
            "start before shifting:  7119\n",
            "11\n",
            "start:  7108\n",
            "ыкнуть. \n",
            "===\n",
            "start before shifting:  7131\n",
            "11\n",
            "start:  7120\n",
            "ала неп\n",
            "===\n",
            "start before shifting:  7138\n",
            "11\n",
            "start:  7127\n",
            "онятно, что в\n",
            "===\n",
            "start before shifting:  7199\n",
            "11\n",
            "start:  7188\n",
            "сперимен\n",
            "===\n",
            "start before shifting:  7485\n",
            "11\n",
            "start:  7474\n",
            "изображений\n",
            "===\n",
            "start before shifting:  7673\n",
            "11\n",
            "start:  7662\n",
            "ы получи\n",
            "===\n",
            "start before shifting:  7817\n",
            "11\n",
            "start:  7806\n",
            "аблицам \n",
            "===\n",
            "start before shifting:  7925\n",
            "11\n",
            "start:  7914\n",
            "га, но э\n",
            "===\n",
            "start before shifting:  8228\n",
            "11\n",
            "start:  8217\n",
            "еского п\n",
            "===\n",
            "start before shifting:  8343\n",
            "11\n",
            "start:  8332\n",
            "ак, чтоб\n",
            "===\n",
            "start before shifting:  8353\n",
            "11\n",
            "start:  8342\n",
            "из естественно\n",
            "===\n",
            "start before shifting:  8368\n",
            "11\n",
            "start:  8357\n",
            " речи получит\n",
            "===\n",
            "start before shifting:  8382\n",
            "11\n",
            "start:  8371\n",
            " набор токенов, ко\n",
            "===\n",
            "start before shifting:  8433\n",
            "11\n",
            "start:  8422\n",
            " воспринимать как действие. Таким образом объединяют ввод\n",
            "===\n",
            "start before shifting:  8571\n",
            "11\n",
            "start:  8560\n",
            "р, для с\n",
            "===\n",
            "start before shifting:  8661\n",
            "11\n",
            "start:  8650\n",
            "аботчико\n",
            "===\n",
            "start before shifting:  9002\n",
            "11\n",
            "start:  8991\n",
            "зованием\n",
            "===\n",
            "start before shifting:  9250\n",
            "11\n",
            "start:  9239\n",
            "студенты\n",
            "===\n",
            "start before shifting:  9394\n",
            "11\n",
            "start:  9383\n",
            "акой-то \n",
            "===\n",
            "start before shifting:  9424\n",
            "11\n",
            "start:  9413\n",
            "ями. В резу\n",
            "===\n",
            "start before shifting:  9449\n",
            "11\n",
            "start:  9438\n",
            "ть \n",
            "===\n",
            "start before shifting:  9514\n",
            "11\n",
            "start:  9503\n",
            "зац\n",
            "===\n",
            "======\n",
            "text_752672.txt\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "RuGPT3X\n",
            "===\n",
            "start before shifting:  3\n",
            "2\n",
            "start:  1\n",
            "\n",
            "RuGPT3\n",
            "===\n",
            "start before shifting:  3\n",
            "2\n",
            "start:  1\n",
            "\n",
            "RuGPT3\n",
            "===\n",
            "start before shifting:  3\n",
            "2\n",
            "start:  1\n",
            "\n",
            "RuGPT3X\n",
            "===\n",
            "start before shifting:  14\n",
            "2\n",
            "start:  12\n",
            "Примеры генерации\n",
            "===\n",
            "start before shifting:  33\n",
            "2\n",
            "start:  31\n",
            "а русском язык\n",
            "===\n",
            "start before shifting:  40\n",
            "2\n",
            "start:  38\n",
            "ом язык\n",
            "===\n",
            "start before shifting:  47\n",
            "2\n",
            "start:  45\n",
            "е (zero-shot co\n",
            "===\n",
            "start before shifting:  47\n",
            "2\n",
            "start:  45\n",
            "е (zero\n",
            "===\n",
            "start before shifting:  48\n",
            "2\n",
            "start:  46\n",
            " (zero-shot codin\n",
            "===\n",
            "start before shifting:  90\n",
            "5\n",
            "start:  85\n",
            "     RuGP\n",
            "===\n",
            "start before shifting:  114\n",
            "5\n",
            "start:  109\n",
            "енераци\n",
            "===\n",
            "start before shifting:  121\n",
            "5\n",
            "start:  116\n",
            "и на русском я\n",
            "===\n",
            "start before shifting:  121\n",
            "5\n",
            "start:  116\n",
            "и на рус\n",
            "===\n",
            "start before shifting:  136\n",
            "5\n",
            "start:  131\n",
            "ыке (zero-shot co\n",
            "===\n",
            "start before shifting:  160\n",
            "5\n",
            "start:  155\n",
            "Readin\n",
            "===\n",
            "start before shifting:  219\n",
            "7\n",
            "start:  212\n",
            "igence Natural Language Proc\n",
            "===\n",
            "start before shifting:  274\n",
            "7\n",
            "start:  267\n",
            "о, чт\n",
            "===\n",
            "start before shifting:  331\n",
            "7\n",
            "start:  324\n",
            "ативных текстовых м\n",
            "===\n",
            "start before shifting:  353\n",
            "7\n",
            "start:  346\n",
            "лей на русском\n",
            "===\n",
            "start before shifting:  369\n",
            "7\n",
            "start:  362\n",
            "зыке - \n",
            "===\n",
            "start before shifting:  392\n",
            "7\n",
            "start:  385\n",
            "сия о\n",
            "===\n",
            "start before shifting:  397\n",
            "7\n",
            "start:  390\n",
            "т Сбер ruGP\n",
            "===\n",
            "start before shifting:  464\n",
            "7\n",
            "start:  457\n",
            "тья от\n",
            "===\n",
            "start before shifting:  512\n",
            "7\n",
            "start:  505\n",
            "предыдущей стать\n",
            "===\n",
            "start before shifting:  530\n",
            "7\n",
            "start:  523\n",
            "описано собствен\n",
            "===\n",
            "start before shifting:  574\n",
            "7\n",
            "start:  567\n",
            "оделей rugpt3small_based_o\n",
            "===\n",
            "start before shifting:  601\n",
            "7\n",
            "start:  594\n",
            "_gpt2, rugpt3medium_based_o\n",
            "===\n",
            "start before shifting:  629\n",
            "7\n",
            "start:  622\n",
            "_gpt2, rugpt3large_based_o\n",
            "===\n",
            "start before shifting:  657\n",
            "7\n",
            "start:  650\n",
            "gpt2 в\n",
            "===\n",
            "start before shifting:  666\n",
            "7\n",
            "start:  659\n",
            "lab на \n",
            "===\n",
            "start before shifting:  745\n",
            "7\n",
            "start:  738\n",
            "тируем ruGP\n",
            "===\n",
            "start before shifting:  769\n",
            "7\n",
            "start:  762\n",
            "на демо-странице от Сбера. К\n",
            "===\n",
            "start before shifting:  782\n",
            "7\n",
            "start:  775\n",
            "ице от\n",
            "===\n",
            "start before shifting:  830\n",
            "7\n",
            "start:  823\n",
            ": даем \n",
            "===\n",
            "start before shifting:  890\n",
            "7\n",
            "start:  883\n",
            "лируем запрос естественным о\n",
            "===\n",
            "start before shifting:  935\n",
            "7\n",
            "start:  928\n",
            "венном русском\n",
            "===\n",
            "start before shifting:  1018\n",
            "7\n",
            "start:  1011\n",
            "ы даем C\n",
            "===\n",
            "start before shifting:  1201\n",
            "7\n",
            "start:  1194\n",
            "в лес4.\n",
            "===\n",
            "start before shifting:  1391\n",
            "7\n",
            "start:  1384\n",
            "в неизв\n",
            "===\n",
            "start before shifting:  1411\n",
            "7\n",
            "start:  1404\n",
            "Искуплен\n",
            "===\n",
            "start before shifting:  1551\n",
            "7\n",
            "start:  1544\n",
            "а бу\n",
            "===\n",
            "start before shifting:  1562\n",
            "8\n",
            "start:  1554\n",
            "мира\"\n",
            " \n",
            "===\n",
            "======\n",
            "text_713920.txt\n",
            "start before shifting:  0\n",
            "0\n",
            "start:  0\n",
            "\n",
            "\n",
            "Теория вероятност\n",
            "===\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "Теория вероятносте\n",
            "===\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "Теория вероятносте\n",
            "===\n",
            "start before shifting:  3\n",
            "2\n",
            "start:  1\n",
            "\n",
            "Теория вероят\n",
            "===\n",
            "start before shifting:  4\n",
            "2\n",
            "start:  2\n",
            "Теория вероятнос\n",
            "===\n",
            "start before shifting:  7\n",
            "2\n",
            "start:  5\n",
            "рия вероятностей в \n",
            "===\n",
            "start before shifting:  9\n",
            "2\n",
            "start:  7\n",
            "я вероятностей в ма\n",
            "===\n",
            "start before shifting:  18\n",
            "2\n",
            "start:  16\n",
            "остей в машинном \n",
            "===\n",
            "start before shifting:  21\n",
            "2\n",
            "start:  19\n",
            "ей в машинном обучении. Ч\n",
            "===\n",
            "start before shifting:  21\n",
            "2\n",
            "start:  19\n",
            "ей в машинном обуче\n",
            "===\n",
            "start before shifting:  24\n",
            "2\n",
            "start:  22\n",
            "в машинном обучени\n",
            "===\n",
            "start before shifting:  29\n",
            "2\n",
            "start:  27\n",
            "инном обучен\n",
            "===\n",
            "start before shifting:  37\n",
            "2\n",
            "start:  35\n",
            "учении. \n",
            "===\n",
            "start before shifting:  51\n",
            "2\n",
            "start:  49\n",
            "1: модель регр\n",
            "===\n",
            "start before shifting:  52\n",
            "2\n",
            "start:  50\n",
            ": модель регресси\n",
            "===\n",
            "start before shifting:  56\n",
            "2\n",
            "start:  54\n",
            "дель регрессии / Habr\n",
            "\n",
            "\n",
            "               Теори\n",
            "===\n",
            "start before shifting:  59\n",
            "2\n",
            "start:  57\n",
            "ь регресси\n",
            "===\n",
            "start before shifting:  59\n",
            "2\n",
            "start:  57\n",
            "ь регрессии / Habr\n",
            "\n",
            "\n",
            "===\n",
            "start before shifting:  60\n",
            "2\n",
            "start:  58\n",
            " регрессии / Habr\n",
            "===\n",
            "start before shifting:  69\n",
            "2\n",
            "start:  67\n",
            "и / Habr\n",
            "\n",
            "\n",
            "    \n",
            "===\n",
            "start before shifting:  71\n",
            "2\n",
            "start:  69\n",
            "/ Habr\n",
            "\n",
            "\n",
            "\n",
            "===\n",
            "start before shifting:  72\n",
            "2\n",
            "start:  70\n",
            " Habr\n",
            "\n",
            "\n",
            " \n",
            "===\n",
            "start before shifting:  78\n",
            "5\n",
            "start:  73\n",
            "br\n",
            "\n",
            "\n",
            "      \n",
            "===\n",
            "start before shifting:  79\n",
            "5\n",
            "start:  74\n",
            "r\n",
            "\n",
            "\n",
            "\n",
            "===\n",
            "start before shifting:  81\n",
            "5\n",
            "start:  76\n",
            "\n",
            "\n",
            "               Т\n",
            "===\n",
            "start before shifting:  93\n",
            "5\n",
            "start:  88\n",
            "     Теория вероятно\n",
            "===\n",
            "start before shifting:  95\n",
            "5\n",
            "start:  90\n",
            "   Теория вероятностей в\n",
            "===\n",
            "start before shifting:  104\n",
            "5\n",
            "start:  99\n",
            " вероятностей в машинном обучении\n",
            "===\n",
            "start before shifting:  104\n",
            "5\n",
            "start:  99\n",
            " вероятностей в маш\n",
            "===\n",
            "start before shifting:  114\n",
            "5\n",
            "start:  109\n",
            "тей в машинном обуче\n",
            "===\n",
            "start before shifting:  115\n",
            "5\n",
            "start:  110\n",
            "ей в машинном обуч\n",
            "===\n",
            "start before shifting:  119\n",
            "5\n",
            "start:  114\n",
            " машинном\n",
            "===\n",
            "start before shifting:  133\n",
            "5\n",
            "start:  128\n",
            "ении. Часть 1: мо\n",
            "===\n",
            "start before shifting:  133\n",
            "5\n",
            "start:  128\n",
            "ении\n",
            "===\n",
            "start before shifting:  134\n",
            "5\n",
            "start:  129\n",
            "нии. Часть 1: \n",
            "===\n",
            "start before shifting:  142\n",
            "5\n",
            "start:  137\n",
            "ть 1: модель регрессии  Reading t\n",
            "===\n",
            "start before shifting:  143\n",
            "5\n",
            "start:  138\n",
            "ь 1: модель регре\n",
            "===\n",
            "start before shifting:  144\n",
            "5\n",
            "start:  139\n",
            " 1: модель регрессии  \n",
            "===\n",
            "start before shifting:  148\n",
            "5\n",
            "start:  143\n",
            "модель регрессии  R\n",
            "===\n",
            "start before shifting:  154\n",
            "5\n",
            "start:  149\n",
            " регрессии  Reading time  \n",
            "    \n",
            "===\n",
            "start before shifting:  155\n",
            "5\n",
            "start:  150\n",
            "регрессии  Reading time  \n",
            "    2\n",
            "===\n",
            "start before shifting:  163\n",
            "5\n",
            "start:  158\n",
            "и  R\n",
            "===\n",
            "start before shifting:  164\n",
            "5\n",
            "start:  159\n",
            "  Reading time\n",
            "===\n",
            "start before shifting:  164\n",
            "5\n",
            "start:  159\n",
            "  Reading time  \n",
            " \n",
            "===\n",
            "start before shifting:  166\n",
            "5\n",
            "start:  161\n",
            "Reading t\n",
            "===\n",
            "start before shifting:  169\n",
            "5\n",
            "start:  164\n",
            "ding time  \n",
            "    28 min\n",
            "   Views \n",
            "===\n",
            "start before shifting:  170\n",
            "5\n",
            "start:  165\n",
            "ing time  \n",
            "    \n",
            "===\n",
            "start before shifting:  176\n",
            "6\n",
            "start:  170\n",
            "ime  \n",
            "    28 m\n",
            "===\n",
            "start before shifting:  210\n",
            "7\n",
            "start:  203\n",
            "en Data Science corporat\n",
            "===\n",
            "start before shifting:  270\n",
            "7\n",
            "start:  263\n",
            " *Statistics in \n",
            "===\n",
            "start before shifting:  302\n",
            "7\n",
            "start:  295\n",
            "telligen\n",
            "===\n",
            "start before shifting:  627\n",
            "7\n",
            "start:  620\n",
            "имизацией среднекв\n",
            "===\n",
            "start before shifting:  655\n",
            "7\n",
            "start:  648\n",
            "о отклонения.В сле\n",
            "===\n",
            "start before shifting:  682\n",
            "7\n",
            "start:  675\n",
            "сти рассм\n",
            "===\n",
            "start before shifting:  835\n",
            "7\n",
            "start:  828\n",
            "тоянием\" между распр\n",
            "===\n",
            "start before shifting:  1008\n",
            "7\n",
            "start:  1001\n",
            "максимизации правд\n",
            "===\n",
            "start before shifting:  1081\n",
            "7\n",
            "start:  1074\n",
            "ниям, таким как ме\n",
            "===\n",
            "start before shifting:  1115\n",
            "7\n",
            "start:  1108\n",
            "го максимум\n",
            "===\n",
            "start before shifting:  1917\n",
            "7\n",
            "start:  1910\n",
            "методы (Müller et al., 2021) и \n",
            "===\n",
            "start before shifting:  1962\n",
            "7\n",
            "start:  1955\n",
            " теории сознания (Friston et al., 2\n",
            "===\n",
            "start before shifting:  2091\n",
            "7\n",
            "start:  2084\n",
            "ематизировать в голове всю и\n",
            "===\n",
            "start before shifting:  2191\n",
            "7\n",
            "start:  2184\n",
            " внезапно складывается в стройную \n",
            "===\n",
            "start before shifting:  2283\n",
            "7\n",
            "start:  2276\n",
            "ь понимание байесовско\n",
            "===\n",
            "start before shifting:  2332\n",
            "7\n",
            "start:  2325\n",
            "ии.Как писал Пьер\n",
            "===\n",
            "start before shifting:  3399\n",
            "7\n",
            "start:  3392\n",
            "т упущено, и в пони\n",
            "===\n",
            "start before shifting:  3632\n",
            "7\n",
            "start:  3625\n",
            "ессии и ее обучени\n",
            "===\n",
            "start before shifting:  4025\n",
            "7\n",
            "start:  4018\n",
            "ель регресс\n",
            "===\n",
            "start before shifting:  4058\n",
            "7\n",
            "start:  4051\n",
            "ти в виде формул и п\n",
            "===\n",
            "start before shifting:  4218\n",
            "7\n",
            "start:  4211\n",
            "статистический выво\n",
            "===\n",
            "start before shifting:  4344\n",
            "7\n",
            "start:  4337\n",
            ". Вероятнос\n",
            "===\n",
            "start before shifting:  4464\n",
            "7\n",
            "start:  4457\n",
            "Вероятностное расп\n",
            "===\n",
            "start before shifting:  4504\n",
            "7\n",
            "start:  4497\n",
            "  3.1. Поняти\n",
            "===\n",
            "start before shifting:  4518\n",
            "7\n",
            "start:  4511\n",
            " распределе\n",
            "===\n",
            "start before shifting:  4610\n",
            "7\n",
            "start:  4603\n",
            "      3.4. i.i.d.-\n",
            "===\n",
            "start before shifting:  4702\n",
            "7\n",
            "start:  4695\n",
            "истические \n",
            "===\n",
            "start before shifting:  4955\n",
            "7\n",
            "start:  4948\n",
            "ерсии*1. Машин\n",
            "===\n",
            "start before shifting:  4971\n",
            "7\n",
            "start:  4964\n",
            "е обучение\n",
            "===\n",
            "start before shifting:  5019\n",
            "7\n",
            "start:  5012\n",
            "вывод (оце\n",
            "===\n",
            "start before shifting:  5096\n",
            "7\n",
            "start:  5089\n",
            "го обучения. Н\n",
            "===\n",
            "start before shifting:  5257\n",
            "7\n",
            "start:  5250\n",
            "стический\n",
            "===\n",
            "start before shifting:  5850\n",
            "7\n",
            "start:  5843\n",
            "у ними довольно\n",
            "===\n",
            "start before shifting:  5867\n",
            "7\n",
            "start:  5860\n",
            "асплывчата. Вообщ\n",
            "===\n",
            "start before shifting:  5968\n",
            "7\n",
            "start:  5961\n",
            " мы более форм\n",
            "===\n",
            "start before shifting:  6010\n",
            "7\n",
            "start:  6003\n",
            "м.Иногда г\n",
            "===\n",
            "start before shifting:  6098\n",
            "7\n",
            "start:  6091\n",
            "ли гипотез\n",
            "===\n",
            "start before shifting:  6134\n",
            "7\n",
            "start:  6127\n",
            "бой переменные\n",
            "===\n",
            "start before shifting:  6158\n",
            "7\n",
            "start:  6151\n",
            "нном обучении целью обыч\n",
            "===\n",
            "start before shifting:  6363\n",
            "7\n",
            "start:  6356\n",
            "ли, тогда как в традиционной\n",
            "===\n",
            "start before shifting:  6591\n",
            "7\n",
            "start:  6584\n",
            "грессия, класс\n",
            "===\n",
            "start before shifting:  6816\n",
            "7\n",
            "start:  6809\n",
            ". Отличие категор\n",
            "===\n",
            "start before shifting:  6859\n",
            "7\n",
            "start:  6852\n",
            "о признака заключае\n",
            "===\n",
            "start before shifting:  6903\n",
            "7\n",
            "start:  6896\n",
            "и float), а скорее в пр\n",
            "===\n",
            "start before shifting:  6959\n",
            "7\n",
            "start:  6952\n",
            "множестве его \n",
            "===\n",
            "start before shifting:  6977\n",
            "7\n",
            "start:  6970\n",
            "ений:В кол\n",
            "===\n",
            "start before shifting:  7265\n",
            "7\n",
            "start:  7258\n",
            "инаково непохожи \n",
            "===\n",
            "start before shifting:  7505\n",
            "7\n",
            "start:  7498\n",
            "ритмах (в форм\n",
            "===\n",
            "start before shifting:  7521\n",
            "7\n",
            "start:  7514\n",
            "е выходных\n",
            "===\n",
            "start before shifting:  8873\n",
            "7\n",
            "start:  8866\n",
            " лишь то, что при выборе формата выхо\n",
            "===\n",
            "start before shifting:  8970\n",
            "7\n",
            "start:  8963\n",
            "а на множе\n",
            "===\n",
            "start before shifting:  9507\n",
            "7\n",
            "start:  9500\n",
            "чно много, \n",
            "===\n",
            "start before shifting:  9591\n",
            "7\n",
            "start:  9584\n",
            "от истин\n",
            "===\n",
            "start before shifting:  9902\n",
            "7\n",
            "start:  9895\n",
            "аписывается как  или пр\n",
            "===\n",
            "start before shifting:  10087\n",
            "7\n",
            "start:  10080\n",
            "меры).Таким образом мы позволи\n",
            "===\n",
            "start before shifting:  10122\n",
            "7\n",
            "start:  10115\n",
            "ели \"сомневаться\" в предсказан\n",
            "===\n",
            "start before shifting:  10185\n",
            "7\n",
            "start:  10178\n",
            "чего\n",
            "===\n",
            "start before shifting:  10204\n",
            "7\n",
            "start:  10197\n",
            "пред\n",
            "===\n",
            "start before shifting:  10306\n",
            "7\n",
            "start:  10299\n",
            "щест\n",
            "===\n",
            "start before shifting:  11850\n",
            "7\n",
            "start:  11843\n",
            "но видеть, что \n",
            "===\n",
            "start before shifting:  11876\n",
            "7\n",
            "start:  11869\n",
            "SE, в сравнении \n",
            "===\n",
            "start before shifting:  12861\n",
            "7\n",
            "start:  12854\n",
            "тие\" колокола по горизонта\n",
            "===\n",
            "start before shifting:  13376\n",
            "7\n",
            "start:  13369\n",
            "ющего примера: че\n",
            "===\n",
            "start before shifting:  13541\n",
            "7\n",
            "start:  13534\n",
            "ункция потерь: нам нужно максимизиров\n",
            "===\n",
            "start before shifting:  13648\n",
            "7\n",
            "start:  13641\n",
            "ет подсчитать конкр\n",
            "===\n",
            "start before shifting:  13728\n",
            "7\n",
            "start:  13721\n",
            "к значений параметров , \n",
            "===\n",
            "start before shifting:  13843\n",
            "7\n",
            "start:  13836\n",
            " максимизации правд\n",
            "===\n",
            "start before shifting:  13863\n",
            "7\n",
            "start:  13856\n",
            "подобия (maximu\n",
            "===\n",
            "start before shifting:  13879\n",
            "7\n",
            "start:  13872\n",
            " likelihood estimation, MLE\n",
            "===\n",
            "start before shifting:  13910\n",
            "7\n",
            "start:  13903\n",
            "араметры, максимизирующи\n",
            "===\n",
            "start before shifting:  14071\n",
            "7\n",
            "start:  14064\n",
            "ого примеров. Будем ис\n",
            "===\n",
            "start before shifting:  14406\n",
            "7\n",
            "start:  14399\n",
            "имизировать функцию п\n",
            "===\n",
            "start before shifting:  14970\n",
            "7\n",
            "start:  14963\n",
            "ать сумму \n",
            "===\n",
            "start before shifting:  14996\n",
            "7\n",
            "start:  14989\n",
            "ых отклонений  по все\n",
            "===\n",
            "start before shifting:  15075\n",
            "7\n",
            "start:  15068\n",
            "грессии мы считали  конс\n",
            "===\n",
            "start before shifting:  15131\n",
            "7\n",
            "start:  15124\n",
            "звольное значение. Теперь\n",
            "===\n",
            "start before shifting:  15227\n",
            "7\n",
            "start:  15220\n",
            "у в задаче поиска оптим\n",
            "===\n",
            "start before shifting:  15418\n",
            "7\n",
            "start:  15411\n",
            "алгоритмическом подход\n",
            "===\n",
            "start before shifting:  15478\n",
            "7\n",
            "start:  15471\n",
            "я параметризованная функ\n",
            "===\n",
            "start before shifting:  15561\n",
            "7\n",
            "start:  15554\n",
            "я сеть, ансамбль реша\n",
            "===\n",
            "start before shifting:  15903\n",
            "7\n",
            "start:  15896\n",
            " нормального распределе\n",
            "===\n",
            "start before shifting:  16010\n",
            "7\n",
            "start:  16003\n",
            "ление .Важно понять, чт\n",
            "===\n",
            "start before shifting:  16119\n",
            "7\n",
            "start:  16112\n",
            "едсказывает, что \" \n",
            "===\n",
            "start before shifting:  16738\n",
            "7\n",
            "start:  16731\n",
            " функции потерь\n",
            "===\n",
            "start before shifting:  16930\n",
            "7\n",
            "start:  16923\n",
            " Пуассона  \n",
            "===\n",
            "start before shifting:  17127\n",
            "7\n",
            "start:  17120\n",
            "де эквивалентен выбору фу\n",
            "===\n",
            "start before shifting:  17559\n",
            "7\n",
            "start:  17552\n",
            "ределение  ск\n",
            "===\n",
            "start before shifting:  17572\n",
            "7\n",
            "start:  17565\n",
            "орее\n",
            "===\n",
            "start before shifting:  18276\n",
            "7\n",
            "start:  18269\n",
            "гда как более бедный ч\n",
            "===\n",
            "start before shifting:  18462\n",
            "7\n",
            "start:  18455\n",
            " 2 выходных нейрона: о\n",
            "===\n",
            "start before shifting:  18606\n",
            "7\n",
            "start:  18599\n",
            "об называется регрессие\n",
            "===\n",
            "start before shifting:  19109\n",
            "7\n",
            "start:  19102\n",
            "ьно, что говорит о ком\n",
            "===\n",
            "start before shifting:  19376\n",
            "7\n",
            "start:  19369\n",
            "lton Board:В реальности\n",
            "===\n",
            "start before shifting:  19689\n",
            "7\n",
            "start:  19682\n",
            "кордсмены по рос\n",
            "===\n",
            "start before shifting:  20183\n",
            "7\n",
            "start:  20176\n",
            "ее вывести функцию потерь по фор\n",
            "===\n",
            "start before shifting:  20549\n",
            "7\n",
            "start:  20542\n",
            "пределения. На самом деле графики плотности \n",
            "===\n",
            "start before shifting:  21111\n",
            "7\n",
            "start:  21104\n",
            "к среднеквадратичную\n",
            "===\n",
            "start before shifting:  21391\n",
            "7\n",
            "start:  21384\n",
            "тей, но в этом сл\n",
            "===\n",
            "start before shifting:  21522\n",
            "7\n",
            "start:  21515\n",
            "пределения данныхКак пра\n",
            "===\n",
            "start before shifting:  21632\n",
            "7\n",
            "start:  21625\n",
            "о распределения\n",
            "===\n",
            "start before shifting:  21967\n",
            "7\n",
            "start:  21960\n",
            "офский. Обычно мы им\n",
            "===\n",
            "start before shifting:  21991\n",
            "7\n",
            "start:  21984\n",
            "лишь конечн\n",
            "===\n",
            "start before shifting:  22136\n",
            "7\n",
            "start:  22129\n",
            "ля \"типичных\" пар , и р\n",
            "===\n",
            "start before shifting:  22375\n",
            "7\n",
            "start:  22368\n",
            "личество авто \"Москв\n",
            "===\n",
            "start before shifting:  22439\n",
            "7\n",
            "start:  22432\n",
            " мощностью 500 л. с. \n",
            "===\n",
            "start before shifting:  22516\n",
            "7\n",
            "start:  22509\n",
            "пределения, в котором дл\n",
            "===\n",
            "start before shifting:  23866\n",
            "7\n",
            "start:  23859\n",
            "одели, способные ге\n",
            "===\n",
            "start before shifting:  24309\n",
            "7\n",
            "start:  24302\n",
            "че предсказа\n",
            "===\n",
            "start before shifting:  24788\n",
            "7\n",
            "start:  24781\n",
            "слительные\n",
            "===\n",
            "start before shifting:  25027\n",
            "7\n",
            "start:  25020\n",
            "ько семплировать пары , то зад\n",
            "===\n",
            "start before shifting:  25115\n",
            "7\n",
            "start:  25108\n",
            "и качество обобщенияЧасто выбо\n",
            "===\n",
            "start before shifting:  26557\n",
            "7\n",
            "start:  26550\n",
            "ление вероятностей.\n",
            "===\n",
            "start before shifting:  26632\n",
            "7\n",
            "start:  26625\n",
            "ы легко можем преобразовать \n",
            "===\n",
            "start before shifting:  27639\n",
            "7\n",
            "start:  27632\n",
            "на от обучающей,\n",
            "===\n",
            "start before shifting:  27656\n",
            "7\n",
            "start:  27649\n",
            "то на ней эта проблема ни\n",
            "===\n",
            "start before shifting:  27685\n",
            "7\n",
            "start:  27678\n",
            "не будет заметна, но при работе \n",
            "===\n",
            "start before shifting:  28164\n",
            "7\n",
            "start:  28157\n",
            "большим количеством примеров я ра\n",
            "===\n",
            "start before shifting:  28449\n",
            "7\n",
            "start:  28442\n",
            "о многом обучение связ\n",
            "===\n",
            "start before shifting:  28853\n",
            "7\n",
            "start:  28846\n",
            "ричинно-следственные св\n",
            "===\n",
            "start before shifting:  29107\n",
            "7\n",
            "start:  29100\n",
            " i.i.d.-обучение, то е\n",
            "===\n",
            "start before shifting:  29947\n",
            "7\n",
            "start:  29940\n",
            "именно произведение ве\n",
            "===\n",
            "start before shifting:  30032\n",
            "7\n",
            "start:  30025\n",
            " методу, используя материал из вт\n",
            "===\n",
            "start before shifting:  30151\n",
            "7\n",
            "start:  30144\n",
            "ой модели и вероятност\n",
            "===\n",
            "start before shifting:  30296\n",
            "7\n",
            "start:  30289\n",
            "естных\n",
            "===\n",
            "start before shifting:  30307\n",
            "7\n",
            "start:  30300\n",
            "метров\n",
            "===\n",
            "start before shifting:  30331\n",
            "7\n",
            "start:  30324\n",
            "сть у нас есть данные, которые явля\n",
            "===\n",
            "start before shifting:  30463\n",
            "7\n",
            "start:  30456\n",
            "ия они получены? М\n",
            "===\n",
            "start before shifting:  30599\n",
            "7\n",
            "start:  30592\n",
            "имер 1. У нас есть набор чисел . М\n",
            "===\n",
            "start before shifting:  31459\n",
            "7\n",
            "start:  31452\n",
            "ы подробно р\n",
            "===\n",
            "start before shifting:  32224\n",
            "7\n",
            "start:  32217\n",
            "стях.На какие \"подводные камни\" м\n",
            "===\n",
            "start before shifting:  32351\n",
            "7\n",
            "start:  32344\n",
            "самом деле распред\n",
            "===\n",
            "start before shifting:  32857\n",
            "7\n",
            "start:  32850\n",
            "мировать - этого уже достаточно (е\n",
            "===\n",
            "start before shifting:  32963\n",
            "7\n",
            "start:  32956\n",
            "о некое приближение\n",
            "===\n",
            "start before shifting:  33007\n",
            "7\n",
            "start:  33000\n",
            "ть не идеально точна, но все р\n",
            "===\n",
            "start before shifting:  33074\n",
            "7\n",
            "start:  33067\n",
            "снованы на моделях к\n",
            "===\n",
            "start before shifting:  33228\n",
            "7\n",
            "start:  33221\n",
            "жет не быть незави\n",
            "===\n",
            "start before shifting:  33417\n",
            "7\n",
            "start:  33410\n",
            "я, разное для разных с\n",
            "===\n",
            "start before shifting:  33494\n",
            "7\n",
            "start:  33487\n",
            "а, но она все равно мо\n",
            "===\n",
            "start before shifting:  33595\n",
            "7\n",
            "start:  33588\n",
            " нельзя, то нужно \n",
            "===\n",
            "start before shifting:  33650\n",
            "7\n",
            "start:  33643\n",
            " прогнозирование вр\n",
            "===\n",
            "start before shifting:  33670\n",
            "7\n",
            "start:  33663\n",
            "менных рядов. \n",
            "===\n",
            "start before shifting:  33685\n",
            "7\n",
            "start:  33678\n",
            "ни тоже могут б\n",
            "===\n",
            "start before shifting:  34010\n",
            "7\n",
            "start:  34003\n",
            " следующей части мы ра\n",
            "===\n",
            "start before shifting:  34722\n",
            "7\n",
            "start:  34715\n",
            "обия является лишь \n",
            "===\n",
            "start before shifting:  34792\n",
            "7\n",
            "start:  34785\n",
            "м чем сложнее мо\n",
            "===\n",
            "start before shifting:  34810\n",
            "7\n",
            "start:  34803\n",
            "ль и меньше данных, \n",
            "===\n",
            "start before shifting:  34835\n",
            "7\n",
            "start:  34828\n",
            "енее точной полу\n",
            "===\n",
            "start before shifting:  35015\n",
            "7\n",
            "start:  35008\n",
            "ют его более точные аппро\n",
            "===\n",
            "start before shifting:  35881\n",
            "7\n",
            "start:  35874\n",
            "ассматривали во второй части. Все,\n",
            "===\n",
            "start before shifting:  36233\n",
            "7\n",
            "start:  36226\n",
            "Именно поэтому в ра\n",
            "===\n",
            "start before shifting:  36460\n",
            "7\n",
            "start:  36453\n",
            "им-либо способом (дл\n",
            "===\n",
            "start before shifting:  36649\n",
            "7\n",
            "start:  36642\n",
            "ыборки.Как видим,\n",
            "===\n",
            "start before shifting:  36696\n",
            "7\n",
            "start:  36689\n",
            "простыми статистич\n",
            "===\n",
            "start before shifting:  36828\n",
            "7\n",
            "start:  36821\n",
            "камня, основным и\n",
            "===\n",
            "start before shifting:  36886\n",
            "7\n",
            "start:  36879\n",
            "ществует множеств\n",
            "===\n",
            "start before shifting:  37117\n",
            "7\n",
            "start:  37110\n",
            " максимизировать \n",
            "===\n",
            "start before shifting:  37179\n",
            "7\n",
            "start:  37172\n",
            "ь. Но во-первых\n",
            "===\n",
            "start before shifting:  37238\n",
            "7\n",
            "start:  37231\n",
            "логарифма упрощает фор\n",
            "===\n",
            "======\n",
            "text_732240.txt\n",
            "start before shifting:  14\n",
            "2\n",
            "start:  12\n",
            "нать тек\n",
            "===\n",
            "start before shifting:  23\n",
            "2\n",
            "start:  21\n",
            "т, написанный нейро\n",
            "===\n",
            "start before shifting:  52\n",
            "2\n",
            "start:  50\n",
            "ак это использо\n",
            "===\n",
            "start before shifting:  70\n",
            "2\n",
            "start:  68\n",
            "ь в B2B\n",
            "===\n",
            "start before shifting:  86\n",
            "2\n",
            "start:  84\n",
            "/ Habr\n",
            "\n",
            "===\n",
            "start before shifting:  101\n",
            "5\n",
            "start:  96\n",
            "       \n",
            "===\n",
            "start before shifting:  130\n",
            "5\n",
            "start:  125\n",
            "кст, нап\n",
            "===\n",
            "start before shifting:  180\n",
            "5\n",
            "start:  175\n",
            " в B2B-бизнесе Leve\n",
            "===\n",
            "start before shifting:  234\n",
            "7\n",
            "start:  227\n",
            "eading time  \n",
            "    8\n",
            "===\n",
            "start before shifting:  238\n",
            "7\n",
            "start:  231\n",
            "ng time  \n",
            "    8 min\n",
            "===\n",
            "start before shifting:  632\n",
            "9\n",
            "start:  623\n",
            "ыдаёт однотипный ме\n",
            "===\n",
            "start before shifting:  666\n",
            "9\n",
            "start:  657\n",
            "т, от которого реально заснут\n",
            "===\n",
            "start before shifting:  862\n",
            "9\n",
            "start:  853\n",
            "рабатыв\n",
            "===\n",
            "start before shifting:  918\n",
            "9\n",
            "start:  909\n",
            "вно выпусти\n",
            "===\n",
            "start before shifting:  1121\n",
            "9\n",
            "start:  1112\n",
            "но это \n",
            "===\n",
            "start before shifting:  1560\n",
            "9\n",
            "start:  1551\n",
            "е такие, как новост\n",
            "===\n",
            "start before shifting:  3867\n",
            "9\n",
            "start:  3858\n",
            "азательс\n",
            "===\n",
            "start before shifting:  5311\n",
            "9\n",
            "start:  5302\n",
            "екста. Н\n",
            "===\n",
            "start before shifting:  5323\n",
            "9\n",
            "start:  5314\n",
            "мер, каждое пр\n",
            "===\n",
            "start before shifting:  7344\n",
            "9\n",
            "start:  7335\n",
            "ой сфере.Проанали\n",
            "===\n",
            "start before shifting:  7370\n",
            "9\n",
            "start:  7361\n",
            "сточни\n",
            "===\n",
            "start before shifting:  7397\n",
            "9\n",
            "start:  7388\n",
            "горитмы ИИ генерир\n",
            "===\n",
            "======\n",
            "text_753418.txt\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "«Диалектик\n",
            "===\n",
            "start before shifting:  32\n",
            "2\n",
            "start:  30\n",
            "иалистическое медиа\n",
            "===\n",
            "start before shifting:  34\n",
            "2\n",
            "start:  32\n",
            "листическо\n",
            "===\n",
            "start before shifting:  72\n",
            "2\n",
            "start:  70\n",
            "х NLP проекта\n",
            "===\n",
            "start before shifting:  74\n",
            "2\n",
            "start:  72\n",
            "NLP проектах, п\n",
            "===\n",
            "start before shifting:  84\n",
            "2\n",
            "start:  82\n",
            "ах, публику\n",
            "===\n",
            "start before shifting:  96\n",
            "2\n",
            "start:  94\n",
            "т датасет\n",
            "===\n",
            "start before shifting:  96\n",
            "2\n",
            "start:  94\n",
            "т датасеты и\n",
            "===\n",
            "start before shifting:  109\n",
            "2\n",
            "start:  107\n",
            "делится к\n",
            "===\n",
            "start before shifting:  117\n",
            "2\n",
            "start:  115\n",
            "кодом / Hab\n",
            "===\n",
            "start before shifting:  120\n",
            "2\n",
            "start:  118\n",
            "ом / Habr\n",
            "\n",
            "===\n",
            "start before shifting:  145\n",
            "5\n",
            "start:  140\n",
            "     «Диалек\n",
            "===\n",
            "start before shifting:  215\n",
            "5\n",
            "start:  210\n",
            "воих NLP прое\n",
            "===\n",
            "start before shifting:  239\n",
            "5\n",
            "start:  234\n",
            "кует дата\n",
            "===\n",
            "start before shifting:  253\n",
            "5\n",
            "start:  248\n",
            "и делится кодом Level of difficulty  \n",
            "    Easy\n",
            "   Reading ti\n",
            "===\n",
            "start before shifting:  293\n",
            "6\n",
            "start:  287\n",
            "   Easy\n",
            "   Reading time  \n",
            "\n",
            "===\n",
            "start before shifting:  304\n",
            "7\n",
            "start:  297\n",
            " Reading tim\n",
            "===\n",
            "start before shifting:  320\n",
            "8\n",
            "start:  312\n",
            "\n",
            "    15 min\n",
            "   Views  4.\n",
            "===\n",
            "start before shifting:  324\n",
            "9\n",
            "start:  315\n",
            "  15 min\n",
            "\n",
            "===\n",
            "start before shifting:  330\n",
            "9\n",
            "start:  321\n",
            "in\n",
            "   Views  4.1K Open\n",
            "===\n",
            "start before shifting:  353\n",
            "9\n",
            "start:  344\n",
            "Data Scienc\n",
            "===\n",
            "start before shifting:  354\n",
            "9\n",
            "start:  345\n",
            "ata Science corporate blog Machine \n",
            "===\n",
            "start before shifting:  363\n",
            "9\n",
            "start:  354\n",
            "ce corporate blog Machine learning *DIY IT\n",
            "===\n",
            "start before shifting:  365\n",
            "9\n",
            "start:  356\n",
            " corporate b\n",
            "===\n",
            "start before shifting:  406\n",
            "9\n",
            "start:  397\n",
            "companies Natural Language\n",
            "===\n",
            "start before shifting:  407\n",
            "9\n",
            "start:  398\n",
            "ompanies Natural Language Pr\n",
            "===\n",
            "start before shifting:  430\n",
            "9\n",
            "start:  421\n",
            "ge Processing \n",
            "===\n",
            "start before shifting:  433\n",
            "9\n",
            "start:  424\n",
            "Processing * \n",
            "    Reporta\n",
            "===\n",
            "start before shifting:  459\n",
            "11\n",
            "start:  448\n",
            "age\n",
            "        \n",
            "Почти сразу после публикации\n",
            "===\n",
            "start before shifting:  495\n",
            "12\n",
            "start:  483\n",
            "икации поста про \n",
            "===\n",
            "start before shifting:  501\n",
            "12\n",
            "start:  489\n",
            " поста про систему поиска новостей о трудовых ко\n",
            "===\n",
            "start before shifting:  550\n",
            "12\n",
            "start:  538\n",
            "фликтах в СНГ я позн\n",
            "===\n",
            "start before shifting:  565\n",
            "12\n",
            "start:  553\n",
            " познакомился \n",
            "===\n",
            "start before shifting:  587\n",
            "12\n",
            "start:  575\n",
            "тивом про\n",
            "===\n",
            "start before shifting:  589\n",
            "12\n",
            "start:  577\n",
            "вом проекта \n",
            "===\n",
            "start before shifting:  598\n",
            "12\n",
            "start:  586\n",
            "та «Диал\n",
            "===\n",
            "start before shifting:  614\n",
            "12\n",
            "start:  602\n",
            "Ребята отмечали\n",
            "===\n",
            "start before shifting:  618\n",
            "12\n",
            "start:  606\n",
            "та отмечали важно\n",
            "===\n",
            "start before shifting:  635\n",
            "12\n",
            "start:  623\n",
            "сть отслежива\n",
            "===\n",
            "start before shifting:  645\n",
            "12\n",
            "start:  633\n",
            "ивания зарубежны\n",
            "===\n",
            "start before shifting:  651\n",
            "12\n",
            "start:  639\n",
            " зарубежных\n",
            "===\n",
            "start before shifting:  665\n",
            "12\n",
            "start:  653\n",
            "бастовок и ан\n",
            "===\n",
            "start before shifting:  678\n",
            "12\n",
            "start:  666\n",
            "ализа опыта мирового рабочего движения в отстаивании трудовых пра\n",
            "===\n",
            "start before shifting:  706\n",
            "12\n",
            "start:  694\n",
            "о дв\n",
            "===\n",
            "start before shifting:  711\n",
            "12\n",
            "start:  699\n",
            "жения в отстаивании трудовы\n",
            "===\n",
            "start before shifting:  744\n",
            "12\n",
            "start:  732\n",
            ". Поэтому я\n",
            "===\n",
            "start before shifting:  747\n",
            "12\n",
            "start:  735\n",
            "оэтому я на\n",
            "===\n",
            "start before shifting:  759\n",
            "12\n",
            "start:  747\n",
            "ал помогать «\n",
            "===\n",
            "start before shifting:  783\n",
            "12\n",
            "start:  771\n",
            " своими на\n",
            "===\n",
            "start before shifting:  797\n",
            "12\n",
            "start:  785\n",
            "ми работы с алгоритмами машинно\n",
            "===\n",
            "start before shifting:  805\n",
            "12\n",
            "start:  793\n",
            "ы с алгоритмами машинного обучения.\n",
            "Было решено разраб\n",
            "===\n",
            "start before shifting:  809\n",
            "12\n",
            "start:  797\n",
            "алгоритмами м\n",
            "===\n",
            "start before shifting:  835\n",
            "13\n",
            "start:  822\n",
            "чения.\n",
            "Было решено \n",
            "===\n",
            "start before shifting:  856\n",
            "13\n",
            "start:  843\n",
            "зрабо\n",
            "===\n",
            "start before shifting:  860\n",
            "13\n",
            "start:  847\n",
            "отать систему, которая бы автома\n",
            "===\n",
            "start before shifting:  881\n",
            "13\n",
            "start:  868\n",
            "я бы автоматически\n",
            "===\n",
            "start before shifting:  886\n",
            "13\n",
            "start:  873\n",
            "автоматически находила новости о зарубежных трудовы\n",
            "===\n",
            "start before shifting:  893\n",
            "13\n",
            "start:  880\n",
            "ически находила новости о зарубежных трудовых конфликт\n",
            "===\n",
            "start before shifting:  900\n",
            "13\n",
            "start:  887\n",
            "находила новости о \n",
            "===\n",
            "start before shifting:  945\n",
            "13\n",
            "start:  932\n",
            "ктах. Во в\n",
            "===\n",
            "start before shifting:  948\n",
            "13\n",
            "start:  935\n",
            "х. Во время разработки этой системы я познакомился с \n",
            "===\n",
            "start before shifting:  956\n",
            "13\n",
            "start:  943\n",
            "емя раз\n",
            "===\n",
            "start before shifting:  964\n",
            "13\n",
            "start:  951\n",
            "аботки э\n",
            "===\n",
            "start before shifting:  1004\n",
            "13\n",
            "start:  991\n",
            "гими техничес\n",
            "===\n",
            "start before shifting:  1004\n",
            "13\n",
            "start:  991\n",
            "гими техническими \n",
            "===\n",
            "start before shifting:  1019\n",
            "13\n",
            "start:  1006\n",
            "ми проектами \n",
            "===\n",
            "start before shifting:  1055\n",
            "13\n",
            "start:  1042\n",
            " хоч\n",
            "===\n",
            "start before shifting:  1059\n",
            "13\n",
            "start:  1046\n",
            "у рассказать в этом посте\n",
            "===\n",
            "start before shifting:  1059\n",
            "13\n",
            "start:  1046\n",
            "у рассказать в \n",
            "===\n",
            "start before shifting:  1063\n",
            "13\n",
            "start:  1050\n",
            "ссказать в это\n",
            "===\n",
            "start before shifting:  1081\n",
            "13\n",
            "start:  1068\n",
            "сте. Почти\n",
            "===\n",
            "start before shifting:  1126\n",
            "13\n",
            "start:  1113\n",
            "из данных, по\n",
            "===\n",
            "start before shifting:  1154\n",
            "13\n",
            "start:  1141\n",
            "ые в открытый дост\n",
            "===\n",
            "start before shifting:  1171\n",
            "13\n",
            "start:  1158\n",
            "туп данные\n",
            "===\n",
            "start before shifting:  1182\n",
            "13\n",
            "start:  1169\n",
            "и код м\n",
            "===\n",
            "start before shifting:  1190\n",
            "13\n",
            "start:  1177\n",
            "гут быть\n",
            "===\n",
            "start before shifting:  1196\n",
            "13\n",
            "start:  1183\n",
            "ть полезными Data Scienc\n",
            "===\n",
            "start before shifting:  1222\n",
            "15\n",
            "start:  1207\n",
            "e сообщест\n",
            "===\n",
            "start before shifting:  1278\n",
            "15\n",
            "start:  1263\n",
            "кое медиа, коллектив которог\n",
            "===\n",
            "start before shifting:  1286\n",
            "15\n",
            "start:  1271\n",
            "а, коллектив \n",
            "===\n",
            "start before shifting:  1303\n",
            "15\n",
            "start:  1288\n",
            "рого работает в области социальной журналистики. Р\n",
            "===\n",
            "start before shifting:  1315\n",
            "15\n",
            "start:  1300\n",
            "т в области социальной журналистики. Ре\n",
            "===\n",
            "start before shifting:  1343\n",
            "15\n",
            "start:  1328\n",
            "листики. Р\n",
            "===\n",
            "start before shifting:  1357\n",
            "15\n",
            "start:  1342\n",
            "торы находят закономерно\n",
            "===\n",
            "start before shifting:  1366\n",
            "15\n",
            "start:  1351\n",
            "дят законом\n",
            "===\n",
            "start before shifting:  1382\n",
            "15\n",
            "start:  1367\n",
            "ти и\n",
            "===\n",
            "start before shifting:  1387\n",
            "15\n",
            "start:  1372\n",
            "освещают противоречия в устр\n",
            "===\n",
            "start before shifting:  1415\n",
            "15\n",
            "start:  1400\n",
            "ойстве со\n",
            "===\n",
            "start before shifting:  1425\n",
            "15\n",
            "start:  1410\n",
            "ременного \n",
            "===\n",
            "start before shifting:  1427\n",
            "15\n",
            "start:  1412\n",
            "менного общества\n",
            "===\n",
            "start before shifting:  1447\n",
            "15\n",
            "start:  1432\n",
            "ллектив волнуют проце\n",
            "===\n",
            "start before shifting:  1462\n",
            "15\n",
            "start:  1447\n",
            " процессы, происходящие к\n",
            "===\n",
            "start before shifting:  1463\n",
            "15\n",
            "start:  1448\n",
            "процессы, происходящие как в э\n",
            "===\n",
            "start before shifting:  1539\n",
            "15\n",
            "start:  1524\n",
            "в обществе, культ\n",
            "===\n",
            "start before shifting:  1551\n",
            "15\n",
            "start:  1536\n",
            "куль\n",
            "===\n",
            "start before shifting:  1555\n",
            "15\n",
            "start:  1540\n",
            "туре, политике. Ребята публикуют свои репортажи в Teleg\n",
            "===\n",
            "start before shifting:  1590\n",
            "15\n",
            "start:  1575\n",
            "ои репорт\n",
            "===\n",
            "start before shifting:  1601\n",
            "15\n",
            "start:  1586\n",
            "и в\n",
            "===\n",
            "start before shifting:  1613\n",
            "15\n",
            "start:  1598\n",
            " и VK, стараются развивать портал. «Диалектик» освещ\n",
            "===\n",
            "start before shifting:  1616\n",
            "15\n",
            "start:  1601\n",
            "VK, стараютс\n",
            "===\n",
            "start before shifting:  1629\n",
            "15\n",
            "start:  1614\n",
            " развиват\n",
            "===\n",
            "start before shifting:  1633\n",
            "15\n",
            "start:  1618\n",
            "вивать порта\n",
            "===\n",
            "start before shifting:  1639\n",
            "15\n",
            "start:  1624\n",
            " портал. «\n",
            "===\n",
            "start before shifting:  1668\n",
            "15\n",
            "start:  1653\n",
            " события с точки зрения простых людей, выражает переж\n",
            "===\n",
            "start before shifting:  1684\n",
            "15\n",
            "start:  1669\n",
            " зрения простых \n",
            "===\n",
            "start before shifting:  1728\n",
            "15\n",
            "start:  1713\n",
            "и ин\n",
            "===\n",
            "start before shifting:  1733\n",
            "15\n",
            "start:  1718\n",
            "ересы трудящихся масс. Этим\n",
            "===\n",
            "start before shifting:  1755\n",
            "15\n",
            "start:  1740\n",
            " Этим он отличается от других ресурсов, которые лоб\n",
            "===\n",
            "start before shifting:  1769\n",
            "15\n",
            "start:  1754\n",
            "ается от др\n",
            "===\n",
            "start before shifting:  1809\n",
            "15\n",
            "start:  1794\n",
            "уют интересы спонсоров и преподносят информацию с точки зрения их б\n",
            "===\n",
            "start before shifting:  1819\n",
            "15\n",
            "start:  1804\n",
            "сы спонсоров и преподнос\n",
            "===\n",
            "start before shifting:  1879\n",
            "16\n",
            "start:  1863\n",
            "неса.\n",
            "Весь коллектив, от редакторов до технических специалистов,\n",
            "===\n",
            "start before shifting:  1962\n",
            "16\n",
            "start:  1946\n",
            "ров-активист\n",
            "===\n",
            "start before shifting:  1980\n",
            "16\n",
            "start:  1964\n",
            "иалектик» не полу\n",
            "===\n",
            "start before shifting:  2016\n",
            "16\n",
            "start:  2000\n",
            "дуна\n",
            "===\n",
            "start before shifting:  2035\n",
            "16\n",
            "start:  2019\n",
            "ийских организаций, финансирование по-настоящему\n",
            "===\n",
            "start before shifting:  2040\n",
            "16\n",
            "start:  2024\n",
            "х организа\n",
            "===\n",
            "start before shifting:  2132\n",
            "16\n",
            "start:  2116\n",
            "ится на продв\n",
            "===\n",
            "======\n",
            "text_760170.txt\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "ChatGP\n",
            "===\n",
            "start before shifting:  8\n",
            "2\n",
            "start:  6\n",
            "GPT на \n",
            "===\n",
            "start before shifting:  14\n",
            "2\n",
            "start:  12\n",
            " темной\n",
            "===\n",
            "start before shifting:  28\n",
            "2\n",
            "start:  26\n",
            "лой стороне / Hab\n",
            "===\n",
            "start before shifting:  29\n",
            "2\n",
            "start:  27\n",
            "ой сторо\n",
            "===\n",
            "start before shifting:  33\n",
            "2\n",
            "start:  31\n",
            "тороне /\n",
            "===\n",
            "start before shifting:  37\n",
            "2\n",
            "start:  35\n",
            "не / Habr\n",
            "\n",
            "\n",
            "  \n",
            "===\n",
            "start before shifting:  37\n",
            "2\n",
            "start:  35\n",
            "не / Habr\n",
            "\n",
            "===\n",
            "start before shifting:  47\n",
            "5\n",
            "start:  42\n",
            "br\n",
            "\n",
            "\n",
            "   \n",
            "===\n",
            "start before shifting:  49\n",
            "5\n",
            "start:  44\n",
            "\n",
            "\n",
            "\n",
            "               ChatGPT на темной и светлой стороне Level of diff\n",
            "===\n",
            "start before shifting:  50\n",
            "5\n",
            "start:  45\n",
            "\n",
            "\n",
            "          \n",
            "===\n",
            "start before shifting:  52\n",
            "5\n",
            "start:  47\n",
            "     \n",
            "===\n",
            "start before shifting:  54\n",
            "5\n",
            "start:  49\n",
            "       \n",
            "===\n",
            "start before shifting:  62\n",
            "5\n",
            "start:  57\n",
            "     Cha\n",
            "===\n",
            "start before shifting:  67\n",
            "5\n",
            "start:  62\n",
            "ChatGPT \n",
            "===\n",
            "start before shifting:  78\n",
            "5\n",
            "start:  73\n",
            "темной и\n",
            "===\n",
            "start before shifting:  81\n",
            "5\n",
            "start:  76\n",
            "ной и свет\n",
            "===\n",
            "start before shifting:  86\n",
            "5\n",
            "start:  81\n",
            " светло\n",
            "===\n",
            "start before shifting:  93\n",
            "5\n",
            "start:  88\n",
            "й сторон\n",
            "===\n",
            "start before shifting:  97\n",
            "5\n",
            "start:  92\n",
            "ороне L\n",
            "===\n",
            "start before shifting:  99\n",
            "5\n",
            "start:  94\n",
            "оне Level of difficulty  \n",
            "    Medium\n",
            "\n",
            "===\n",
            "start before shifting:  102\n",
            "5\n",
            "start:  97\n",
            " Level \n",
            "===\n",
            "start before shifting:  102\n",
            "5\n",
            "start:  97\n",
            " Level of diff\n",
            "===\n",
            "start before shifting:  105\n",
            "5\n",
            "start:  100\n",
            "vel of d\n",
            "===\n",
            "start before shifting:  106\n",
            "5\n",
            "start:  101\n",
            "el of di\n",
            "===\n",
            "start before shifting:  111\n",
            "5\n",
            "start:  106\n",
            " difficu\n",
            "===\n",
            "start before shifting:  115\n",
            "5\n",
            "start:  110\n",
            "ficulty \n",
            "===\n",
            "start before shifting:  122\n",
            "6\n",
            "start:  116\n",
            "y  \n",
            "    Mediu\n",
            "===\n",
            "start before shifting:  128\n",
            "6\n",
            "start:  122\n",
            "  Medium\n",
            "   Readin\n",
            "===\n",
            "start before shifting:  132\n",
            "7\n",
            "start:  125\n",
            "edium\n",
            "  \n",
            "===\n",
            "start before shifting:  137\n",
            "7\n",
            "start:  130\n",
            "\n",
            "   Readi\n",
            "===\n",
            "start before shifting:  142\n",
            "7\n",
            "start:  135\n",
            "eading\n",
            "===\n",
            "start before shifting:  143\n",
            "7\n",
            "start:  136\n",
            "ading time  \n",
            "    9 min\n",
            "   Views\n",
            "===\n",
            "start before shifting:  149\n",
            "8\n",
            "start:  141\n",
            " time \n",
            "===\n",
            "start before shifting:  153\n",
            "8\n",
            "start:  145\n",
            "e  \n",
            "    \n",
            "===\n",
            "start before shifting:  158\n",
            "8\n",
            "start:  150\n",
            "   9 min\n",
            "===\n",
            "start before shifting:  158\n",
            "8\n",
            "start:  150\n",
            "   9 min\n",
            "===\n",
            "start before shifting:  168\n",
            "9\n",
            "start:  159\n",
            "   View\n",
            "===\n",
            "start before shifting:  176\n",
            "9\n",
            "start:  167\n",
            "  4.1K Securit\n",
            "===\n",
            "start before shifting:  181\n",
            "9\n",
            "start:  172\n",
            "K Security Vision corporate blog Machine learning *Artificial Intelligen\n",
            "===\n",
            "start before shifting:  183\n",
            "9\n",
            "start:  174\n",
            "Securit\n",
            "===\n",
            "start before shifting:  183\n",
            "9\n",
            "start:  174\n",
            "Secu\n",
            "===\n",
            "start before shifting:  192\n",
            "9\n",
            "start:  183\n",
            "Vision corporate bl\n",
            "===\n",
            "start before shifting:  197\n",
            "9\n",
            "start:  188\n",
            "n corpor\n",
            "===\n",
            "start before shifting:  200\n",
            "9\n",
            "start:  191\n",
            "orporate \n",
            "===\n",
            "start before shifting:  212\n",
            "9\n",
            "start:  203\n",
            "g Machi\n",
            "===\n",
            "start before shifting:  212\n",
            "9\n",
            "start:  203\n",
            "g Machine learning *Artificial Intelligence Na\n",
            "===\n",
            "start before shifting:  220\n",
            "9\n",
            "start:  211\n",
            "e learn\n",
            "===\n",
            "start before shifting:  233\n",
            "9\n",
            "start:  224\n",
            "rtificia\n",
            "===\n",
            "start before shifting:  236\n",
            "9\n",
            "start:  227\n",
            "ficial \n",
            "===\n",
            "start before shifting:  247\n",
            "9\n",
            "start:  238\n",
            "lligence Natural Language Pr\n",
            "===\n",
            "start before shifting:  253\n",
            "9\n",
            "start:  244\n",
            "ce Natu\n",
            "===\n",
            "start before shifting:  255\n",
            "9\n",
            "start:  246\n",
            " Natural Language Pr\n",
            "===\n",
            "start before shifting:  257\n",
            "9\n",
            "start:  248\n",
            "atural Language Processing * \n",
            "===\n",
            "start before shifting:  258\n",
            "9\n",
            "start:  249\n",
            "tural La\n",
            "===\n",
            "start before shifting:  259\n",
            "9\n",
            "start:  250\n",
            "ural Language Processing * \n",
            "\n",
            "===\n",
            "start before shifting:  270\n",
            "9\n",
            "start:  261\n",
            "ge Pro\n",
            "===\n",
            "start before shifting:  274\n",
            "9\n",
            "start:  265\n",
            "rocessing * \n",
            "    Analy\n",
            "===\n",
            "start before shifting:  275\n",
            "9\n",
            "start:  266\n",
            "ocessing\n",
            "===\n",
            "start before shifting:  281\n",
            "10\n",
            "start:  271\n",
            "ing * \n",
            " \n",
            "===\n",
            "start before shifting:  283\n",
            "10\n",
            "start:  273\n",
            "g * \n",
            "  \n",
            "===\n",
            "start before shifting:  285\n",
            "10\n",
            "start:  275\n",
            "* \n",
            "   \n",
            "===\n",
            "start before shifting:  339\n",
            "11\n",
            "start:  328\n",
            "ад. На \n",
            "===\n",
            "start before shifting:  381\n",
            "11\n",
            "start:  370\n",
            "нимание, что в сфере искусственного и\n",
            "===\n",
            "start before shifting:  421\n",
            "11\n",
            "start:  410\n",
            "ллекта происходит нечто важное, каче\n",
            "===\n",
            "start before shifting:  495\n",
            "11\n",
            "start:  484\n",
            "е более \n",
            "===\n",
            "start before shifting:  502\n",
            "11\n",
            "start:  491\n",
            " сотни че\n",
            "===\n",
            "start before shifting:  553\n",
            "11\n",
            "start:  542\n",
            "тавили п\n",
            "===\n",
            "start before shifting:  609\n",
            "11\n",
            "start:  598\n",
            "ав техноло\n",
            "===\n",
            "start before shifting:  657\n",
            "11\n",
            "start:  646\n",
            "тивного \n",
            "===\n",
            "start before shifting:  704\n",
            "11\n",
            "start:  693\n",
            "енения. \n",
            "===\n",
            "start before shifting:  719\n",
            "11\n",
            "start:  708\n",
            "с в техн\n",
            "===\n",
            "start before shifting:  771\n",
            "11\n",
            "start:  760\n",
            "вызывае\n",
            "===\n",
            "start before shifting:  913\n",
            "11\n",
            "start:  902\n",
            " нашей \n",
            "===\n",
            "start before shifting:  936\n",
            "11\n",
            "start:  925\n",
            "ерить, что мы \n",
            "===\n",
            "start before shifting:  1054\n",
            "11\n",
            "start:  1043\n",
            "ения ка\n",
            "===\n",
            "start before shifting:  1156\n",
            "11\n",
            "start:  1145\n",
            "одня и как\n",
            "===\n",
            "start before shifting:  1573\n",
            "11\n",
            "start:  1562\n",
            "OpenAI г\n",
            "===\n",
            "start before shifting:  1591\n",
            "11\n",
            "start:  1580\n",
            "«Мы об\n",
            "===\n",
            "start before shifting:  1599\n",
            "11\n",
            "start:  1588\n",
            "или модель под на\n",
            "===\n",
            "start before shifting:  1616\n",
            "11\n",
            "start:  1605\n",
            "званием ChatGPT, которая\n",
            "===\n",
            "start before shifting:  1640\n",
            "11\n",
            "start:  1629\n",
            " взаимодействует в разговорн\n",
            "===\n",
            "start before shifting:  1692\n",
            "11\n",
            "start:  1681\n",
            "а по\n",
            "===\n",
            "start before shifting:  1697\n",
            "11\n",
            "start:  1686\n",
            "воляет ChatGPT о\n",
            "===\n",
            "start before shifting:  1854\n",
            "11\n",
            "start:  1843\n",
            "одели Op\n",
            "===\n",
            "start before shifting:  1855\n",
            "11\n",
            "start:  1844\n",
            "дели Ope\n",
            "===\n",
            "======\n",
            "text_747330.txt\n",
            "start before shifting:  9\n",
            "2\n",
            "start:  7\n",
            "риру\n",
            "===\n",
            "start before shifting:  14\n",
            "2\n",
            "start:  12\n",
            "ить \n",
            "===\n",
            "start before shifting:  16\n",
            "2\n",
            "start:  14\n",
            "ь чат GP\n",
            "===\n",
            "start before shifting:  65\n",
            "2\n",
            "start:  63\n",
            "или он\n",
            "===\n",
            "start before shifting:  66\n",
            "2\n",
            "start:  64\n",
            "ли о\n",
            "===\n",
            "start before shifting:  84\n",
            "5\n",
            "start:  79\n",
            "         \n",
            "===\n",
            "start before shifting:  86\n",
            "5\n",
            "start:  81\n",
            "    \n",
            "===\n",
            "start before shifting:  108\n",
            "5\n",
            "start:  103\n",
            "чить чат\n",
            "===\n",
            "start before shifting:  148\n",
            "5\n",
            "start:  143\n",
            "быст\n",
            "===\n",
            "start before shifting:  156\n",
            "5\n",
            "start:  151\n",
            "— я \n",
            "===\n",
            "start before shifting:  160\n",
            "5\n",
            "start:  155\n",
            "или \n",
            "===\n",
            "start before shifting:  167\n",
            "5\n",
            "start:  162\n",
            " Rea\n",
            "===\n",
            "start before shifting:  179\n",
            "6\n",
            "start:  173\n",
            "me  \n",
            "    9 min\n",
            "  \n",
            "===\n",
            "start before shifting:  191\n",
            "7\n",
            "start:  184\n",
            "min\n",
            "   V\n",
            "===\n",
            "start before shifting:  287\n",
            "8\n",
            "start:  279\n",
            "\n",
            "   \n",
            "===\n",
            "start before shifting:  330\n",
            "9\n",
            "start:  321\n",
            "т Ма\n",
            "===\n",
            "start before shifting:  434\n",
            "9\n",
            "start:  425\n",
            "ак о\n",
            "===\n",
            "start before shifting:  460\n",
            "9\n",
            "start:  451\n",
            "по-прежнему нет. В\n",
            "===\n",
            "start before shifting:  609\n",
            "9\n",
            "start:  600\n",
            "чере\n",
            "===\n",
            "start before shifting:  861\n",
            "9\n",
            "start:  852\n",
            "с ни\n",
            "===\n",
            "start before shifting:  1072\n",
            "9\n",
            "start:  1063\n",
            "и: к\n",
            "===\n",
            "start before shifting:  1129\n",
            "9\n",
            "start:  1120\n",
            "фик,\n",
            "===\n",
            "start before shifting:  1557\n",
            "9\n",
            "start:  1548\n",
            "е се\n",
            "===\n",
            "start before shifting:  2141\n",
            "9\n",
            "start:  2132\n",
            "дит как \n",
            "===\n",
            "start before shifting:  2229\n",
            "9\n",
            "start:  2220\n",
            "-зад\n",
            "===\n",
            "start before shifting:  2336\n",
            "9\n",
            "start:  2327\n",
            "нить\n",
            "===\n",
            "start before shifting:  2457\n",
            "9\n",
            "start:  2448\n",
            "ует \n",
            "===\n",
            "start before shifting:  2626\n",
            "9\n",
            "start:  2617\n",
            "Stat\n",
            "===\n",
            "start before shifting:  3068\n",
            "9\n",
            "start:  3059\n",
            "отли\n",
            "===\n",
            "start before shifting:  3140\n",
            "9\n",
            "start:  3131\n",
            "льны\n",
            "===\n",
            "start before shifting:  3260\n",
            "9\n",
            "start:  3251\n",
            "техн\n",
            "===\n",
            "start before shifting:  3429\n",
            "9\n",
            "start:  3420\n",
            " соо\n",
            "===\n",
            "start before shifting:  3798\n",
            "9\n",
            "start:  3789\n",
            "ить \n",
            "===\n",
            "start before shifting:  3916\n",
            "9\n",
            "start:  3907\n",
            "крыв\n",
            "===\n",
            "start before shifting:  4007\n",
            "9\n",
            "start:  3998\n",
            ", за\n",
            "===\n",
            "start before shifting:  4053\n",
            "9\n",
            "start:  4044\n",
            "рило\n",
            "===\n",
            "start before shifting:  4109\n",
            "9\n",
            "start:  4100\n",
            "колько времени \n",
            "===\n",
            "start before shifting:  4125\n",
            "9\n",
            "start:  4116\n",
            "не п\n",
            "===\n",
            "start before shifting:  4236\n",
            "9\n",
            "start:  4227\n",
            "ия п\n",
            "===\n",
            "start before shifting:  4334\n",
            "9\n",
            "start:  4325\n",
            "z0qJ\n",
            "===\n",
            "start before shifting:  4545\n",
            "9\n",
            "start:  4536\n",
            "жени\n",
            "===\n",
            "start before shifting:  4728\n",
            "9\n",
            "start:  4719\n",
            "запр\n",
            "===\n",
            "start before shifting:  4794\n",
            "9\n",
            "start:  4785\n",
            " заняло ок\n",
            "===\n",
            "start before shifting:  4808\n",
            "9\n",
            "start:  4799\n",
            "2 минут, чтобы учесть все факторы и я\n",
            "===\n",
            "start before shifting:  4992\n",
            "9\n",
            "start:  4983\n",
            "а си\n",
            "===\n",
            "start before shifting:  5179\n",
            "9\n",
            "start:  5170\n",
            "и см\n",
            "===\n",
            "start before shifting:  5354\n",
            "9\n",
            "start:  5345\n",
            " где\n",
            "===\n",
            "start before shifting:  5444\n",
            "9\n",
            "start:  5435\n",
            "s6kj\n",
            "===\n",
            "start before shifting:  5671\n",
            "9\n",
            "start:  5662\n",
            "ьзов\n",
            "===\n",
            "start before shifting:  6031\n",
            "9\n",
            "start:  6022\n",
            "сех \n",
            "===\n",
            "start before shifting:  6110\n",
            "9\n",
            "start:  6101\n",
            "ть, \n",
            "===\n",
            "start before shifting:  6167\n",
            "9\n",
            "start:  6158\n",
            "уре,\n",
            "===\n",
            "start before shifting:  6373\n",
            "9\n",
            "start:  6364\n",
            "терн\n",
            "===\n",
            "start before shifting:  6551\n",
            "9\n",
            "start:  6542\n",
            "яетс\n",
            "===\n",
            "start before shifting:  6751\n",
            "9\n",
            "start:  6742\n",
            ", GPT не о\n",
            "===\n",
            "start before shifting:  6908\n",
            "9\n",
            "start:  6899\n",
            "тро \n",
            "===\n",
            "start before shifting:  6959\n",
            "9\n",
            "start:  6950\n",
            "ть GPT объяснить, \n",
            "===\n",
            "start before shifting:  7014\n",
            "9\n",
            "start:  7005\n",
            "те. По\n",
            "===\n",
            "start before shifting:  7104\n",
            "9\n",
            "start:  7095\n",
            "шет функциональность класса, реализуемые протоколы и другие сведе\n",
            "===\n",
            "start before shifting:  7216\n",
            "9\n",
            "start:  7207\n",
            " код и\n",
            "===\n",
            "start before shifting:  7222\n",
            "9\n",
            "start:  7213\n",
            " попросить предложить улучшения.В сущно\n",
            "===\n",
            "start before shifting:  7331\n",
            "9\n",
            "start:  7322\n",
            "олагатьс\n",
            "===\n",
            "start before shifting:  7360\n",
            "9\n",
            "start:  7351\n",
            " но ин\n",
            "===\n",
            "start before shifting:  7486\n",
            "9\n",
            "start:  7477\n",
            "ать функции высшего порядка\n",
            "===\n",
            "start before shifting:  7536\n",
            "9\n",
            "start:  7527\n",
            "и этот\n",
            "===\n",
            "start before shifting:  7546\n",
            "9\n",
            "start:  7537\n",
            "ент.Если нет вариантов решения или готовых\n",
            "===\n",
            "start before shifting:  7888\n",
            "9\n",
            "start:  7879\n",
            "тации.Как \n",
            "===\n",
            "start before shifting:  8312\n",
            "9\n",
            "start:  8303\n",
            "ь во\n",
            "===\n",
            "start before shifting:  8326\n",
            "9\n",
            "start:  8317\n",
            "рианты реализации.Это стандартный подход к с\n",
            "===\n",
            "start before shifting:  8619\n",
            "9\n",
            "start:  8610\n",
            "стим\n",
            "===\n",
            "start before shifting:  8767\n",
            "9\n",
            "start:  8758\n",
            "бу.Н\n",
            "===\n",
            "start before shifting:  9376\n",
            "9\n",
            "start:  9367\n",
            " с G\n",
            "===\n",
            "start before shifting:  9749\n",
            "9\n",
            "start:  9740\n",
            "анны\n",
            "===\n",
            "start before shifting:  9941\n",
            "9\n",
            "start:  9932\n",
            "т-бо\n",
            "===\n",
            "start before shifting:  10139\n",
            "9\n",
            "start:  10130\n",
            "s — \n",
            "===\n",
            "start before shifting:  10885\n",
            "9\n",
            "start:  10876\n",
            "адач\n",
            "===\n",
            "start before shifting:  11117\n",
            "9\n",
            "start:  11108\n",
            "е мо\n",
            "===\n",
            "start before shifting:  11156\n",
            "9\n",
            "start:  11147\n",
            " гов\n",
            "===\n",
            "start before shifting:  11707\n",
            "9\n",
            "start:  11698\n",
            "ешние зави\n",
            "===\n",
            "======\n",
            "text_79830.txt\n",
            "start before shifting:  4\n",
            "2\n",
            "start:  2\n",
            "Заметки об NLP (час\n",
            "===\n",
            "start before shifting:  13\n",
            "2\n",
            "start:  11\n",
            "б NL\n",
            "===\n",
            "start before shifting:  14\n",
            "2\n",
            "start:  12\n",
            " NLP (часть 3) / Ha\n",
            "===\n",
            "start before shifting:  88\n",
            "5\n",
            "start:  83\n",
            "и об\n",
            "===\n",
            "start before shifting:  102\n",
            "5\n",
            "start:  97\n",
            "ь 3) Artificial Intellig\n",
            "===\n",
            "start before shifting:  126\n",
            "5\n",
            "start:  121\n",
            "ence Natural Language Proces\n",
            "===\n",
            "start before shifting:  419\n",
            "7\n",
            "start:  412\n",
            "я, как синтаксический \n",
            "===\n",
            "start before shifting:  441\n",
            "7\n",
            "start:  434\n",
            "анализ предл\n",
            "===\n",
            "start before shifting:  467\n",
            "7\n",
            "start:  460\n",
            "лийски p\n",
            "===\n",
            "start before shifting:  527\n",
            "7\n",
            "start:  520\n",
            "афа, «каким-либо обр\n",
            "===\n",
            "start before shifting:  567\n",
            "7\n",
            "start:  560\n",
            "руктуру п\n",
            "===\n",
            "start before shifting:  742\n",
            "8\n",
            "start:  734\n",
            "мках одной концепции\n",
            "===\n",
            "start before shifting:  827\n",
            "8\n",
            "start:  819\n",
            "ичаться \n",
            "===\n",
            "start before shifting:  875\n",
            "8\n",
            "start:  867\n",
            "морфолог\n",
            "===\n",
            "start before shifting:  906\n",
            "8\n",
            "start:  898\n",
            "шла речь в \n",
            "===\n",
            "start before shifting:  959\n",
            "10\n",
            "start:  949\n",
            "о надо разделить способы \n",
            "===\n",
            "start before shifting:  1025\n",
            "10\n",
            "start:  1015\n",
            "мостей на phrase structure-base\n",
            "===\n",
            "start before shifting:  1053\n",
            "10\n",
            "start:  1043\n",
            "ased pars\n",
            "===\n",
            "start before shifting:  1058\n",
            "10\n",
            "start:  1048\n",
            "parsing и dependenc\n",
            "===\n",
            "start before shifting:  1237\n",
            "12\n",
            "start:  1225\n",
            " пока не дойдём \n",
            "===\n",
            "start before shifting:  1277\n",
            "12\n",
            "start:  1265\n",
            " иллюстрирует ри\n",
            "===\n",
            "start before shifting:  1288\n",
            "12\n",
            "start:  1276\n",
            "ет рисунок\n",
            "===\n",
            "start before shifting:  1422\n",
            "15\n",
            "start:  1407\n",
            "х-либо вспомогат\n",
            "===\n",
            "start before shifting:  1451\n",
            "18\n",
            "start:  1433\n",
            "ов:\n",
            "\n",
            "\n",
            "Сраз\n",
            "===\n",
            "start before shifting:  1497\n",
            "18\n",
            "start:  1479\n",
            " второго подхода (d\n",
            "===\n",
            "start before shifting:  1534\n",
            "18\n",
            "start:  1516\n",
            ", но оба они заслужив\n",
            "===\n",
            "start before shifting:  1571\n",
            "20\n",
            "start:  1551\n",
            "льного о\n",
            "===\n",
            "start before shifting:  1624\n",
            "20\n",
            "start:  1604\n",
            "ющим» явно вырос из\n",
            "===\n",
            "start before shifting:  1634\n",
            "20\n",
            "start:  1614\n",
            " вырос из\n",
            "===\n",
            "start before shifting:  1663\n",
            "20\n",
            "start:  1643\n",
            " Если кто не знает, \n",
            "===\n",
            "start before shifting:  1687\n",
            "20\n",
            "start:  1667\n",
            "матика Хомского пре\n",
            "===\n",
            "start before shifting:  1704\n",
            "20\n",
            "start:  1684\n",
            "редставля\n",
            "===\n",
            "start before shifting:  1755\n",
            "20\n",
            "start:  1735\n",
            "х предложения языка.\n",
            "===\n",
            "start before shifting:  1806\n",
            "20\n",
            "start:  1786\n",
            "но как\n",
            "===\n",
            "start before shifting:  1894\n",
            "20\n",
            "start:  1874\n",
            " «язык», со\n",
            "===\n",
            "start before shifting:  1963\n",
            "20\n",
            "start:  1943\n",
            "дует произвольное к\n",
            "===\n",
            "======\n",
            "text_716918.txt\n",
            "start before shifting:  15\n",
            "2\n",
            "start:  13\n",
            "т ChatGP\n",
            "===\n",
            "start before shifting:  15\n",
            "2\n",
            "start:  13\n",
            "т ChatGP\n",
            "===\n",
            "start before shifting:  35\n",
            "2\n",
            "start:  33\n",
            " на п\n",
            "===\n",
            "start before shifting:  51\n",
            "2\n",
            "start:  49\n",
            "ком эвол\n",
            "===\n",
            "start before shifting:  86\n",
            "2\n",
            "start:  84\n",
            "до чуда \n",
            "===\n",
            "start before shifting:  119\n",
            "5\n",
            "start:  114\n",
            "  Как \n",
            "===\n",
            "start before shifting:  129\n",
            "5\n",
            "start:  124\n",
            "тает Cha\n",
            "===\n",
            "start before shifting:  142\n",
            "5\n",
            "start:  137\n",
            " объясняем на прос\n",
            "===\n",
            "start before shifting:  161\n",
            "5\n",
            "start:  156\n",
            "ом рус\n",
            "===\n",
            "start before shifting:  175\n",
            "5\n",
            "start:  170\n",
            "люцию языковых \n",
            "===\n",
            "start before shifting:  204\n",
            "5\n",
            "start:  199\n",
            "о чуда L\n",
            "===\n",
            "start before shifting:  245\n",
            "7\n",
            "start:  238\n",
            "  Reading \n",
            "===\n",
            "start before shifting:  247\n",
            "7\n",
            "start:  240\n",
            "Reading time  \n",
            "\n",
            "===\n",
            "start before shifting:  261\n",
            "8\n",
            "start:  253\n",
            " \n",
            "    30\n",
            "===\n",
            "start before shifting:  263\n",
            "8\n",
            "start:  255\n",
            "    30 m\n",
            "===\n",
            "start before shifting:  301\n",
            "9\n",
            "start:  292\n",
            "cience\n",
            "===\n",
            "start before shifting:  375\n",
            "9\n",
            "start:  366\n",
            " is here\n",
            "===\n",
            "start before shifting:  388\n",
            "9\n",
            "start:  379\n",
            "ral Langua\n",
            "===\n",
            "start before shifting:  402\n",
            "9\n",
            "start:  393\n",
            "rocessing * \n",
            "    R\n",
            "===\n",
            "start before shifting:  404\n",
            "9\n",
            "start:  395\n",
            "cessing\n",
            "===\n",
            "start before shifting:  408\n",
            "10\n",
            "start:  398\n",
            "sing * \n",
            "    \n",
            "===\n",
            "start before shifting:  552\n",
            "11\n",
            "start:  541\n",
            "и, и поч\n",
            "===\n",
            "start before shifting:  2516\n",
            "11\n",
            "start:  2505\n",
            "лачениемОткуда нейросе\n",
            "===\n",
            "start before shifting:  2541\n",
            "11\n",
            "start:  2530\n",
            "берут \n",
            "===\n",
            "start before shifting:  3177\n",
            "11\n",
            "start:  3166\n",
            "ачала понять, чем он точно\n",
            "===\n",
            "start before shifting:  3854\n",
            "11\n",
            "start:  3843\n",
            "за \n",
            "===\n",
            "start before shifting:  3861\n",
            "11\n",
            "start:  3850\n",
            " угадыва\n",
            "===\n",
            "start before shifting:  4083\n",
            "11\n",
            "start:  4072\n",
            "рые могли бы идт\n",
            "===\n",
            "start before shifting:  4134\n",
            "11\n",
            "start:  4123\n",
            "и с такой «пр\n",
            "===\n",
            "start before shifting:  4261\n",
            "11\n",
            "start:  4250\n",
            "сит в меня каменьИ\n",
            "===\n",
            "start before shifting:  4349\n",
            "11\n",
            "start:  4338\n",
            " простую за\n",
            "===\n",
            "start before shifting:  4400\n",
            "11\n",
            "start:  4389\n",
            "его \n",
            "===\n",
            "start before shifting:  4405\n",
            "11\n",
            "start:  4394\n",
            "лова. Это и есть языко\n",
            "===\n",
            "start before shifting:  4677\n",
            "11\n",
            "start:  4666\n",
            "х или ин\n",
            "===\n",
            "start before shifting:  5368\n",
            "11\n",
            "start:  5357\n",
            " Samsu\n",
            "===\n",
            "start before shifting:  5453\n",
            "11\n",
            "start:  5442\n",
            "арплат\n",
            "===\n",
            "start before shifting:  8704\n",
            "11\n",
            "start:  8693\n",
            " чере\n",
            "===\n",
            "start before shifting:  8892\n",
            "11\n",
            "start:  8881\n",
            " заче\n",
            "===\n",
            "start before shifting:  8898\n",
            "11\n",
            "start:  8887\n",
            " языко\n",
            "===\n",
            "start before shifting:  8976\n",
            "11\n",
            "start:  8965\n",
            "ве \n",
            "===\n",
            "start before shifting:  9032\n",
            "11\n",
            "start:  9021\n",
            "ько конк\n",
            "===\n",
            "start before shifting:  9098\n",
            "11\n",
            "start:  9087\n",
            "отор\n",
            "===\n",
            "start before shifting:  9217\n",
            "11\n",
            "start:  9206\n",
            "слово дл\n",
            "===\n",
            "start before shifting:  9246\n",
            "11\n",
            "start:  9235\n",
            "е ра\n",
            "===\n",
            "start before shifting:  9271\n",
            "11\n",
            "start:  9260\n",
            "ольшой игры.Правила такие: вы притв\n",
            "===\n",
            "start before shifting:  9435\n",
            "11\n",
            "start:  9424\n",
            "то Бара\n",
            "===\n",
            "start before shifting:  9452\n",
            "11\n",
            "start:  9441\n",
            "ставь\n",
            "===\n",
            "start before shifting:  9650\n",
            "11\n",
            "start:  9639\n",
            "вероятностью 100%, то позд\n",
            "===\n",
            "start before shifting:  9677\n",
            "11\n",
            "start:  9666\n",
            "авл\n",
            "===\n",
            "start before shifting:  9807\n",
            "11\n",
            "start:  9796\n",
            "зид\n",
            "===\n",
            "start before shifting:  9944\n",
            "11\n",
            "start:  9933\n",
            "одель должна\n",
            "===\n",
            "start before shifting:  10398\n",
            "11\n",
            "start:  10387\n",
            "о «случайным»\n",
            "===\n",
            "start before shifting:  10537\n",
            "11\n",
            "start:  10526\n",
            "роятностям, которые подсказывают м\n",
            "===\n",
            "start before shifting:  11108\n",
            "11\n",
            "start:  11097\n",
            "ет вариативно\n",
            "===\n",
            "start before shifting:  11229\n",
            "11\n",
            "start:  11218\n",
            "пос\n",
            "===\n",
            "start before shifting:  11722\n",
            "11\n",
            "start:  11711\n",
            "обов в\n",
            "===\n",
            "start before shifting:  11740\n",
            "11\n",
            "start:  11729\n",
            "ях, т\n",
            "===\n",
            "start before shifting:  12006\n",
            "11\n",
            "start:  11995\n",
            "роятн\n",
            "===\n",
            "start before shifting:  12012\n",
            "11\n",
            "start:  12001\n",
            "сти сл\n",
            "===\n",
            "start before shifting:  13444\n",
            "11\n",
            "start:  13433\n",
            " — от \n",
            "===\n",
            "start before shifting:  13738\n",
            "11\n",
            "start:  13727\n",
            "й вычис\n",
            "===\n",
            "start before shifting:  13747\n",
            "11\n",
            "start:  13736\n",
            "тельн\n",
            "===\n",
            "start before shifting:  13873\n",
            "11\n",
            "start:  13862\n",
            "е тоже\n",
            "===\n",
            "start before shifting:  14251\n",
            "11\n",
            "start:  14240\n",
            " которы\n",
            "===\n",
            "start before shifting:  14344\n",
            "11\n",
            "start:  14333\n",
            "кряхтет\n",
            "===\n",
            "start before shifting:  15018\n",
            "11\n",
            "start:  15007\n",
            " навер\n",
            "===\n",
            "start before shifting:  15214\n",
            "11\n",
            "start:  15203\n",
            "ой обр\n",
            "===\n",
            "start before shifting:  15399\n",
            "11\n",
            "start:  15388\n",
            "язи ти\n",
            "===\n",
            "start before shifting:  16788\n",
            "11\n",
            "start:  16777\n",
            "хотим н\n",
            "===\n",
            "start before shifting:  17741\n",
            "11\n",
            "start:  17730\n",
            "раметр\n",
            "===\n",
            "start before shifting:  17821\n",
            "11\n",
            "start:  17810\n",
            "бличных\n",
            "===\n",
            "start before shifting:  18134\n",
            "11\n",
            "start:  18123\n",
            " гипер\n",
            "===\n",
            "start before shifting:  18288\n",
            "11\n",
            "start:  18277\n",
            "ные из\n",
            "===\n",
            "start before shifting:  18980\n",
            "11\n",
            "start:  18969\n",
            "T-2 по\n",
            "===\n",
            "start before shifting:  19335\n",
            "11\n",
            "start:  19324\n",
            "ё собр\n",
            "===\n",
            "start before shifting:  20176\n",
            "11\n",
            "start:  20165\n",
            "ов? Ха\n",
            "===\n",
            "start before shifting:  20853\n",
            "11\n",
            "start:  20842\n",
            "тем со\n",
            "===\n",
            "start before shifting:  21663\n",
            "11\n",
            "start:  21652\n",
            "и. А н\n",
            "===\n",
            "start before shifting:  21677\n",
            "11\n",
            "start:  21666\n",
            "ди ри\n",
            "===\n",
            "start before shifting:  22047\n",
            "11\n",
            "start:  22036\n",
            " вот \n",
            "===\n",
            "start before shifting:  22053\n",
            "11\n",
            "start:  22042\n",
            "PT-2 у\n",
            "===\n",
            "start before shifting:  22163\n",
            "11\n",
            "start:  22152\n",
            "итичес\n",
            "===\n",
            "start before shifting:  22180\n",
            "11\n",
            "start:  22169\n",
            "ия необ\n",
            "===\n",
            "start before shifting:  22298\n",
            "11\n",
            "start:  22287\n",
            "мы). \n",
            "===\n",
            "start before shifting:  22335\n",
            "11\n",
            "start:  22324\n",
            " напра\n",
            "===\n",
            "start before shifting:  22537\n",
            "11\n",
            "start:  22526\n",
            "ыдилис\n",
            "===\n",
            "start before shifting:  22663\n",
            "11\n",
            "start:  22652\n",
            "ется ориги\n",
            "===\n",
            "start before shifting:  22923\n",
            "11\n",
            "start:  22912\n",
            "имер, \n",
            "===\n",
            "start before shifting:  23060\n",
            "11\n",
            "start:  23049\n",
            "е пора\n",
            "===\n",
            "start before shifting:  23751\n",
            "11\n",
            "start:  23740\n",
            " разны\n",
            "===\n",
            "start before shifting:  23857\n",
            "11\n",
            "start:  23846\n",
            "ном пр\n",
            "===\n",
            "start before shifting:  24029\n",
            "11\n",
            "start:  24018\n",
            " решают такие\n",
            "===\n",
            "start before shifting:  24046\n",
            "11\n",
            "start:  24035\n",
            "ачи правил\n",
            "===\n",
            "start before shifting:  24059\n",
            "11\n",
            "start:  24048\n",
            " примерно в\n",
            "===\n",
            "start before shifting:  24091\n",
            "11\n",
            "start:  24080\n",
            "анние \n",
            "===\n",
            "start before shifting:  24443\n",
            "11\n",
            "start:  24432\n",
            " ее на\n",
            "===\n",
            "start before shifting:  24477\n",
            "11\n",
            "start:  24466\n",
            "И со старым\n",
            "===\n",
            "start before shifting:  24832\n",
            "11\n",
            "start:  24821\n",
            "тот самый п\n",
            "===\n",
            "start before shifting:  25637\n",
            "11\n",
            "start:  25626\n",
            "одель \n",
            "===\n",
            "start before shifting:  26078\n",
            "11\n",
            "start:  26067\n",
            "щая но\n",
            "===\n",
            "start before shifting:  26103\n",
            "11\n",
            "start:  26092\n",
            "3, уже\n",
            "===\n",
            "start before shifting:  26784\n",
            "11\n",
            "start:  26773\n",
            " в глаз\n",
            "===\n",
            "start before shifting:  27475\n",
            "11\n",
            "start:  27464\n",
            "ми проб\n",
            "===\n",
            "start before shifting:  27492\n",
            "11\n",
            "start:  27481\n",
            " нес\n",
            "===\n",
            "start before shifting:  27509\n",
            "11\n",
            "start:  27498\n",
            "ов, и GPT-3 схвати\n",
            "===\n",
            "start before shifting:  29589\n",
            "11\n",
            "start:  29578\n",
            "нообра\n",
            "===\n",
            "start before shifting:  30211\n",
            "11\n",
            "start:  30200\n",
            "бще оз\n",
            "===\n",
            "start before shifting:  30225\n",
            "11\n",
            "start:  30214\n",
            " «мод\n",
            "===\n",
            "start before shifting:  30554\n",
            "11\n",
            "start:  30543\n",
            " (про\n",
            "===\n",
            "start before shifting:  30560\n",
            "11\n",
            "start:  30549\n",
            "пт, или «зап\n",
            "===\n",
            "start before shifting:  32017\n",
            "11\n",
            "start:  32006\n",
            "аботае\n",
            "===\n",
            "start before shifting:  32833\n",
            "11\n",
            "start:  32822\n",
            "линне\n",
            "===\n",
            "start before shifting:  33244\n",
            "11\n",
            "start:  33233\n",
            "чем вот этот «режи\n",
            "===\n",
            "start before shifting:  33263\n",
            "11\n",
            "start:  33252\n",
            " рассуждения»\n",
            "===\n",
            "start before shifting:  33278\n",
            "11\n",
            "start:  33267\n",
            " это од\n",
            "===\n",
            "start before shifting:  34130\n",
            "17\n",
            "start:  34113\n",
            "И снова рост\n",
            "===\n",
            "start before shifting:  34163\n",
            "17\n",
            "start:  34146\n",
            "внезапно\n",
            "===\n",
            "start before shifting:  34193\n",
            "17\n",
            "start:  34176\n",
            "модель\n",
            "===\n",
            "start before shifting:  35126\n",
            "17\n",
            "start:  35109\n",
            "ать и \n",
            "===\n",
            "start before shifting:  35463\n",
            "17\n",
            "start:  35446\n",
            "сли бы м\n",
            "===\n",
            "start before shifting:  35525\n",
            "17\n",
            "start:  35508\n",
            "более ра\n",
            "===\n",
            "start before shifting:  35554\n",
            "17\n",
            "start:  35537\n",
            "ые инструкци\n",
            "===\n",
            "start before shifting:  35586\n",
            "17\n",
            "start:  35569\n",
            "тавля\n",
            "===\n",
            "start before shifting:  35861\n",
            "17\n",
            "start:  35844\n",
            "стов \n",
            "===\n",
            "start before shifting:  35867\n",
            "17\n",
            "start:  35850\n",
            "з Интерн\n",
            "===\n",
            "start before shifting:  35935\n",
            "17\n",
            "start:  35918\n",
            "напис\n",
            "===\n",
            "start before shifting:  36002\n",
            "17\n",
            "start:  35985\n",
            "жденный таким образо\n",
            "===\n",
            "start before shifting:  36355\n",
            "17\n",
            "start:  36338\n",
            "ватели думал\n",
            "===\n",
            "start before shifting:  36418\n",
            "17\n",
            "start:  36401\n",
            "то свойс\n",
            "===\n",
            "start before shifting:  36434\n",
            "17\n",
            "start:  36417\n",
            "ли «точ\n",
            "===\n",
            "start before shifting:  37246\n",
            "17\n",
            "start:  37229\n",
            "ых спорн\n",
            "===\n",
            "start before shifting:  37267\n",
            "17\n",
            "start:  37250\n",
            " огро\n",
            "===\n",
            "start before shifting:  37289\n",
            "17\n",
            "start:  37272\n",
            "то четко фор\n",
            "===\n",
            "start before shifting:  37326\n",
            "17\n",
            "start:  37309\n",
            "редстав\n",
            "===\n",
            "start before shifting:  37407\n",
            "17\n",
            "start:  37390\n",
            "едние не\n",
            "===\n",
            "start before shifting:  37623\n",
            "17\n",
            "start:  37606\n",
            "чем прос\n",
            "===\n",
            "start before shifting:  37676\n",
            "17\n",
            "start:  37659\n",
            "каком-то смы\n",
            "===\n",
            "start before shifting:  37830\n",
            "17\n",
            "start:  37813\n",
            " реакцие\n",
            "===\n",
            "start before shifting:  38481\n",
            "17\n",
            "start:  38464\n",
            "т таким \n",
            "===\n",
            "start before shifting:  38583\n",
            "17\n",
            "start:  38566\n",
            "ной связ\n",
            "===\n",
            "start before shifting:  38780\n",
            "17\n",
            "start:  38763\n",
            " стал те\n",
            "===\n",
            "start before shifting:  39099\n",
            "17\n",
            "start:  39082\n",
            "х людей мо\n",
            "===\n",
            "start before shifting:  39132\n",
            "17\n",
            "start:  39115\n",
            "ться эт\n",
            "===\n",
            "start before shifting:  39208\n",
            "17\n",
            "start:  39191\n",
            "ным». В\n",
            "===\n",
            "start before shifting:  39530\n",
            "17\n",
            "start:  39513\n",
            " – но за\n",
            "===\n",
            "start before shifting:  39553\n",
            "17\n",
            "start:  39536\n",
            "дгоня\n",
            "===\n",
            "start before shifting:  40154\n",
            "17\n",
            "start:  40137\n",
            "чной с\n",
            "===\n",
            "start before shifting:  40174\n",
            "17\n",
            "start:  40157\n",
            "ным описа\n",
            "===\n",
            "start before shifting:  41535\n",
            "17\n",
            "start:  41518\n",
            " это з\n",
            "===\n",
            "start before shifting:  41563\n",
            "17\n",
            "start:  41546\n",
            "ёрды‑а\n",
            "===\n",
            "start before shifting:  41728\n",
            "17\n",
            "start:  41711\n",
            "туп \n",
            "===\n",
            "======\n",
            "text_750394.txt\n",
            "start before shifting:  3\n",
            "2\n",
            "start:  1\n",
            "\n",
            "Новый т\n",
            "===\n",
            "start before shifting:  3\n",
            "2\n",
            "start:  1\n",
            "\n",
            "Новый тест Тьюри\n",
            "===\n",
            "start before shifting:  8\n",
            "2\n",
            "start:  6\n",
            "й тест Тьюринг\n",
            "===\n",
            "start before shifting:  97\n",
            "5\n",
            "start:  92\n",
            "овый тест Тьюр\n",
            "===\n",
            "start before shifting:  103\n",
            "5\n",
            "start:  98\n",
            "ест Тьюри\n",
            "===\n",
            "start before shifting:  126\n",
            "5\n",
            "start:  121\n",
            " ИИ заработать 1 милл\n",
            "===\n",
            "start before shifting:  269\n",
            "8\n",
            "start:  261\n",
            "here      \n",
            "===\n",
            "start before shifting:  287\n",
            "9\n",
            "start:  278\n",
            "едыдущий тест \n",
            "===\n",
            "start before shifting:  296\n",
            "9\n",
            "start:  287\n",
            "тест Тьюринга \n",
            "===\n",
            "start before shifting:  320\n",
            "9\n",
            "start:  311\n",
            "т. Это с\n",
            "===\n",
            "start before shifting:  341\n",
            "9\n",
            "start:  332\n",
            "м по\n",
            "===\n",
            "start before shifting:  346\n",
            "9\n",
            "start:  337\n",
            "ле того, как сам разработчик Google н\n",
            "===\n",
            "start before shifting:  366\n",
            "9\n",
            "start:  357\n",
            "работчи\n",
            "===\n",
            "start before shifting:  372\n",
            "9\n",
            "start:  363\n",
            "ик Google начал бить тревогу\n",
            "===\n",
            "start before shifting:  459\n",
            "9\n",
            "start:  450\n",
            "о чатб\n",
            "===\n",
            "start before shifting:  469\n",
            "9\n",
            "start:  460\n",
            "aMDa, ко\n",
            "===\n",
            "start before shifting:  572\n",
            "9\n",
            "start:  563\n",
            " ИИ, то \n",
            "===\n",
            "start before shifting:  599\n",
            "9\n",
            "start:  590\n",
            " об обычных дом\n",
            "===\n",
            "start before shifting:  614\n",
            "9\n",
            "start:  605\n",
            "охозяйках. Обм\n",
            "===\n",
            "start before shifting:  676\n",
            "9\n",
            "start:  667\n",
            "ния\n",
            "===\n",
            "start before shifting:  710\n",
            "9\n",
            "start:  701\n",
            "ечатать. GP\n",
            "===\n",
            "start before shifting:  738\n",
            "9\n",
            "start:  729\n",
            "это с закрытым\n",
            "===\n",
            "start before shifting:  739\n",
            "9\n",
            "start:  730\n",
            "то с зак\n",
            "===\n",
            "start before shifting:  784\n",
            "9\n",
            "start:  775\n",
            "ессора \n",
            "===\n",
            "start before shifting:  814\n",
            "9\n",
            "start:  805\n",
            "нно потому что уме\n",
            "===\n",
            "start before shifting:  883\n",
            "9\n",
            "start:  874\n",
            " почитат\n",
            "===\n",
            "start before shifting:  905\n",
            "9\n",
            "start:  896\n",
            "уссию Ллео Кагано\n",
            "===\n",
            "start before shifting:  917\n",
            "9\n",
            "start:  908\n",
            "аганова \n",
            "===\n",
            "start before shifting:  923\n",
            "9\n",
            "start:  914\n",
            "а с ChatGPT.\n",
            "   \n",
            "===\n",
            "start before shifting:  965\n",
            "10\n",
            "start:  955\n",
            "аем что у GP\n",
            "===\n",
            "start before shifting:  968\n",
            "10\n",
            "start:  958\n",
            " что у\n",
            "===\n",
            "start before shifting:  969\n",
            "10\n",
            "start:  959\n",
            "что у GPT-моде\n",
            "===\n",
            "start before shifting:  969\n",
            "10\n",
            "start:  959\n",
            "что у GPT-моделей есть\n",
            "===\n",
            "start before shifting:  1001\n",
            "10\n",
            "start:  991\n",
            "ние. Хотя тест\n",
            "===\n",
            "start before shifting:  1126\n",
            "10\n",
            "start:  1116\n",
            "ьно ли ИИ\n",
            "===\n",
            "start before shifting:  1235\n",
            "11\n",
            "start:  1224\n",
            "создателе\n",
            "===\n",
            "start before shifting:  1344\n",
            "11\n",
            "start:  1333\n",
            ". В реальном мире. Если он\n",
            "===\n",
            "start before shifting:  1419\n",
            "11\n",
            "start:  1408\n",
            " победить — зн\n",
            "===\n",
            "======\n",
            "text_760298.txt\n",
            "start before shifting:  0\n",
            "0\n",
            "start:  0\n",
            "\n",
            "\n",
            "GPT-4: надеж\n",
            "===\n",
            "start before shifting:  2\n",
            "2\n",
            "start:  0\n",
            "\n",
            "\n",
            "GPT-\n",
            "===\n",
            "start before shifting:  57\n",
            "5\n",
            "start:  52\n",
            "br\n",
            "\n",
            "\n",
            "        \n",
            "===\n",
            "start before shifting:  72\n",
            "5\n",
            "start:  67\n",
            "      GPT-4: н\n",
            "===\n",
            "start before shifting:  73\n",
            "5\n",
            "start:  68\n",
            "     G\n",
            "===\n",
            "start before shifting:  73\n",
            "5\n",
            "start:  68\n",
            "     GPT-4: на\n",
            "===\n",
            "start before shifting:  98\n",
            "5\n",
            "start:  93\n",
            "трашны\n",
            "===\n",
            "start before shifting:  147\n",
            "6\n",
            "start:  141\n",
            "    Easy\n",
            "   Reading time  \n",
            "    9 m\n",
            "===\n",
            "start before shifting:  156\n",
            "7\n",
            "start:  149\n",
            "\n",
            "   Re\n",
            "===\n",
            "start before shifting:  182\n",
            "9\n",
            "start:  173\n",
            " min\n",
            "  \n",
            "===\n",
            "start before shifting:  188\n",
            "9\n",
            "start:  179\n",
            "  Views  3.9K О\n",
            "===\n",
            "start before shifting:  227\n",
            "9\n",
            "start:  218\n",
            "log Reading room Patenti\n",
            "===\n",
            "start before shifting:  232\n",
            "9\n",
            "start:  223\n",
            "eading \n",
            "===\n",
            "start before shifting:  245\n",
            "9\n",
            "start:  236\n",
            "atenti\n",
            "===\n",
            "start before shifting:  252\n",
            "9\n",
            "start:  243\n",
            "g *A\n",
            "===\n",
            "start before shifting:  255\n",
            "9\n",
            "start:  246\n",
            "Artifici\n",
            "===\n",
            "start before shifting:  257\n",
            "9\n",
            "start:  248\n",
            "tifici\n",
            "===\n",
            "start before shifting:  272\n",
            "10\n",
            "start:  262\n",
            "ligence  \n",
            "\n",
            "===\n",
            "start before shifting:  282\n",
            "10\n",
            "start:  272\n",
            "    Rev\n",
            "===\n",
            "start before shifting:  613\n",
            "11\n",
            "start:  602\n",
            "ного и\n",
            "===\n",
            "start before shifting:  689\n",
            "11\n",
            "start:  678\n",
            "гонку \n",
            "===\n",
            "start before shifting:  696\n",
            "11\n",
            "start:  685\n",
            "оделей\n",
            "===\n",
            "start before shifting:  703\n",
            "11\n",
            "start:  692\n",
            "универ\n",
            "===\n",
            "start before shifting:  710\n",
            "11\n",
            "start:  699\n",
            "ального,\n",
            "===\n",
            "start before shifting:  719\n",
            "11\n",
            "start:  708\n",
            "так называем\n",
            "===\n",
            "start before shifting:  732\n",
            "11\n",
            "start:  721\n",
            "го сегод\n",
            "===\n",
            "start before shifting:  800\n",
            "11\n",
            "start:  789\n",
            "а то\n",
            "===\n",
            "start before shifting:  1017\n",
            "11\n",
            "start:  1006\n",
            "темы верифика\n",
            "===\n",
            "start before shifting:  1031\n",
            "11\n",
            "start:  1020\n",
            "ии и марки\n",
            "===\n",
            "start before shifting:  1169\n",
            "11\n",
            "start:  1158\n",
            "ния ИИ в эконом\n",
            "===\n",
            "start before shifting:  1207\n",
            "11\n",
            "start:  1196\n",
            "ить ответствен\n",
            "===\n",
            "start before shifting:  1230\n",
            "11\n",
            "start:  1219\n",
            "вред. Похоже на полноценную па\n",
            "===\n",
            "start before shifting:  1355\n",
            "11\n",
            "start:  1344\n",
            " новый\n",
            "===\n",
            "start before shifting:  1438\n",
            "11\n",
            "start:  1427\n",
            "монстрир\n",
            "===\n",
            "start before shifting:  1454\n",
            "11\n",
            "start:  1443\n",
            " например, в в\n",
            "===\n",
            "start before shifting:  1521\n",
            "11\n",
            "start:  1510\n",
            "ть (особ\n",
            "===\n",
            "start before shifting:  1746\n",
            "11\n",
            "start:  1735\n",
            "аммное о\n",
            "===\n",
            "start before shifting:  1862\n",
            "11\n",
            "start:  1851\n",
            "ния набр\n",
            "===\n",
            "start before shifting:  1895\n",
            "11\n",
            "start:  1884\n",
            ": youtu\n",
            "===\n",
            "start before shifting:  1944\n",
            "11\n",
            "start:  1933\n",
            "ели \n",
            "===\n",
            "start before shifting:  2168\n",
            "11\n",
            "start:  2157\n",
            "ледован\n",
            "===\n",
            "start before shifting:  2234\n",
            "11\n",
            "start:  2223\n",
            "вой ит\n",
            "===\n",
            "start before shifting:  2388\n",
            "11\n",
            "start:  2377\n",
            "ия. Реа\n",
            "===\n",
            "start before shifting:  2431\n",
            "11\n",
            "start:  2420\n",
            "GPT-4 х\n",
            "===\n",
            "start before shifting:  2474\n",
            "11\n",
            "start:  2463\n",
            "мные, улучшились результаты по \n",
            "===\n",
            "start before shifting:  2518\n",
            "11\n",
            "start:  2507\n",
            "редыдущей мо\n",
            "===\n",
            "start before shifting:  2532\n",
            "11\n",
            "start:  2521\n",
            "лью, в\n",
            "===\n",
            "start before shifting:  3183\n",
            "11\n",
            "start:  3172\n",
            "авляет с\n",
            "===\n",
            "start before shifting:  3387\n",
            "11\n",
            "start:  3376\n",
            "щиеся пр\n",
            "===\n",
            "start before shifting:  4441\n",
            "11\n",
            "start:  4430\n",
            "самокр\n",
            "===\n",
            "start before shifting:  4537\n",
            "11\n",
            "start:  4526\n",
            "пании по создан\n",
            "===\n",
            "start before shifting:  4911\n",
            "11\n",
            "start:  4900\n",
            " Сэм А\n",
            "===\n",
            "start before shifting:  5071\n",
            "11\n",
            "start:  5060\n",
            "ющая изо\n",
            "===\n",
            "start before shifting:  5439\n",
            "11\n",
            "start:  5428\n",
            "брабаты\n",
            "===\n",
            "start before shifting:  5627\n",
            "11\n",
            "start:  5616\n",
            "Life Wi\n",
            "===\n",
            "start before shifting:  6475\n",
            "11\n",
            "start:  6464\n",
            "ашнем к\n",
            "===\n",
            "start before shifting:  6549\n",
            "11\n",
            "start:  6538\n",
            "ые из ни\n",
            "===\n",
            "start before shifting:  6632\n",
            "11\n",
            "start:  6621\n",
            "ющих вар\n",
            "===\n",
            "start before shifting:  6640\n",
            "11\n",
            "start:  6629\n",
            "иантов \n",
            "===\n",
            "start before shifting:  6755\n",
            "11\n",
            "start:  6744\n",
            "ные яды, то его такж\n",
            "===\n",
            "start before shifting:  6796\n",
            "11\n",
            "start:  6785\n",
            "для опреде\n",
            "===\n",
            "start before shifting:  6861\n",
            "11\n",
            "start:  6850\n",
            "оизводи\n",
            "===\n",
            "start before shifting:  6869\n",
            "11\n",
            "start:  6858\n",
            "ь в домашних условия\n",
            "===\n",
            "start before shifting:  6891\n",
            "11\n",
            "start:  6880\n",
            "и с использован\n",
            "===\n",
            "start before shifting:  6927\n",
            "11\n",
            "start:  6916\n",
            "атов, \n",
            "===\n",
            "start before shifting:  7088\n",
            "11\n",
            "start:  7077\n",
            "зовать\n",
            "===\n",
            "start before shifting:  7145\n",
            "11\n",
            "start:  7134\n",
            "ньги. Тот самый \n",
            "===\n",
            "start before shifting:  7338\n",
            "11\n",
            "start:  7327\n",
            "ил сет\n",
            "===\n",
            "start before shifting:  8774\n",
            "11\n",
            "start:  8763\n",
            "жем, н\n",
            "===\n",
            "start before shifting:  8802\n",
            "11\n",
            "start:  8791\n",
            "ения (на\n",
            "===\n",
            "start before shifting:  8861\n",
            "11\n",
            "start:  8850\n",
            "е). Прогр\n",
            "===\n",
            "start before shifting:  8887\n",
            "11\n",
            "start:  8876\n",
            "акже приг\n",
            "===\n",
            "start before shifting:  8988\n",
            "11\n",
            "start:  8977\n",
            "правл\n",
            "===\n",
            "start before shifting:  8995\n",
            "11\n",
            "start:  8984\n",
            "тся. Как г\n",
            "===\n",
            "start before shifting:  9014\n",
            "11\n",
            "start:  9003\n",
            "авнее исследование GitHub, время, \n",
            "===\n",
            "start before shifting:  9173\n",
            "11\n",
            "start:  9162\n",
            "Для работа\n",
            "===\n",
            "start before shifting:  9223\n",
            "11\n",
            "start:  9212\n",
            "ить в\n",
            "===\n",
            "start before shifting:  9623\n",
            "11\n",
            "start:  9612\n",
            "вестировал\n",
            "===\n",
            "start before shifting:  9652\n",
            "11\n",
            "start:  9641\n",
            " котора\n",
            "===\n",
            "start before shifting:  9702\n",
            "11\n",
            "start:  9691\n",
            " английский язык.\n",
            "===\n",
            "start before shifting:  10350\n",
            "11\n",
            "start:  10339\n",
            "ботник\n",
            "===\n",
            "start before shifting:  10356\n",
            "11\n",
            "start:  10345\n",
            " сможет с помощью ассистента выд\n",
            "===\n",
            "start before shifting:  11013\n",
            "11\n",
            "start:  11002\n",
            "карты»\n",
            "===\n",
            "start before shifting:  11021\n",
            "11\n",
            "start:  11010\n",
            "только зак\n",
            "===\n",
            "start before shifting:  11033\n",
            "11\n",
            "start:  11022\n",
            "ывают гла\n",
            "===\n",
            "start before shifting:  11402\n",
            "11\n",
            "start:  11391\n",
            "теграц\n",
            "===\n",
            "start before shifting:  11560\n",
            "11\n",
            "start:  11549\n",
            "rt, ко\n",
            "===\n",
            "======\n",
            "text_731102.txt\n",
            "start before shifting:  5\n",
            "2\n",
            "start:  3\n",
            "ышел Atlassian Intellige\n",
            "===\n",
            "start before shifting:  8\n",
            "2\n",
            "start:  6\n",
            "л Atlassian Intelligenc\n",
            "===\n",
            "start before shifting:  34\n",
            "2\n",
            "start:  32\n",
            " ИИ-помощник для Jira и\n",
            "===\n",
            "start before shifting:  39\n",
            "2\n",
            "start:  37\n",
            "омощник\n",
            "===\n",
            "start before shifting:  42\n",
            "2\n",
            "start:  40\n",
            "щник для Jira и Confluen\n",
            "===\n",
            "start before shifting:  49\n",
            "2\n",
            "start:  47\n",
            "я Jir\n",
            "===\n",
            "start before shifting:  49\n",
            "2\n",
            "start:  47\n",
            "я Jira \n",
            "===\n",
            "start before shifting:  52\n",
            "2\n",
            "start:  50\n",
            "ira и Confluence / Habr\n",
            "\n",
            "\n",
            "               Вы\n",
            "===\n",
            "start before shifting:  56\n",
            "2\n",
            "start:  54\n",
            "и Confluenc\n",
            "===\n",
            "start before shifting:  56\n",
            "2\n",
            "start:  54\n",
            "и Confluence / Habr\n",
            "\n",
            "\n",
            " \n",
            "===\n",
            "start before shifting:  69\n",
            "2\n",
            "start:  67\n",
            "/ Habr\n",
            "\n",
            "\n",
            "              \n",
            "===\n",
            "start before shifting:  80\n",
            "5\n",
            "start:  75\n",
            "\n",
            "      \n",
            "===\n",
            "start before shifting:  84\n",
            "5\n",
            "start:  79\n",
            "            Вышел Atlas\n",
            "===\n",
            "start before shifting:  93\n",
            "5\n",
            "start:  88\n",
            "   Вышел Atlassian Intelligen\n",
            "===\n",
            "start before shifting:  97\n",
            "5\n",
            "start:  92\n",
            "ышел Atlassian Intellig\n",
            "===\n",
            "start before shifting:  109\n",
            "5\n",
            "start:  104\n",
            "an Intel\n",
            "===\n",
            "start before shifting:  110\n",
            "5\n",
            "start:  105\n",
            "n Intelligence — ИИ-помо\n",
            "===\n",
            "start before shifting:  113\n",
            "5\n",
            "start:  108\n",
            "ntelligence — ИИ-помощник д\n",
            "===\n",
            "start before shifting:  138\n",
            "5\n",
            "start:  133\n",
            " для \n",
            "===\n",
            "start before shifting:  138\n",
            "5\n",
            "start:  133\n",
            " для Jira и Confluence \n",
            "===\n",
            "start before shifting:  145\n",
            "5\n",
            "start:  140\n",
            "ra и Conflu\n",
            "===\n",
            "start before shifting:  149\n",
            "5\n",
            "start:  144\n",
            " Confluence\n",
            "===\n",
            "start before shifting:  154\n",
            "5\n",
            "start:  149\n",
            "luence  \n",
            "===\n",
            "start before shifting:  160\n",
            "5\n",
            "start:  155\n",
            "  Re\n",
            "===\n",
            "start before shifting:  167\n",
            "5\n",
            "start:  162\n",
            "ng time  \n",
            "    2 min\n",
            "  \n",
            "===\n",
            "start before shifting:  168\n",
            "5\n",
            "start:  163\n",
            "g ti\n",
            "===\n",
            "start before shifting:  174\n",
            "6\n",
            "start:  168\n",
            "e  \n",
            "    2 min\n",
            "   V\n",
            "===\n",
            "start before shifting:  275\n",
            "7\n",
            "start:  268\n",
            "sian пр\n",
            "===\n",
            "start before shifting:  283\n",
            "7\n",
            "start:  276\n",
            "дстави\n",
            "===\n",
            "start before shifting:  290\n",
            "7\n",
            "start:  283\n",
            "а «в\n",
            "===\n",
            "start before shifting:  295\n",
            "7\n",
            "start:  288\n",
            "ртуаль\n",
            "===\n",
            "start before shifting:  302\n",
            "7\n",
            "start:  295\n",
            "ого товарищ\n",
            "===\n",
            "start before shifting:  315\n",
            "7\n",
            "start:  308\n",
            "по коман\n",
            "===\n",
            "start before shifting:  334\n",
            "7\n",
            "start:  327\n",
            "an Inte\n",
            "===\n",
            "start before shifting:  381\n",
            "7\n",
            "start:  374\n",
            "енной модели к\n",
            "===\n",
            "start before shifting:  477\n",
            "7\n",
            "start:  470\n",
            " создавать контент. \n",
            "===\n",
            "start before shifting:  498\n",
            "7\n",
            "start:  491\n",
            "н работает в с\n",
            "===\n",
            "start before shifting:  683\n",
            "7\n",
            "start:  676\n",
            "мер, подвести итоги встречи\n",
            "===\n",
            "======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset"
      ],
      "metadata": {
        "id": "A49x0V_ffobu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "splitted_texts_dir = \"./rucoco/kristina/kristinas_texts/splitted_texts\"\n",
        "dataset1 = {}\n",
        "\n",
        "def get_file_length(file_name: str):\n",
        "     with open(file_name, mode=\"r\", encoding=\"utf8\") as current_file:\n",
        "        return len(current_file.read())\n",
        "\n",
        "for file_name, data in dataset0.items():\n",
        "    if file_name in os.scandir(splitted_texts_dir):\n",
        "        dataset1[file_name] = data\n",
        "        continue\n",
        "\n",
        "    for obj in data:\n",
        "        offset = 0\n",
        "        i = 0\n",
        "        current_file_name = os.path.splitext(file_name)[0] + \"_\" + str(i) + \".txt\"\n",
        "        current_file_len = get_file_length(os.path.join(splitted_texts_dir,  current_file_name))\n",
        "\n",
        "        while obj[\"location\"][\"start\"] > current_file_len + offset:\n",
        "            offset += current_file_len + 1\n",
        "            i += 1\n",
        "            current_file_name = os.path.splitext(file_name)[0] + \"_\" + str(i) + \".txt\"\n",
        "            current_file_len = get_file_length(os.path.join(splitted_texts_dir,  current_file_name))\n",
        "\n",
        "        obj[\"location\"][\"start\"] -= offset\n",
        "        obj[\"location\"][\"end\"] -= offset\n",
        "\n",
        "        if current_file_name not in dataset1.keys():\n",
        "            dataset1[current_file_name] = []\n",
        "        dataset1[current_file_name].append(obj)"
      ],
      "metadata": {
        "id": "H5N3_EHKBcuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def is_useless(test_str):\n",
        "    symbols = set(string.whitespace + '\\n' + '\\r')\n",
        "    return set(test_str) <= symbols\n",
        "\n",
        "entries = [entry for entry in os.scandir(splitted_texts_dir) if entry.name.endswith(\".txt\")]\n",
        "for entry in entries:\n",
        "    with open(entry.path, mode=\"r\", encoding=\"utf-8\") as f:\n",
        "        print(\"check \" + entry.path)\n",
        "        if is_useless(f.read()):\n",
        "            os.remove(entry.path)\n",
        "            print(\"remove \" + entry.path)\n",
        "            continue\n",
        "    if entry.name not in dataset1.items():\n",
        "        dataset1[entry.name] = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O8rUhHY2D_3",
        "outputId": "4d4ea053-944b-49d5-c2d5-d7e18670ac57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_758406_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_16.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_9.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_18.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_542718_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_542718_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_19.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_731102_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_9.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_21.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_79830_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_8.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_15.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_17.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_12.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_542718_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_18.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_731102_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_79830_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_16.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_12.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_14.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_542718_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_11.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_23.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_14.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753914_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_10.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747330_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_12.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_760298_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_11.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_8.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753914_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737018_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_14.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_752672_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_8.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_20.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_9.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737018_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_758406_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747330_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_15.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_10.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_19.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_752672_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_760170_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_24.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_22.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_732240_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_9.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_13.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_752672_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753914_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_19.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_10.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_9.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_17.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_760170_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_542718_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_25.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_752672_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_716918_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_79830_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_20.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_760298_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_8.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_11.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_16.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_18.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_15.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_760170_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_12.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_17.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_5.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_26.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_756964_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_6.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_7.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_756964_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_8.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_747488_3.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_716918_1.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_750394_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_756964_2.txt\n",
            "remove ./rucoco/kristina/kristinas_texts/splitted_texts/text_756964_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_13.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_10.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_713920_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_751972_11.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_418701_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_753418_13.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_731102_2.txt\n",
            "remove ./rucoco/kristina/kristinas_texts/splitted_texts/text_731102_2.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_759210_4.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_737046_10.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_732240_0.txt\n",
            "check ./rucoco/kristina/kristinas_texts/splitted_texts/text_79830_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open((\"./rucoco/kristina/dataset_splitted.json\"), mode=\"w\", encoding=\"utf8\") as f:\n",
        "    json.dump(dataset1, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "fM_rJCyBr-PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "JWV2FBbM43R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CorefModel()\n",
        "model = model.load_from_checkpoint(\"./rucoco/lightning_logs/version_10_ru_Roberta_large_RuCoCo/checkpoints/last.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDg28xgfAlWT",
        "outputId": "1514f5ab-601e-4416-b5c6-4ce5c76c9516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ai-forever/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at ai-forever/ruRoberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\"\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "z_aGSBvxQxnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28176b7a-d368-420b-fd3e-abb9679b4647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CorefModel(\n",
              "  (encoder): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (token_importance_linear): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  (span_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (coarse_bilinear): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (coarse_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fine_linear): Sequential(\n",
              "    (0): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.k = 50"
      ],
      "metadata": {
        "id": "NUvuQkEGKfJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = copy.deepcopy(dataset1)"
      ],
      "metadata": {
        "id": "lh-GT0JyCuYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzhrXVLkEfa7"
      },
      "outputs": [],
      "source": [
        "logging.disable()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.disable(level=logging.NOTSET)"
      ],
      "metadata": {
        "id": "9_0o2wcOrE6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_dir = \"./rucoco/kristina/result_RuCoCo_semantics\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "entries = [entry for entry in os.scandir(\"./rucoco/kristina/kristinas_texts/splitted_texts\") if entry.name.endswith(\".txt\")]\n",
        "with torch.no_grad():\n",
        "    i = 0\n",
        "    for entry in tqdm(entries, leave=True):\n",
        "        i += 1\n",
        "        with open(entry.path, mode=\"r\", encoding=\"utf8\") as f:\n",
        "            print(entry.name)\n",
        "            data = {\"text\": f.read(), \"entities\": [], \"includes\": []}\n",
        "            doc = Doc(entry.name, data, dataset[entry.name], tokenizer=tokenizer, extract_all_spans=True)\n",
        "            # doc = Doc(entry.name, data, tokenizer=tokenizer, extract_all_spans=True)\n",
        "            char_entities = [\n",
        "                [doc.token_span_to_chars(span) for span in token_entity]\n",
        "                for token_entity in model.predict(doc)\n",
        "            ]\n",
        "            data[\"entities\"] = char_entities\n",
        "            data[\"includes\"] = [[] for _ in char_entities]\n",
        "            out_name = os.path.splitext(entry.name)[0] + \".json\"\n",
        "            with open(os.path.join(out_dir, out_name), mode=\"w\", encoding=\"utf8\") as f:\n",
        "                json.dump(data, f, ensure_ascii=False)\n",
        "    print(\"Files: \", i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImvALpSDD6q7",
        "outputId": "ae94515f-24f2-4659-99d1-73497b9d119d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                                                                                                                   | 0/151 [00:00<?, ?it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:text_750394_3.txt: skipping span (0, 76), '   Но это будет заработок не лично ИИ, а тех людей, которые его разработали.'\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "  2%|██▊                                                                                                                                        | 3/151 [00:00<00:06, 24.43it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_751972_9.txt: skipping span (617, 642), 'тестов с комментариями\\n  '\n",
            "WARNING:root:text_751972_9.txt: skipping span (626, 642), 'комментариями\\n  '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_753418_2.txt\n",
            "text_750394_3.txt\n",
            "text_753418_7.txt\n",
            "text_758406_0.txt\n",
            "text_418701_16.txt\n",
            "text_751972_9.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "  5%|██████▍                                                                                                                                    | 7/151 [00:00<00:04, 31.22it/s]WARNING:root:text_753418_18.txt: overlapping subtoken 31 at (84, 85); existing subtokens: None, 30\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "  7%|██████████                                                                                                                                | 11/151 [00:00<00:04, 31.44it/s]WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_747488_7.txt\n",
            "text_753418_18.txt\n",
            "text_542718_1.txt\n",
            "text_751972_2.txt\n",
            "text_753418_0.txt\n",
            "text_542718_0.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:text_751972_4.txt: skipping span (0, 26), '        Великие Старейшины'\n",
            "WARNING:root:text_751972_4.txt: skipping span (1638, 1654), 'дороге \\n        '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_759210_0.txt: skipping span (205, 375), ' Reading time  \\n    9 min\\n   Views  6.4K МТС corporate blog MTS AI corporate blog Machine learning *Artificial Intelligence Natural Language Processing *      Всем привет'\n",
            "WARNING:root:text_759210_0.txt: skipping span (1157, 1189), 'Ответ на вопрос по контексту\\n   '\n",
            "WARNING:root:semantic classes: []\n",
            " 10%|█████████████▋                                                                                                                            | 15/151 [00:00<00:04, 30.51it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 13%|█████████████████▎                                                                                                                        | 19/151 [00:00<00:04, 32.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_4.txt\n",
            "text_418701_19.txt\n",
            "text_759210_0.txt\n",
            "text_759210_5.txt\n",
            "text_731102_0.txt\n",
            "text_418701_1.txt\n",
            "text_751972_6.txt\n",
            "text_418701_9.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 15%|█████████████████████                                                                                                                     | 23/151 [00:00<00:03, 33.38it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_737046_12.txt: overlapping subtoken 318 at (1082, 1083); existing subtokens: None, 317\n",
            "WARNING:root:text_737046_12.txt: overlapping subtoken 393 at (1350, 1351); existing subtokens: None, 392\n",
            "WARNING:root:text_737046_12.txt: overlapping subtoken 473 at (1686, 1687); existing subtokens: None, 472\n",
            "WARNING:root:text_737046_12.txt: overlapping subtoken 641 at (2422, 2423); existing subtokens: None, 640\n",
            "WARNING:root:text_737046_12.txt: overlapping subtoken 679 at (2615, 2616); existing subtokens: None, 678\n",
            "WARNING:root:text_737046_12.txt: skipping span (3345, 3420), 'learning  Hubs: PythonMachine learningNatural Language Processing          '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_21.txt\n",
            "text_79830_3.txt\n",
            "text_753418_8.txt\n",
            "text_751972_15.txt\n",
            "text_418701_17.txt\n",
            "text_753418_6.txt\n",
            "text_737046_12.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|████████████████████████▋                                                                                                                 | 27/151 [00:00<00:03, 31.24it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_737046_1.txt: overlapping subtoken 995 at (4185, 4186); existing subtokens: None, 994\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_731102_1.txt: skipping span (2224, 2417), '     Tags: atlassianatlassian jirajiraconfluenceискусственный интеллектчат-ботпомощникразработкасовместная работаоблачные сервисы  Hubs: AtlassianCloud servicesArtificial Intelligence          '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_542718_2.txt\n",
            "text_418701_18.txt\n",
            "text_737046_1.txt\n",
            "text_731102_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|████████████████████████████▎                                                                                                             | 31/151 [00:01<00:04, 24.97it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_747488_6.txt: skipping span (993, 1014), 'Интернет будущего\\n   '\n",
            "WARNING:root:semantic classes: []\n",
            " 23%|███████████████████████████████▉                                                                                                          | 35/151 [00:01<00:04, 26.42it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:text_418701_0.txt: skipping span (10, 102), 'синтаксические парсеры для русского языка / Habr\\n\\n\\n               9  August  2018 at 09:00  '\n",
            "WARNING:root:text_418701_0.txt: skipping span (37, 102), 'русского языка / Habr\\n\\n\\n               9  August  2018 at 09:00  '\n",
            "WARNING:root:text_418701_0.txt: skipping span (54, 76), 'Habr\\n\\n\\n               '\n",
            "WARNING:root:text_418701_0.txt: skipping span (137, 233), 'русского языка Сбер corporate blog Programming *Machine learning *Artificial Intelligence       '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_79830_2.txt\n",
            "text_753418_16.txt\n",
            "text_751972_12.txt\n",
            "text_747488_6.txt\n",
            "text_737046_3.txt\n",
            "text_418701_0.txt\n",
            "text_418701_14.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            " 26%|███████████████████████████████████▋                                                                                                      | 39/151 [00:01<00:03, 28.47it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_753914_2.txt: skipping span (1480, 1569), 'не всеми возможностями ChatGPT \\n            17\\n           \\n            18.92%\\n           '\n",
            "WARNING:root:semantic classes: []\n",
            " 28%|███████████████████████████████████████▎                                                                                                  | 43/151 [00:01<00:03, 30.77it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_542718_4.txt\n",
            "text_737046_11.txt\n",
            "text_751972_23.txt\n",
            "text_753418_14.txt\n",
            "text_753914_2.txt\n",
            "text_753418_10.txt\n",
            "text_753418_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 31%|██████████████████████████████████████████▉                                                                                               | 47/151 [00:01<00:03, 31.22it/s]WARNING:root:text_760298_1.txt: skipping span (4660, 4703), 'Источник: businessinsider.com Сама OpenAI\\xa0 '\n",
            "WARNING:root:text_760298_1.txt: skipping span (4690, 4703), 'Сама OpenAI\\xa0 '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_747330_0.txt\n",
            "text_753418_12.txt\n",
            "text_760298_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 34%|██████████████████████████████████████████████▌                                                                                           | 51/151 [00:01<00:04, 22.69it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 36%|██████████████████████████████████████████████████▎                                                                                       | 55/151 [00:01<00:03, 25.55it/s]WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_753418_11.txt\n",
            "text_737046_8.txt\n",
            "text_753914_0.txt\n",
            "text_753418_3.txt\n",
            "text_737018_0.txt\n",
            "text_747488_0.txt\n",
            "text_750394_7.txt\n",
            "text_737046_5.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_752672_3.txt: skipping span (4923, 4944), 'генерация на RuGPT3  '\n",
            "WARNING:root:text_752672_3.txt: skipping span (4936, 4944), 'RuGPT3  '\n",
            "WARNING:root:text_752672_3.txt: skipping span (5423, 5628), 'искусственный интеллектнейронные сетиgptrugpt3nlpязыковые моделигенерация текстаобработка естественного языкаchatgptlarge language model  Hubs: Artificial Intelligence Natural Language Processing          '\n",
            "WARNING:root:text_752672_3.txt: skipping span (5497, 5628), 'текстаобработка естественного языкаchatgptlarge language model  Hubs: Artificial Intelligence Natural Language Processing          '\n",
            "WARNING:root:semantic classes: []\n",
            " 38%|█████████████████████████████████████████████████████                                                                                     | 58/151 [00:02<00:03, 23.91it/s]WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_14.txt\n",
            "text_752672_3.txt\n",
            "text_751972_8.txt\n",
            "text_751972_20.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 40%|███████████████████████████████████████████████████████▋                                                                                  | 61/151 [00:02<00:04, 20.06it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 236 at (941, 942); existing subtokens: None, 235\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 995 at (4531, 4532); existing subtokens: None, 994\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 1496 at (6602, 6603); existing subtokens: None, 1495\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 2505 at (11040, 11041); existing subtokens: None, 2504\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 2692 at (11926, 11927); existing subtokens: None, 2691\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 2707 at (11983, 11984); existing subtokens: None, 2706\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 2952 at (12964, 12965); existing subtokens: None, 2951\n",
            "WARNING:root:text_737018_1.txt: overlapping subtoken 3681 at (15944, 15945); existing subtokens: None, 3680\n",
            "WARNING:root:text_737018_1.txt: skipping span (0, 130), '   Views  3K SberDevices corporate blog Data Mining *Image processing *Machine learning *Artificial Intelligence       Всем привет'\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_737046_9.txt\n",
            "text_737046_2.txt\n",
            "text_737018_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_758406_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|██████████████████████████████████████████████████████████▍                                                                               | 64/151 [00:02<00:07, 11.41it/s]WARNING:root:text_747330_1.txt: overlapping subtoken 341 at (1299, 1300); existing subtokens: None, 340\n",
            "WARNING:root:text_747330_1.txt: overlapping subtoken 710 at (2917, 2918); existing subtokens: None, 709\n",
            "WARNING:root:text_747330_1.txt: overlapping subtoken 1582 at (6347, 6348); existing subtokens: None, 1581\n",
            "WARNING:root:text_747330_1.txt: skipping span (0, 19), '        Всем привет'\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_747330_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            " 44%|████████████████████████████████████████████████████████████▎                                                                             | 66/151 [00:03<00:07, 10.63it/s]WARNING:root:text_751972_10.txt: skipping span (1353, 1362), 'голове\\n  '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 46%|███████████████████████████████████████████████████████████████▉                                                                          | 70/151 [00:03<00:05, 14.16it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_418701_15.txt\n",
            "text_751972_10.txt\n",
            "text_759210_6.txt\n",
            "text_753418_19.txt\n",
            "text_713920_5.txt\n",
            "text_747488_4.txt\n",
            "text_752672_2.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 49%|███████████████████████████████████████████████████████████████████▋                                                                      | 74/151 [00:03<00:04, 17.98it/s]WARNING:root:text_751972_24.txt: skipping span (731, 746), 'обучения\\n      '\n",
            "WARNING:root:text_751972_24.txt: skipping span (911, 917), 'несу  '\n",
            "WARNING:root:text_751972_24.txt: skipping span (946, 952), 'несу  '\n",
            "WARNING:root:text_751972_24.txt: skipping span (1003, 1009), 'несу  '\n",
            "WARNING:root:text_751972_24.txt: skipping span (1017, 1042), 'несу\\n      Несу.н и  н   '\n",
            "WARNING:root:text_751972_24.txt: skipping span (1063, 1082), 'Ольга Дми еж\\n      '\n",
            "WARNING:root:text_751972_24.txt: skipping span (1073, 1082), 'еж\\n      '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_759210_1.txt: skipping span (0, 209), '   У YandexGPT тоже проблемы с этим вопросом:YandexGpt             Как отвечает LLaMa (после \"bot\"):Предложение обрывается из- за ограничения в количестве генерируемых токенов Prompt: \"У нас есть много курсов.'\n",
            "WARNING:root:text_759210_1.txt: skipping span (31, 67), 'этим вопросом:YandexGpt             '\n",
            "WARNING:root:text_759210_1.txt: skipping span (45, 67), 'YandexGpt             '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_751972_22.txt: skipping span (101, 142), \"x['text'].split('\\\\n<bot>: ')[1],\\n        \"\n",
            "WARNING:root:semantic classes: []\n",
            " 52%|███████████████████████████████████████████████████████████████████████▎                                                                  | 78/151 [00:03<00:03, 20.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_760170_0.txt\n",
            "text_418701_5.txt\n",
            "text_751972_24.txt\n",
            "text_759210_1.txt\n",
            "text_418701_3.txt\n",
            "text_751972_22.txt\n",
            "text_732240_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:text_732240_1.txt: skipping span (3826, 3838), 'нейросетью  '\n",
            "WARNING:root:text_732240_1.txt: skipping span (4222, 4237), '  Не только тон'\n",
            "WARNING:root:text_732240_1.txt: skipping span (7109, 7129), 'источники и цитаты  '\n",
            "WARNING:root:text_732240_1.txt: skipping span (7121, 7129), 'цитаты  '\n",
            "WARNING:root:text_732240_1.txt: skipping span (7693, 7717), ' Изучите первоисточники.'\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_747488_9.txt: skipping span (0, 103), '   Главный фактор ИИ, из-за которого за него все ухватились — невероятная возможность масштабироваться.'\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 54%|██████████████████████████████████████████████████████████████████████████                                                                | 81/151 [00:03<00:04, 17.32it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_747488_9.txt\n",
            "text_751972_13.txt\n",
            "text_750394_1.txt\n",
            "text_752672_1.txt\n",
            "text_753914_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            " 56%|████████████████████████████████████████████████████████████████████████████▊                                                             | 84/151 [00:03<00:04, 15.78it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 58%|████████████████████████████████████████████████████████████████████████████████▍                                                         | 88/151 [00:04<00:03, 19.60it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:text_713920_1.txt: overlapping subtoken 2094 at (8991, 8992); existing subtokens: None, 2093\n",
            "WARNING:root:text_713920_1.txt: overlapping subtoken 3775 at (16455, 16456); existing subtokens: None, 3774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_19.txt\n",
            "text_747488_10.txt\n",
            "text_713920_3.txt\n",
            "text_753418_9.txt\n",
            "text_750394_0.txt\n",
            "text_713920_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:text_713920_1.txt: skipping span (6236, 6276), 'счет этого они более интерпретируемы и  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (9579, 9620), 'распределение вероятностей на множестве  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (9609, 9620), 'множестве  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (10007, 10035), 'распределение вероятностей  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (10021, 10035), 'вероятностей  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (10120, 10130), 'Величина  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (10595, 10604), 'матрица  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (12167, 12177), 'значение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (12285, 12303), 'вероятностей для  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (12639, 12652), 'Коэффициент  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (12704, 12717), 'коэффициент  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (12951, 12961), 'величина  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13124, 13162), 'вероятность для любого значения  при  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13140, 13162), 'любого значения  при  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13208, 13240), 'вероятность истинного значения  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13220, 13240), 'истинного значения  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13468, 13499), 'конкретное численное значение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13570, 13618), 'вероятность (правдоподобие) наблюдаемых данных  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (13598, 13618), 'наблюдаемых данных  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (14786, 14817), 'среднеквадратичных отклонений  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (14979, 14990), 'константа  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (17214, 17353), ' - это количество неких событий, которые произошли в условиях  - например, количество посетителей тренажерного зала в зависимости от погоды'\n",
            "WARNING:root:text_713920_1.txt: skipping span (17361, 17376), 'распределение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (17767, 17782), 'распределение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (17809, 17820), 'дисперсия  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (17952, 17963), 'дисперсия  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (18730, 18756), 'некая случайная величина  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (18871, 18881), 'величина  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (21530, 21545), 'распределении  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (22370, 22385), 'распределение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (22801, 22809), 'модели  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (24111, 24136), 'задаче предсказания  по  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (24118, 24136), 'предсказания  по  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (24394, 24406), 'любой пары  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (24811, 24824), 'наша модель  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (24860, 24875), 'задача оценки  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (24867, 24875), 'оценки  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (25470, 25498), 'ожидаемой метрики качества  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (25488, 25498), 'качества  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (25872, 25906), 'большом размере тестовой выборки  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (25888, 25906), 'тестовой выборки  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (27725, 27750), 'обучающее распределение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (30598, 30626), 'наша статистическая модель  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (30999, 31034), 'любого распределения из множества  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (31023, 31034), 'множества  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (31081, 31092), 'множества  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (31747, 31779), 'какого множества распределений  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (31764, 31779), 'распределений  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (32202, 32211), 'выборка  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (32559, 32572), 'наша модель  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (32623, 32638), 'элементами из  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (33281, 33294), 'наша модель  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (33345, 33362), 'зависимостью от  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (35345, 35369), 'условное распределение  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (37649, 37698), ' вообще переход к вероятностной постановке задачи'\n",
            "WARNING:root:text_713920_1.txt: skipping span (38650, 38662), 'два числа:  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (39108, 39153), 'ожидание целевой переменной  и ее дисперсия  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (39139, 39153), 'ее дисперсия  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (39298, 39313), 'выражения для  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (39797, 39843), 'Высокое значение предсказанной неуверенности  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (39814, 39843), 'предсказанной неуверенности  '\n",
            "WARNING:root:text_713920_1.txt: skipping span (40137, 40154), 'самого значения  '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_751972_17.txt: skipping span (925, 1061), 'этот флаг:model = AutoGPTQForCausalLM.from_quantized(\\n        ...\\n        low_cpu_mem_usage=True, #Пониженное использование RAM\\n        '\n",
            "WARNING:root:text_751972_17.txt: skipping span (935, 1061), 'model = AutoGPTQForCausalLM.from_quantized(\\n        ...\\n        low_cpu_mem_usage=True, #Пониженное использование RAM\\n        '\n",
            "WARNING:root:text_751972_17.txt: skipping span (1024, 1061), 'Пониженное использование RAM\\n        '\n",
            "WARNING:root:text_751972_17.txt: skipping span (1049, 1061), 'RAM\\n        '\n",
            "WARNING:root:semantic classes: []\n",
            " 60%|███████████████████████████████████████████████████████████████████████████████████▏                                                      | 91/151 [00:04<00:05, 10.17it/s]WARNING:root:text_713920_7.txt: skipping span (639, 656), 'любого значения  '\n",
            "WARNING:root:text_713920_7.txt: skipping span (719, 730), 'изменение  '\n",
            "WARNING:root:text_713920_7.txt: skipping span (1132, 1152), 'стремлении  к  или  '\n",
            "WARNING:root:text_713920_7.txt: skipping span (1809, 1819), 'значение  '\n",
            "WARNING:root:text_713920_7.txt: skipping span (2412, 2673), 'статистическая модельметод максимального правдоподобиярегрессиянормальное распределениестатистикатеория вероятностейсреднеквадратичное отклонение  Hubs: Open Data Science corporate blogMathematicsMachine learningStatistics in ITArtificial Intelligence          '\n",
            "WARNING:root:text_713920_7.txt: skipping span (2516, 2673), 'вероятностейсреднеквадратичное отклонение  Hubs: Open Data Science corporate blogMathematicsMachine learningStatistics in ITArtificial Intelligence          '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_760170_1.txt: skipping span (1540, 1550), 'моделей   '\n",
            "WARNING:root:text_760170_1.txt: skipping span (2471, 2674), '  Davinchi –самая крупная модель OpenAI (для понимания: при обучении модели использовалось более 150 миллиардов обучающих блоков, тогда как GPT-3,5 и GPT-4 обучались всего на 6 миллиардах блоков данных).'\n",
            "WARNING:root:semantic classes: []\n",
            " 62%|████████████████████████████████████████████████████████████████████████████████████▉                                                     | 93/151 [00:04<00:05, 11.16it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_17.txt\n",
            "text_713920_7.txt\n",
            "text_760170_1.txt\n",
            "text_418701_4.txt\n",
            "text_542718_3.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            " 64%|███████████████████████████████████████████████████████████████████████████████████████▋                                                  | 96/151 [00:05<00:04, 12.25it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_752672_0.txt: skipping span (100, 254), 'Примеры генерации на русском языке (zero-shot coding)  Reading time  \\n    6 min\\n   Views  2.1K Artificial Intelligence Natural Language Processing *      '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_7.txt\n",
            "text_751972_25.txt\n",
            "text_750394_5.txt\n",
            "text_752672_0.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            " 66%|██████████████████████████████████████████████████████████████████████████████████████████▋                                              | 100/151 [00:05<00:03, 16.06it/s]WARNING:root:text_79830_0.txt: overlapping subtoken 412 at (1585, 1586); existing subtokens: None, 411\n",
            "WARNING:root:text_79830_0.txt: skipping span (13, 50), 'NLP (часть 3) / Habr\\n\\n\\n              '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 68%|█████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 103/151 [00:05<00:02, 18.10it/s]WARNING:root:text_751972_1.txt: skipping span (0, 96), '        Игра Данные Обертка Тесты UI Ещё тесты Fine-tune LoRADataset Результат Заключение Статья'\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_716918_0.txt\n",
            "text_79830_0.txt\n",
            "text_759210_2.txt\n",
            "text_751972_3.txt\n",
            "text_751972_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 70%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 106/151 [00:05<00:02, 18.93it/s]WARNING:root:text_751972_5.txt: skipping span (0, 83), '        Игре, которая состоит на 99% из дженерик текста, писанного анончиками, игра'\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_737046_6.txt\n",
            "text_753418_4.txt\n",
            "text_751972_5.txt\n",
            "text_759210_3.txt\n",
            "text_753418_20.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                      | 109/151 [00:05<00:02, 19.26it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_751972_0.txt: skipping span (39, 100), 'Генерация новеллы на ходу нейросетью / Habr\\n\\n\\n               '\n",
            "WARNING:root:text_751972_0.txt: skipping span (65, 100), 'нейросетью / Habr\\n\\n\\n               '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 113/151 [00:05<00:01, 23.45it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_747488_1.txt\n",
            "text_760298_0.txt\n",
            "text_751972_0.txt\n",
            "text_418701_8.txt\n",
            "text_418701_11.txt\n",
            "text_750394_6.txt\n",
            "text_751972_16.txt\n",
            "text_418701_7.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            " 77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 117/151 [00:05<00:01, 25.88it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_747488_5.txt: skipping span (0, 112), '   Но даже трудности Stack Overflow — мелочь по сравнению с теми изменениями, на которые предстоит пойти Google.'\n",
            "WARNING:root:semantic classes: []\n",
            " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 121/151 [00:05<00:01, 27.54it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_750394_2.txt: skipping span (1610, 1638), '\\n   ИИ — предприниматель\\n   '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_737046_4.txt\n",
            "text_751972_18.txt\n",
            "text_747488_2.txt\n",
            "text_747488_5.txt\n",
            "text_713920_6.txt\n",
            "text_753418_15.txt\n",
            "text_750394_2.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:text_760170_2.txt: skipping span (6672, 6700), 'Множество оттенков серого   '\n",
            "WARNING:root:text_760170_2.txt: skipping span (6682, 6700), 'оттенков серого   '\n",
            "WARNING:root:text_760170_2.txt: skipping span (11662, 11881), '     Tags: chatgptmachine learninginformation securityгенеративные моделинейросетиязыковые моделиgpt-4  Hubs: Security Vision corporate blog Machine learning Artificial Intelligence Natural Language Processing          '\n",
            "WARNING:root:semantic classes: []\n",
            " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 125/151 [00:06<00:01, 21.94it/s]WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_760170_2.txt\n",
            "text_418701_12.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:text_737046_7.txt: skipping span (905, 1205), 'это путь к данным внутри контейнера Airflow.from docker.types import Mount\\ndockerops_kwargs = {\\n    \"mount_tmp_dir\": False,\\n    \"mounts\": [\\n        Mount(\\n            source=\"<path_to_your_airflow-ml_repo>/data\",\\n            target=\"/opt/airflow/data/\",\\n            type=\"bind\",\\n        )\\n    ],\\n    '\n",
            "WARNING:root:text_737046_7.txt: skipping span (1022, 1205), 'False,\\n    \"mounts\": [\\n        Mount(\\n            source=\"<path_to_your_airflow-ml_repo>/data\",\\n            target=\"/opt/airflow/data/\",\\n            type=\"bind\",\\n        )\\n    ],\\n    '\n",
            "WARNING:root:semantic classes: []\n",
            " 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 129/151 [00:06<00:00, 24.48it/s]WARNING:root:text_751972_26.txt: skipping span (2515, 2728), 'новеллыtext generationtext adventuregpt3transformershuggingfaceигрыpythonнейросетиadventure  Hubs: Programming Machine learning Artificial Intelligence Games and game consoles Natural Language Processing          '\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_753418_17.txt\n",
            "text_753418_5.txt\n",
            "text_737046_7.txt\n",
            "text_751972_26.txt\n",
            "text_756964_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:text_756964_1.txt: skipping span (19101, 19205), 'ииалан тьюрингтест тьюрингаchatgpt  Hubs: Reading room Popular science Artificial Intelligence          '\n",
            "WARNING:root:text_756964_1.txt: skipping span (19108, 19205), 'тьюрингтест тьюрингаchatgpt  Hubs: Reading room Popular science Artificial Intelligence          '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 132/151 [00:06<00:01, 16.20it/s]WARNING:root:text_759210_7.txt: skipping span (683, 938), '     Tags: искусственный интеллектnlpязыковые моделиgigachatllamaмашинное обучениеобработка естественного языканейронные сети  Hubs: МТС corporate blog MTS AI corporate blog Machine learning Artificial Intelligence Natural Language Processing          \\n\\n\\n'\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 136/151 [00:06<00:00, 19.78it/s]WARNING:root:text_716918_1.txt: overlapping subtoken 663 at (2437, 2438); existing subtokens: None, 662\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 715 at (2598, 2599); existing subtokens: None, 714\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 2304 at (8506, 8507); existing subtokens: None, 2303\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 3875 at (14485, 14486); existing subtokens: None, 3874\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 5597 at (20852, 20853); existing subtokens: None, 5596\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 6833 at (25440, 25441); existing subtokens: None, 6832\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9095 at (33401, 33402); existing subtokens: 9094, 9094\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9096 at (33401, 33402); existing subtokens: 9094, 9094\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9098 at (33402, 33403); existing subtokens: 9097, 9097\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9099 at (33402, 33403); existing subtokens: 9097, 9097\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9101 at (33403, 33404); existing subtokens: 9100, 9100\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9102 at (33403, 33404); existing subtokens: 9100, 9100\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9143 at (33504, 33505); existing subtokens: 9142, 9142\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9144 at (33504, 33505); existing subtokens: 9142, 9142\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9146 at (33505, 33506); existing subtokens: 9145, 9145\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9147 at (33505, 33506); existing subtokens: 9145, 9145\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9149 at (33506, 33507); existing subtokens: 9148, 9148\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9150 at (33506, 33507); existing subtokens: 9148, 9148\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 9982 at (36559, 36560); existing subtokens: None, 9981\n",
            "WARNING:root:text_716918_1.txt: overlapping subtoken 12269 at (44968, 44969); existing subtokens: None, 12268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_418701_6.txt\n",
            "text_759210_7.txt\n",
            "text_756964_0.txt\n",
            "text_747488_8.txt\n",
            "text_747488_3.txt\n",
            "text_716918_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:text_716918_1.txt: skipping span (5950, 6008), 'весь наш массив данных на\\xa0графике: по\\xa0горизонтальной оси  '\n",
            "WARNING:root:text_716918_1.txt: skipping span (5975, 6008), '\\xa0графике: по\\xa0горизонтальной оси  '\n",
            "WARNING:root:text_716918_1.txt: skipping span (5987, 6008), '\\xa0горизонтальной оси  '\n",
            "WARNING:root:text_716918_1.txt: skipping span (6574, 6601), 'коэффициенты уравнения  и  '\n",
            "WARNING:root:text_716918_1.txt: skipping span (6587, 6601), 'уравнения  и  '\n",
            "WARNING:root:text_716918_1.txt: skipping span (45091, 45339), 'chatgptнейросетиopenaigptt9генеративные моделиязыковые моделимашинное обучениегенерацияnatural language processing  Hubs: Open Data Science corporate blogMachine learningArtificial IntelligenceThe future is hereNatural Language Processing          '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 139/151 [00:07<00:01,  8.65it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 142/151 [00:07<00:00, 10.62it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_750394_4.txt\n",
            "text_713920_0.txt\n",
            "text_713920_4.txt\n",
            "text_418701_13.txt\n",
            "text_418701_10.txt\n",
            "text_713920_2.txt\n",
            "text_737046_0.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 146/151 [00:07<00:00, 14.08it/s]WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n",
            " 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 149/151 [00:08<00:00, 16.32it/s]WARNING:root:text_732240_0.txt: skipping span (76, 108), 'бизнесе / Habr\\n\\n\\n               '\n",
            "WARNING:root:text_732240_0.txt: skipping span (86, 108), 'Habr\\n\\n\\n               '\n",
            "WARNING:root:semantic classes: []\n",
            "WARNING:root:semantic classes: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_751972_11.txt\n",
            "text_418701_2.txt\n",
            "text_753418_13.txt\n",
            "text_759210_4.txt\n",
            "text_737046_10.txt\n",
            "text_732240_0.txt\n",
            "text_79830_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 151/151 [00:08<00:00, 18.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files:  151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PyGg3amMeXJ6",
        "lRxQS9lTzXnl",
        "MqiFaV1myzbm",
        "I9eQMUDEztdZ",
        "eHBT-meYujzT",
        "O_qD3QStvY9-",
        "j0GY8tuaASAw",
        "bshuwxArxin9",
        "5ox_ZzLnoWj6",
        "OcK4anC_yC8j"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b651ce371ee2444b8dc22ad7c5eb18dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b81e80a7522842a0b941dbe9872ed1b6",
              "IPY_MODEL_05822181ce9546718855001c892adf18",
              "IPY_MODEL_6e93818df3e84fb8a7d3e0c17e24ddac"
            ],
            "layout": "IPY_MODEL_852139825b4a49f193b85027e1dc15fe",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b81e80a7522842a0b941dbe9872ed1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7a3b85387c444161839c6a4fae7a155d",
            "placeholder": "​",
            "style": "IPY_MODEL_4988c719747a47fa8f4e8400e4dfb1f6",
            "tabbable": null,
            "tooltip": null,
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "05822181ce9546718855001c892adf18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_63aee209e4584fcca293c64f5bed9007",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcc674ca81204858b15cb5cdd62522ee",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "6e93818df3e84fb8a7d3e0c17e24ddac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_75565d8b1e1f41b486e0c58a40465205",
            "placeholder": "​",
            "style": "IPY_MODEL_0bba67d5287e44eaaf5576bf673eaa84",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [00:00&lt;00:00,  5.13it/s]"
          }
        },
        "852139825b4a49f193b85027e1dc15fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "7a3b85387c444161839c6a4fae7a155d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4988c719747a47fa8f4e8400e4dfb1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "63aee209e4584fcca293c64f5bed9007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc674ca81204858b15cb5cdd62522ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75565d8b1e1f41b486e0c58a40465205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bba67d5287e44eaaf5576bf673eaa84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c1819ba5e5334f83bcc93cecafc9a093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6ca9e5f49ca4e268ee0f851158a65ba",
              "IPY_MODEL_a735cae784e54361bdaf6216335f1e76",
              "IPY_MODEL_b6f345e7e7b34f6a8f7e86438b366996"
            ],
            "layout": "IPY_MODEL_f52f76f1e5944de0bdfec77907e9a7da",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f6ca9e5f49ca4e268ee0f851158a65ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c427076e05f143f993c6c17a346eadc8",
            "placeholder": "​",
            "style": "IPY_MODEL_535e7e8ec4e8471889ec47a264b07a0a",
            "tabbable": null,
            "tooltip": null,
            "value": "Epoch 11:  34%"
          }
        },
        "a735cae784e54361bdaf6216335f1e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d96454d791274b92a68d72d9bac00486",
            "max": 2765,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd1efeeb4771468b8784d9ceae8690ab",
            "tabbable": null,
            "tooltip": null,
            "value": 927
          }
        },
        "b6f345e7e7b34f6a8f7e86438b366996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c9518f576c0140b29178fd08bcc7fda4",
            "placeholder": "​",
            "style": "IPY_MODEL_800548da03ed4c569fd19cc1def37306",
            "tabbable": null,
            "tooltip": null,
            "value": " 927/2765 [03:14&lt;06:25,  4.76it/s, loss=0.0887, v_num=14]"
          }
        },
        "f52f76f1e5944de0bdfec77907e9a7da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c427076e05f143f993c6c17a346eadc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535e7e8ec4e8471889ec47a264b07a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d96454d791274b92a68d72d9bac00486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1efeeb4771468b8784d9ceae8690ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9518f576c0140b29178fd08bcc7fda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800548da03ed4c569fd19cc1def37306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "aeade328277544639a3852e7deeb4fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f93fd009aee24aeb9068a4f952676e87",
              "IPY_MODEL_34f4aabb3ef8445faa6a93a868c6de62",
              "IPY_MODEL_149187c3d52c4990b3838d6bd618aa8d"
            ],
            "layout": "IPY_MODEL_9ad46e50aec8488280d941851a262d0b",
            "tabbable": null,
            "tooltip": null
          }
        },
        "f93fd009aee24aeb9068a4f952676e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7882b795cc70439780e1aec52f40ed8b",
            "placeholder": "​",
            "style": "IPY_MODEL_d6b49e326d824e1eb759f4c266b86cd3",
            "tabbable": null,
            "tooltip": null,
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "34f4aabb3ef8445faa6a93a868c6de62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_808cb1a615dd49afb2e3eb96a37d4ec1",
            "max": 303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4e33789d35b48af84349785495c2f6f",
            "tabbable": null,
            "tooltip": null,
            "value": 303
          }
        },
        "149187c3d52c4990b3838d6bd618aa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_89f136796d664932bd2e5c258c9531e4",
            "placeholder": "​",
            "style": "IPY_MODEL_263788092d6d4eee958c4db453d06d91",
            "tabbable": null,
            "tooltip": null,
            "value": " 303/303 [00:15&lt;00:00, 20.06it/s]"
          }
        },
        "9ad46e50aec8488280d941851a262d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "7882b795cc70439780e1aec52f40ed8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b49e326d824e1eb759f4c266b86cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "808cb1a615dd49afb2e3eb96a37d4ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e33789d35b48af84349785495c2f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f136796d664932bd2e5c258c9531e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263788092d6d4eee958c4db453d06d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "18b4eca995f0423fb5957e7de233c1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d00e6f33444ae696e68508f6d74f2b",
              "IPY_MODEL_048810b6fe05497ca53653d531ba7e82",
              "IPY_MODEL_a84ee8bd6dd04c6e9296f7353eaf6d0f"
            ],
            "layout": "IPY_MODEL_71ad413ff5274899a338c2c6f37e29eb",
            "tabbable": null,
            "tooltip": null
          }
        },
        "e4d00e6f33444ae696e68508f6d74f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c3c78945f09041d4baddd304b20d4e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_0362c532b16942869a727da8c3fcf97c",
            "tabbable": null,
            "tooltip": null,
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "048810b6fe05497ca53653d531ba7e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5e9a695249f745db996a0c270399676a",
            "max": 303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e5cefbdc7474a8bbedc1f1b78adfe00",
            "tabbable": null,
            "tooltip": null,
            "value": 303
          }
        },
        "a84ee8bd6dd04c6e9296f7353eaf6d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_be86f683e64d438eaa3b2c3db85a4257",
            "placeholder": "​",
            "style": "IPY_MODEL_35eb2d3b3a9e4f598c5b723af71094e9",
            "tabbable": null,
            "tooltip": null,
            "value": " 303/303 [00:15&lt;00:00, 19.97it/s]"
          }
        },
        "71ad413ff5274899a338c2c6f37e29eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c3c78945f09041d4baddd304b20d4e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0362c532b16942869a727da8c3fcf97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "5e9a695249f745db996a0c270399676a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5cefbdc7474a8bbedc1f1b78adfe00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be86f683e64d438eaa3b2c3db85a4257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35eb2d3b3a9e4f598c5b723af71094e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e9cd2ea5b0004d10ac962e2ff477bf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b90b877dbb4448d589ac02027a8443d7",
              "IPY_MODEL_f31ebd1f053941c991f690f6f1eb63d3",
              "IPY_MODEL_b5665f150fcb49bfbd403eddf40c135f"
            ],
            "layout": "IPY_MODEL_ba645928cd99456ab6fb612694fa41f6",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b90b877dbb4448d589ac02027a8443d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ffe9e0827dd2458a91e2d286fb04178b",
            "placeholder": "​",
            "style": "IPY_MODEL_cdf6a0a9c44748a79e04bcf6f6def0df",
            "tabbable": null,
            "tooltip": null,
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "f31ebd1f053941c991f690f6f1eb63d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3c29da84a0df43bfbe1aa472453958db",
            "max": 303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa4b0b7da0047a897c0e1e4e3e65461",
            "tabbable": null,
            "tooltip": null,
            "value": 303
          }
        },
        "b5665f150fcb49bfbd403eddf40c135f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ecf7842d09d44479ad48994ae86b0a74",
            "placeholder": "​",
            "style": "IPY_MODEL_089d59f404c94ae5b0590314b9a04ed4",
            "tabbable": null,
            "tooltip": null,
            "value": " 303/303 [00:15&lt;00:00, 19.97it/s]"
          }
        },
        "ba645928cd99456ab6fb612694fa41f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "ffe9e0827dd2458a91e2d286fb04178b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf6a0a9c44748a79e04bcf6f6def0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3c29da84a0df43bfbe1aa472453958db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa4b0b7da0047a897c0e1e4e3e65461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf7842d09d44479ad48994ae86b0a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089d59f404c94ae5b0590314b9a04ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3b0d4181afc74503aec0953ea270a3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a637dad82e54fdfb757a2176ce2d45d",
              "IPY_MODEL_71d460c13ff64b7d90871843d017b2ba",
              "IPY_MODEL_4deb87f0c9f341a8ab0cd275aad53288"
            ],
            "layout": "IPY_MODEL_a6ec26092e874d3dbe286bc1a63491e8",
            "tabbable": null,
            "tooltip": null
          }
        },
        "0a637dad82e54fdfb757a2176ce2d45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b6de724510d54d25a7d4a347704fa8c1",
            "placeholder": "​",
            "style": "IPY_MODEL_4018533da60544098f1d5cecebb3a5e0",
            "tabbable": null,
            "tooltip": null,
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "71d460c13ff64b7d90871843d017b2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4247176ad58e4b3993f1a8c6c26c6110",
            "max": 303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b67cc80311d7402c9992d4edcd3243bf",
            "tabbable": null,
            "tooltip": null,
            "value": 303
          }
        },
        "4deb87f0c9f341a8ab0cd275aad53288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5f439754a2de43d9b7ebfdba88b8fe22",
            "placeholder": "​",
            "style": "IPY_MODEL_f3fdaadf791a4ab2b258cbf40284ed36",
            "tabbable": null,
            "tooltip": null,
            "value": " 303/303 [00:15&lt;00:00, 20.00it/s]"
          }
        },
        "a6ec26092e874d3dbe286bc1a63491e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "b6de724510d54d25a7d4a347704fa8c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4018533da60544098f1d5cecebb3a5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4247176ad58e4b3993f1a8c6c26c6110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67cc80311d7402c9992d4edcd3243bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f439754a2de43d9b7ebfdba88b8fe22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fdaadf791a4ab2b258cbf40284ed36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ce37263490924409af68ec5d1c511a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c145c400e45d4940b88469c3bc40664f",
              "IPY_MODEL_db65d75cc08b41f498512eaab3c7efc4",
              "IPY_MODEL_2e726a485b0a4e7c8f80cbd0785fe592"
            ],
            "layout": "IPY_MODEL_09ccc91a82e84481beebf0033573dfd9",
            "tabbable": null,
            "tooltip": null
          }
        },
        "c145c400e45d4940b88469c3bc40664f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_21562d9055c34e2f904b221e2bc0f363",
            "placeholder": "​",
            "style": "IPY_MODEL_090872bf75c748f88f2bf1c9465755a5",
            "tabbable": null,
            "tooltip": null,
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "db65d75cc08b41f498512eaab3c7efc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e87b58fd09684c00b7f1e48d058512c8",
            "max": 303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_849694b80ba0444e8036e2216235bba8",
            "tabbable": null,
            "tooltip": null,
            "value": 303
          }
        },
        "2e726a485b0a4e7c8f80cbd0785fe592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3cd92ebe2de14165a0f6bb46caf12da7",
            "placeholder": "​",
            "style": "IPY_MODEL_9fe354fbc6804c75a9a1b32c24f9bd34",
            "tabbable": null,
            "tooltip": null,
            "value": " 303/303 [00:15&lt;00:00, 19.95it/s]"
          }
        },
        "09ccc91a82e84481beebf0033573dfd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "21562d9055c34e2f904b221e2bc0f363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090872bf75c748f88f2bf1c9465755a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e87b58fd09684c00b7f1e48d058512c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849694b80ba0444e8036e2216235bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cd92ebe2de14165a0f6bb46caf12da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe354fbc6804c75a9a1b32c24f9bd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "42b3cce7335a430cb244e9e1252c2bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00d64aee60b24f009e2a26ce44551c20",
              "IPY_MODEL_7f679aefc39f4b27b57604afcd30643f",
              "IPY_MODEL_bf9829b185fc41de93247990dc54dbe8"
            ],
            "layout": "IPY_MODEL_b73816b016694432949264fca37621d6",
            "tabbable": null,
            "tooltip": null
          }
        },
        "00d64aee60b24f009e2a26ce44551c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ce88b6fc24f042babb77838ad1da4431",
            "placeholder": "​",
            "style": "IPY_MODEL_78c8788c1fd44852b03c13e15d8580db",
            "tabbable": null,
            "tooltip": null,
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "7f679aefc39f4b27b57604afcd30643f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b8d1fb937eb04fb1acf837132bf53116",
            "max": 303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cab6b737d804499a4bf21a17dd441a5",
            "tabbable": null,
            "tooltip": null,
            "value": 303
          }
        },
        "bf9829b185fc41de93247990dc54dbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3bc52bb2d96d44268e008badef4ba87f",
            "placeholder": "​",
            "style": "IPY_MODEL_437fde8b4153494a823bd40f5430e058",
            "tabbable": null,
            "tooltip": null,
            "value": " 303/303 [00:15&lt;00:00, 19.94it/s]"
          }
        },
        "b73816b016694432949264fca37621d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "ce88b6fc24f042babb77838ad1da4431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c8788c1fd44852b03c13e15d8580db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b8d1fb937eb04fb1acf837132bf53116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cab6b737d804499a4bf21a17dd441a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bc52bb2d96d44268e008badef4ba87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437fde8b4153494a823bd40f5430e058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}